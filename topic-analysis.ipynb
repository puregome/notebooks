{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic analysis\n",
    "\n",
    "Compare words in tweets from volume peak dates with words from tweets from other dates to find out which topics triggered the volume peaks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "sys.path.append(\"/home/erikt/projects/newsgac/fasttext-runs\")\n",
    "import tscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/erikt/projects/puregome/data/text/\"\n",
    "ID = \"id_str\"\n",
    "TEXT = \"text\"\n",
    "TOKEN = \"token\"\n",
    "TOKENFILE = \"tokens.csv\"\n",
    "USER = \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEPATTERN = \"2020031[1245]\"\n",
    "QUERY = \"corona|covid|flattenthecurve|blijfthuis|rivm|mondkapje|huisarts|houvol|zorg\"\n",
    "NBROFEXAMPLES = 10\n",
    "\n",
    "def getExamples(datePattern,query1=QUERY,query2=\"\"):\n",
    "    fileList = sorted(os.listdir(DATADIR))\n",
    "    tweets = {}\n",
    "    for inFileName in fileList:\n",
    "        if re.search(datePattern,inFileName):\n",
    "            clear_output(wait=True)\n",
    "            print(inFileName)\n",
    "            df = pd.read_csv(DATADIR+inFileName,compression=\"gzip\",index_col=ID)\n",
    "            for i in range(0,len(df)):\n",
    "                text = df.iloc[i][TEXT]\n",
    "                if re.search(query1,text) and re.search(query2,text):\n",
    "                    if text in tweets: tweets[text] += 1\n",
    "                    else: tweets[text] = 1\n",
    "    return({tweet:tweets[tweet] for tweet in sorted(tweets.keys(),key=lambda t:tweets[t],reverse=True)})\n",
    "\n",
    "def makeData(datePattern,query=QUERY):\n",
    "    fileList = sorted(os.listdir(DATADIR))\n",
    "    tokens = {}\n",
    "    for inFileName in fileList:\n",
    "        if re.search(datePattern,inFileName):\n",
    "            clear_output(wait=True)\n",
    "            print(inFileName)\n",
    "            date = inFileName[0:8]\n",
    "            if not date in tokens: tokens[date] = {}\n",
    "            df = pd.read_csv(DATADIR+inFileName,compression=\"gzip\",index_col=ID)\n",
    "            for i in range(0,len(df)):\n",
    "                text = df.iloc[i][TEXT]\n",
    "                if re.search(query,text):\n",
    "                    for token in TweetTokenizer().tokenize(text.lower()): \n",
    "                        if re.search(r\"[a-z]\",token):\n",
    "                            if not token in tokens[date]: tokens[date][token] = 0\n",
    "                            tokens[date][token] += 1\n",
    "    return(tokens)\n",
    "\n",
    "def writeData(data,fileName):\n",
    "    pd.DataFrame(data).to_csv(fileName,index_label=TOKEN)\n",
    "    \n",
    "def readData(fileName):\n",
    "    return(pd.read_csv(fileName,index_col=TOKEN).to_dict())\n",
    "\n",
    "def dictTopN(dictionary,N=NBROFEXAMPLES):\n",
    "    return([(x[1],x[0]) for x in dictionary.items()][0:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200525-18.out.gz\n"
     ]
    }
   ],
   "source": [
    "#tokens = readData(TOKENFILE)\n",
    "for month in \"202003 202004 202005\".split():\n",
    "    print(month)\n",
    "    tokens = makeData(month)\n",
    "    writeData(tokens,\"tokens\"+month+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFTOKENS = \"totalFreq\"\n",
    "NBROFTYPES = \"nbrOfWords\"\n",
    "WORDFREQS = \"wordFreqs\"\n",
    "\n",
    "def makeTscoreData(tokenList):\n",
    "    data = { NBROFTOKENS:0, NBROFTYPES:0, WORDFREQS:{} }\n",
    "    for token in tokenList:\n",
    "        if not math.isnan(tokenList[token]):\n",
    "            data[WORDFREQS][token] = tokenList[token]\n",
    "            data[NBROFTYPES] += 1\n",
    "            data[NBROFTOKENS] += tokenList[token]\n",
    "    return(data)\n",
    "\n",
    "def sortTscores(tscores):\n",
    "    return({token:tscores[token] for token in sorted(tscores.keys(),key=lambda t:tscores[t],reverse=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscoreData = {}\n",
    "for date in tokens:\n",
    "    tscoreData[date] = makeTscoreData(tokens[date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(91.60442025764918, '#coronadebat'),\n",
       " (78.97741163967773, '#covid_19'),\n",
       " (65.5129728502599, 'scholen'),\n",
       " (58.05318808343848, 'rutte'),\n",
       " (45.94871916226014, 'kinderen'),\n",
       " (42.2056255747426, 'kabinet'),\n",
       " (41.77929963688309, 'maatregelen'),\n",
       " (40.13852933881494, 'trump'),\n",
       " (38.934780261956206, 'onderwijs'),\n",
       " (38.143346719667484, 'sluiten'),\n",
       " (36.15941845414344, 'ouders'),\n",
       " (34.67443174873152, '#persconferentie'),\n",
       " (32.30460846375055, 'schouders'),\n",
       " (31.94561264372927, 'vanavond'),\n",
       " (31.443044262387314, 'persconferentie'),\n",
       " (30.64989800427607, '#coronahulp'),\n",
       " (30.451036528043275, 'vvd'),\n",
       " (30.242371033416283, 'blijven'),\n",
       " (30.154322917933154, 'onderwijspersoneel'),\n",
       " (30.12977279038019, '#coronavirusnederland')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictTopN(sortTscores(tscore.computeTscore(tscoreData[\"20200312\"],tscoreData[\"20200311\"])),N=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56.10373202523538, '#coronavirusnl'),\n",
       " (51.27541386261536, '16u'),\n",
       " (43.506825050815195, 'horeca'),\n",
       " (42.68413740392834, '#covid19nl'),\n",
       " (42.666377863812585, 'genomen'),\n",
       " (42.130617286003975, '#lockdownnl'),\n",
       " (41.27300848805268, 'april'),\n",
       " (38.706021588851996, 'morgenavond'),\n",
       " (37.41640267762352, 'nbelgen'),\n",
       " (36.594544941735116, 'aanvullende'),\n",
       " (36.34116105725093, 'fuiven'),\n",
       " (36.13170079804637, 'pletter'),\n",
       " (35.97562853910354, 'beginnen'),\n",
       " (35.90013496104832, 'uitlachen'),\n",
       " (35.520520050898924, 'morgenvroeg'),\n",
       " (35.489863712482006, '9u'),\n",
       " (35.448115484855634, 'maatregelen'),\n",
       " (34.7973055808141, 'negatief'),\n",
       " (34.72120740646297, 'ndat'),\n",
       " (34.30839614997719, '@mohamedouaamari')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictTopN(sortTscores(tscore.computeTscore(tscoreData[\"20200315\"],tscoreData[\"20200314\"])),N=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "There is a clear impact of the national press conferences on the topic tweets of the two volume peak dates. On 20200312, both the event (*persconferentie*) and the speakers (*rutte* and *kabinet*) are present in the top 20 words selected by the tscore measure. The most important topic in the tweets was the dicussion about school closures (*scholen*, *kinderen*, *onderwijs*, *sluiten*, *ouders* and *onderwijspersoneel*). On 20200315 the main topic is the closure of bars and restaurants (*horeca*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTopN(getExamples(\"20200312\",query1=QUERY,query2=\"scholen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTopN(getExamples(\"20200313\",query1=QUERY,query2=\"scholen\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
