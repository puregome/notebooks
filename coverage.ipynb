{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage tests for collected tweets\n",
    "\n",
    "Estimate what percentage of Dutch tweets are collected by twiqs.nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIRTEXT = \"/home/erikt/projects/puregome/data/text/\"\n",
    "DATADIRCLOUD = \"/home/erikt/projects/puregome/data/text-cloud/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extimate coverage with reply ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDSTR = \"id_str\"\n",
    "INREPLYTOSTATUSIDSTR = \"in_reply_to_status_id_str\"\n",
    "\n",
    "def getReplyPercentage(filePattern):\n",
    "    files = sorted(os.listdir(DATADIRTEXT))\n",
    "    found = 0\n",
    "    missing = 0\n",
    "    seenIds = {}\n",
    "    for inFileName in files:\n",
    "        if re.search(filePattern,inFileName):\n",
    "            squeal(inFileName)\n",
    "            df = pd.read_csv(DATADIRTEXT+inFileName,dtype={IDSTR:object})\n",
    "            seenIds = {**seenIds,**{idStr:True for idStr in df[IDSTR]}}\n",
    "    files = sorted(os.listdir(DATADIRCLOUD))\n",
    "    for inFileName in files:\n",
    "        if re.search(filePattern,inFileName):\n",
    "            squeal(inFileName)\n",
    "            df = pd.read_csv(DATADIRCLOUD+inFileName,dtype={INREPLYTOSTATUSIDSTR:object})\n",
    "            for idStr in df[INREPLYTOSTATUSIDSTR]:\n",
    "                if idStr == idStr:\n",
    "                    if idStr in seenIds: found += 1\n",
    "                    else: missing += 1\n",
    "    return(found/(found+missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200726-08.out.gz\n"
     ]
    }
   ],
   "source": [
    "filePattern = \"202007\"\n",
    "percentage = getReplyPercentage(filePattern)\n",
    "print(f\"target date: {filePattern}; percentage: {percentage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query token language coverage\n",
    "\n",
    "How many of the tweets containing a query token are written in Dutch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIRCOVERAGE = \"./\"\n",
    "FILEPATTERNCOVERAGE = \"20200701-0[0-57-9]|20200701-1[0-7]|20200701-2[12]\"\n",
    "TEXT = \"text\"\n",
    "LANG = \"lang\"\n",
    "DUTCH = \"dutch\"\n",
    "OTHER = \"other\"\n",
    "UNKNOWN = \"unknown\"\n",
    "\n",
    "def coverage(token):\n",
    "    files = sorted(os.listdir(DATADIRCOVERAGE))    \n",
    "    langs = {}\n",
    "    for inFileName in files:\n",
    "        if re.search(FILEPATTERNCOVERAGE,inFileName):\n",
    "            df = pd.read_csv(inFileName,compression=\"gzip\")\n",
    "            for i in range(0,len(df)):\n",
    "                try:\n",
    "                    if re.search(r'\\b'+token+r'\\b',df.iloc[i][TEXT]):\n",
    "                        lang = df.iloc[i][LANG]\n",
    "                        if lang in langs: langs[lang] += 1\n",
    "                        else: langs[lang] = 1\n",
    "                except: pass\n",
    "    return(langs)\n",
    "\n",
    "def coverageDutchOld(token):\n",
    "    langs = coverage(token)\n",
    "    summary = {DUTCH:0,OTHER:0}\n",
    "    for lang in langs:\n",
    "        if lang == DUTCH: summary[DUTCH] += langs[lang]\n",
    "        elif lang != UNKNOWN: summary[OTHER] += langs[lang]\n",
    "    if summary[DUTCH] == 0: return(0)\n",
    "    else: return(summary[DUTCH]/(summary[DUTCH]+summary[OTHER]))\n",
    "    \n",
    "def coverageDutch(token,tweetsLang):\n",
    "    summary = {DUTCH:0,OTHER:0}\n",
    "    for text in tweetsLang.keys():\n",
    "        if token in text.split():\n",
    "            if tweetsLang[text] == DUTCH: summary[DUTCH] += 1\n",
    "            elif tweetsLang[text] != UNKNOWN: summary[OTHER] += 1\n",
    "    if summary[DUTCH] == 0: return(0)\n",
    "    else: return(summary[DUTCH]/(summary[DUTCH]+summary[OTHER]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIPTOKENS = \"rt amsterdam the woof ros√© de en in is van me ben we via nos juno br staysafe spnmarais arcinho kamafotos youtube \\\n",
    "update amp bts_twt blackpink baby and omg best ygofficialblink on ig goal wonderland ten instagram top you wonwoo daniel \\\n",
    "1advancehbdmaheshbabu with open of for vlive ver to netherlands jungkook up joonie jennie from super my kpop klopp gt vlog queen \\\n",
    "nct love by boy bergwijn zoe twitter teen te stop so more master lee hahahaha gogh god ever bruyne an ameen tik this stream slap \\\n",
    "school one oh ni man level ko just im hi here help he duit deluxe day da better beef be art aameen zico yes wtf wtaf winner will \\\n",
    "vn video vc total that team superior street snoop re pubg pink oopsie no new ne namkook moots moon miss maam look link la ka juliet \\\n",
    "jinnie jinkook his hey hahahahaha goals go gemes fan een dus do black back am all aaron zombie yep yeah woop won win weekend war un \\\n",
    "tingz thank tekken taekook sterling star stan sorry snap sex sb19official robin poor pls out onvres onde omfg ok ns now not need \\\n",
    "moonbin mood min mein maap maaf live let legend left laptop ke kangen jimin jan it iq how hot hoodie holy her hee happy hahahahah \\\n",
    "haha ha groningen got gg gente funny ft ff fc engineer eh ee down donde dm damn cute chief can bro big bestie banget at as \\\n",
    "xiaojun gee advancehbdmaheshbabu weareoneexo kang tier straykids kun dream tiktok than kevin jin haechan golden boys actorvijay \\\n",
    "unnie tweets pop only mochi missing like genie don bts alice it's he's i'm let's zone tok she mo made kids howyoulikethat era el \\\n",
    "duo drop angel allah urstrulymahesh winwin exo official dance hours heels has el edit proud\".split()\n",
    "SKIPTOKENS = r\", . ! ? : ; - ( ) @ # $ / [ ] < >  ' + = | .. ... ` & \\\" \".split()\n",
    "SKIPTOKENS = \"üòâ ¬∞ ü•á ü•à ü•â ‚Äì ¬ø ¬• ‚òÄ wonderland\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATTERN = \"202006\"\n",
    "TEXT = \"text\"\n",
    "BASELEXICON = \"\".split()\n",
    "ALLCOUNT = 596893 # 5623571 # 22798953 # 22798953\n",
    "LEFT200 = 61599\n",
    "LEFT100 = 80258 # 349598 # 1724488 # 1231745\n",
    "LEFT200100 = 43622 # 179089 # 801171 # 732526\n",
    "LEFT300200100 = 34583 # 130887 # 557205 # 531315\n",
    "LEFT400300200100 = 29528 # 109099 # 451231 # 439565\n",
    "LEFT500400300200100 = 0 # # 394609 # 387447\n",
    "LEFT600500400300200100 = 0 # # 357003 # 352026\n",
    "LEFT700600500400300200100 = 0 # # 329054 # 324628\n",
    "LEFT800700600500400300200100 = 0 # # 306745 # 303422\n",
    "\n",
    "results = []\n",
    "\n",
    "def cleanupText(text):\n",
    "    text = re.sub(r\"\\\\n\",\" \",text.lower())\n",
    "    text = re.sub(r\"[#@]\",\" \",text)\n",
    "    return(text)\n",
    "\n",
    "def tokenize(tokenizer,text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return(\" \".join(sorted(list(set(tokens)))))\n",
    "\n",
    "def cleanupTokens(text):\n",
    "    tokens = set(text.split())\n",
    "    newTokens = []\n",
    "    for token in tokens:\n",
    "        if not re.search(r\"http\",token) and not token in SKIPTOKENS and len(token) > 1: newTokens.append(token)\n",
    "    return(\" \".join(newTokens))\n",
    "\n",
    "def getTweetsFile(inFileName,dataDir):\n",
    "    tweets = {}\n",
    "    squeal(inFileName)\n",
    "    tokenizer = TweetTokenizer()\n",
    "    df = pd.read_csv(dataDir+inFileName)\n",
    "    for i in range(0,len(df)):\n",
    "        text = cleanupText(df.iloc[i][TEXT])\n",
    "        text = tokenize(tokenizer,text)\n",
    "        text = cleanupTokens(text)\n",
    "        if LANG in df: tweets[text] = df.iloc[i][LANG]\n",
    "        else: tweets[text] = True\n",
    "    return(tweets)\n",
    "\n",
    "def collectResult(result):\n",
    "    global results\n",
    "    results.append(result)\n",
    "\n",
    "def getTweetsParallel(filePattern=FILEPATTERN,dataDir=DATADIR):\n",
    "    global results\n",
    "    files = sorted(os.listdir(dataDir))\n",
    "    inFileNames = []\n",
    "    for inFileName in files:\n",
    "        if re.search(filePattern,inFileName): inFileNames.append(inFileName)\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    results = [pool.apply(getTweetsFile,args=[inFileName,dataDir]) for inFileName in inFileNames]\n",
    "    pool.close()\n",
    "    while len(results) > 1:\n",
    "        toBeDeleted = []\n",
    "        for i in range(0,len(results),2):\n",
    "            if i < len(results)-1: \n",
    "                results[i] = {**results[i],**results[i+1]}\n",
    "                toBeDeleted.append(i+1)\n",
    "        toBeDeleted.reverse()\n",
    "        for i in toBeDeleted: del(results[i])\n",
    "    return(results[0])\n",
    "\n",
    "def getTweets(filePattern=FILEPATTERN,dataDir=DATADIR):\n",
    "    files = sorted(os.listdir(dataDir))\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tweets = {}\n",
    "    for inFileName in files:\n",
    "        if re.search(filePattern,inFileName):\n",
    "            squeal(inFileName)\n",
    "            df = pd.read_csv(dataDir+inFileName)\n",
    "            for i in range(0,len(df)):\n",
    "                text = cleanupText(df.iloc[i][TEXT])\n",
    "                text = tokenize(tokenizer,text)\n",
    "                text = cleanupTokens(text)\n",
    "                if LANG in df: tweets[text] = df.iloc[i][LANG]\n",
    "                else: tweets[text] = True\n",
    "    return(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200630-23.out.gz\n"
     ]
    }
   ],
   "source": [
    "tweetsLangOrg = getTweets(filePattern=FILEPATTERNCOVERAGE,dataDir=DATADIRCOVERAGE)\n",
    "tweetsOrg = getTweetsParallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsLang = dict(tweetsLangOrg)\n",
    "tweets = dict(tweetsOrg)\n",
    "lexicon = {token:0 for token in list(BASELEXICON)}\n",
    "skipTokens = {s:0 for s in SKIPTOKENS}\n",
    "processedTweetCounts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 1651848 1570 252 winter 0.9675324675324676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'de een ik is je en rt het in ... niet van op dat voor met ja die ook me te we maar weer zijn wat zo of lekker wel bij tweet .. goed was open geen mooi echt dan dit 2020 vacature na stop via nog 20 ze fijne mijn ben best over man ga aan amsterdam jij mm nu veel eens mooie he door letsel naar gefeliciteerd dankjewel kan al 01 goedemorgen uit 10 deze toch morgen om :) nee wie zeker af heel even da als den heeft gewoon nemen nieuwe leuk br sterkte er hoor 11 twitter 12 graag hoe heerlijk meer prachtig ah inderdaad 13 eu mij mn p2000 waar dag 18 altijd ver vs blonde hier klopt men ff nos 19 doen goeie geweldig onze wolf dus weg bedankt telegraaf mee moet foto komen waarom ten tot up 15 welkom 14 welke 02 net lang snap 71 jullie team alles fijn goede 17 nooit 16 daar allen 21 :/ been school tz hij vandaag utrecht nou uw 03 allemaal 100 ter 24 black zonder want zeg gaat gaan keren 23 gelukkig dank doe niemand word h√® alle nieuw klaar tijd gedaan jaar water geniet had tegen vvd gij auto 99 haar 27 smakelijk wordt 25 bv natuurlijk rotterdam video kijk toe ge beetje 50 let gezellig heb goeiemorgen zie 28 mensen uur wil link 30 ie kom bijna hoezo 33 hoi eindelijk tuurlijk leuke rgoerkgor hoop nieuws helemaal werk seventeen nl jan wet wij oeps :p 29 never 31 pas succes gratis beste terug hard thierrybaudet genie sex 48 online 26 gente kim misschien gelijk wflwkowrk live beterschap week ;) nintendoswitch gwn max your jazeker hetero laat allah herkenbaar mag 77 hun vol uiteraard zou eerste ingeborgvraagt new 95 bos mark 123 kraken gaaf wierdduk vn moe rglmergrm grote maak instagram goedemiddag ggdk zee vreselijk zeer min 44 kids worden sleep kun ken niks steven prachtige links 40 94 per ok√© time minpres green mario youtube vws nederland glrglrmeor fc lief half master oms 007 ons neen jouw 35 pfff 2019 wanneer jawel doei h√© hmm zelf 42 mis legends weekend sterling vrtweer beter joe ): 55 welk daarom reglermg led jk punten 93 jndkgrf st verdade alleen leer 88 45 model geld groningen zoiets 64 naam last fruit klein echte bnr kut noor zal terecht 2.0 iets afstand don 75 kanker stay iedereen name mode helen politie start art hele komt erg zone 79 band post ruim vrouw netflix ad 91 status tweets onder pak beer los alweer corona blind btw 78 90 joel iemand 81 john cv wind eric blijft 87 dr wforkgorekg doet irrelevant duidelijk karen 59 gl 101 plan idd jurgen alex paper vr eerst challenge walgelijk gang kijken belgium 38 lifeliner 66 gero missing dts alert ps4share jaaa hugodejonge wa jezus club ewdevlieger staat taak buiten paar 72 who netherlands geertwilderspvv snel tiktok 74 34 rlerogkmero keer knap bek 89 ow ns joostniemoller 67 meen 70 37 official zwarte info 83 blijven wc bende junior 52 hebben gecondoleerd eer val zwolle george helaas spongebob amersfoort twee app genial zoals extra james burger done genoeg 666 rtlnieuws menu ajax kk veronicainside denzel namjoon sp :-) zelfs gelukkige donarturito bang nder 73 ca trump film maakt bbq erwin monster chris binnen ii anders mama verschrikkelijk las inzet slaap pffff derek hyunjin vroeg boek test sgravh 32 ziek account laatste park venmo tuig ongeval ach joke borderlands respect gezien frank gek radio metal boven boze ser stelletje michael mv dom 60 keep thuis 333 80 vo blue weew 1000 hem weibo sterlin maken mr vanavond 39 genieten 2018 nunl zaten draadje stuk nope 200 spring bas 62 broer 47 rap gm leg eet 54 soonhoon heerlijke block fans ijs opening dalende schatje moment niets 36 crying pro gender leider 85 perfect ooit screen gemeente enzo 82 ouwe log zit late trending knuffel coronavirus zin plus netjes later porno welterusten gezocht linkse nen schade kkk ivan voodoo 68 next superjan gas jr spotify johnny sterk 76 type nel special bakr 000 gevonden prima hobi adnl zalig zoekt internet vooral outdoor heineken goe rose merci groen 4ever 53 chips white vocal dating 84 65 tom nodig bazaar zekers vanaf geweldige hou np 51 lag zegt cupcakke_rapper maat bent woonhuis ex huis groenlinks newprofilepic vraag v5 nederlands kpophappenings kop krijgt pt geniaal bed maal blijkbaar mega meter koffie des precies garden tv women erikmouthaanrtl jack haarlem kat kong 63 ij zero vminkook ms little ronde ofzo college denk playing bighitent friends woman shirt insta 61 letterlijk geworden dam joebiden 41 rug vd eng groot 43 jaaaa robin zag zoveel konnect_danielk maandag land lekkere paul zelfde hets slaapwel gerapporteerd cm jones gewonnen 110 volunteer rest if reis bts_jp_official job west 2000 woeee raar ab 777 winter'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 0.9\n",
    "MAXLEXICONSIZE = 800\n",
    "\n",
    "coverageDutchScore = \"\"\n",
    "while len(lexicon) < MAXLEXICONSIZE:\n",
    "    frequencies = {}\n",
    "    processedTweetCount = 0\n",
    "    counter = 0\n",
    "    toBeDeleted = []\n",
    "    if len(lexicon) > 0: lastToken = list(lexicon.keys())[-1]\n",
    "    else: lastToken = \"\"\n",
    "    for text in tweets.keys():\n",
    "        counter += 1\n",
    "        if counter%10000 == 0: squeal(str(counter)+\"/\"+str(len(tweets))+\" \"+str(len(lexicon))+\" \"+lastToken+\" \"+str(coverageDutchScore))\n",
    "        tokens = text.split()\n",
    "        if len(set(lexicon.keys()).intersection(tokens)) >= 1:\n",
    "            toBeDeleted.append(text)\n",
    "        else:\n",
    "            processedTweetCount += 1\n",
    "            for token in tokens:\n",
    "                if token in frequencies: frequencies[token] += 1\n",
    "                else: frequencies[token] = 1\n",
    "    for text in toBeDeleted:\n",
    "        del(tweets[text])\n",
    "    #toBeDeletedLang = []\n",
    "    #for text in tweetsLang.keys():\n",
    "    #    tokens = text.split()\n",
    "    #    if len(set(lexicon).intersection(tokens)) >= 1:\n",
    "    #        toBeDeletedLang.append(text)\n",
    "    #for text in toBeDeletedLang:\n",
    "    #    del(tweetsLang[text])    \n",
    "    processedTweetCounts.append(processedTweetCount)\n",
    "    frequencies = {k:frequencies[k] for k in sorted(frequencies.keys(),key=lambda k:frequencies[k],reverse=True)}\n",
    "    for token in frequencies:\n",
    "        if not token in skipTokens and len(token) > 1:\n",
    "            coverageDutchScore = coverageDutch(token,tweetsLang)\n",
    "            squeal(str(len(lexicon))+\" \"+str(processedTweetCount)+\" \"+str(len(skipTokens))+\" \"+str(frequencies[token])+\" \"+str(coverageDutchScore)+\" \"+token)\n",
    "            if coverageDutchScore >= THRESHOLD:\n",
    "                lexicon[token] = coverageDutchScore\n",
    "                break\n",
    "            else: skipTokens[token] = coverageDutchScore\n",
    "    squeal(str(len(lexicon))+\" \"+str(processedTweetCount)+\" \"+str(len(skipTokens))+\" \"+str(frequencies[list(lexicon.keys())[-1]])+\" \"+list(lexicon.keys())[-1]+\" \"+str(coverageDutchScore))\n",
    "    \n",
    "\" \".join(list(lexicon.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de een ik is je en rt het in ... niet van op dat voor met ja die ook me te we maar weer zijn wat zo of lekker wel bij tweet .. goed was open geen mooi echt dan dit 2020 vacature na stop via nog 20 ze fijne mijn ben best over man ga aan amsterdam jij mm nu veel eens mooie he door letsel naar gefeliciteerd dankjewel kan al 01 goedemorgen uit 10 deze toch morgen om :) nee wie zeker af heel even da als den heeft gewoon nemen nieuwe leuk br sterkte er hoor 11 twitter 12 graag hoe heerlijk meer prachtig ah inderdaad 13 eu mij mn p2000 waar dag 18 altijd ver vs blonde hier klopt men ff nos 19 doen goeie geweldig onze wolf dus weg bedankt telegraaf mee moet foto komen waarom ten tot up 15 welkom 14 welke 02 net lang snap 71 jullie team alles fijn goede 17 nooit 16 daar allen 21 :/ been school tz hij vandaag utrecht nou uw 03 allemaal 100 ter 24 black zonder want zeg gaat gaan keren 23 gelukkig dank doe niemand word h√® alle nieuw klaar tijd gedaan jaar water geniet had tegen vvd gij auto 99 haar 27 smakelijk wordt 25 bv natuurlijk rotterdam video kijk toe ge beetje 50 let gezellig heb goeiemorgen zie 28 mensen uur wil link 30 ie kom bijna hoezo 33 hoi eindelijk tuurlijk leuke rgoerkgor hoop nieuws helemaal werk seventeen nl jan wet wij oeps :p 29 never 31 pas succes gratis beste terug hard thierrybaudet genie sex 48 online 26 gente kim misschien gelijk wflwkowrk live beterschap week ;) nintendoswitch gwn max your jazeker hetero laat allah herkenbaar mag 77 hun vol uiteraard zou eerste ingeborgvraagt new 95 bos mark 123 kraken gaaf wierdduk vn moe rglmergrm grote maak instagram goedemiddag ggdk zee vreselijk zeer min 44 kids worden sleep kun ken niks steven prachtige links 40 94 per ok√© time minpres green mario youtube vws nederland glrglrmeor fc lief half master oms 007 ons neen jouw 35 pfff 2019 wanneer jawel doei h√© hmm zelf 42 mis legends weekend sterling vrtweer beter joe ): 55 welk daarom reglermg led jk punten 93 jndkgrf st verdade alleen leer 88 45 model geld groningen zoiets 64 naam last fruit klein echte bnr kut noor zal terecht 2.0 iets afstand don 75 kanker stay iedereen name mode helen politie start art hele komt erg zone 79 band post ruim vrouw netflix ad 91 status tweets onder pak beer los alweer corona blind btw 78 90 joel iemand 81 john cv wind eric blijft 87 dr wforkgorekg doet irrelevant duidelijk karen 59 gl 101 plan idd jurgen alex paper vr eerst challenge walgelijk gang kijken belgium 38 lifeliner 66 gero missing dts alert ps4share jaaa hugodejonge wa jezus club ewdevlieger staat taak buiten paar 72 who netherlands geertwilderspvv snel tiktok 74 34 rlerogkmero keer knap bek 89 ow ns joostniemoller 67 meen 70 37 official zwarte info 83 blijven wc bende junior 52 hebben gecondoleerd eer val zwolle george helaas spongebob amersfoort twee app genial zoals extra james burger done genoeg 666 rtlnieuws menu ajax kk veronicainside denzel namjoon sp :-) zelfs gelukkige donarturito bang nder 73 ca trump film maakt bbq erwin monster chris binnen ii anders mama verschrikkelijk las inzet slaap pffff derek hyunjin vroeg boek test sgravh 32 ziek account laatste park venmo tuig ongeval ach joke borderlands respect gezien frank gek radio metal boven boze ser stelletje michael mv dom 60 keep thuis 333 80 vo blue weew 1000 hem weibo sterlin maken mr vanavond 39 genieten 2018 nunl zaten draadje stuk nope 200 spring bas 62 broer 47 rap gm leg eet 54 soonhoon heerlijke block fans ijs opening dalende schatje moment niets 36 crying pro gender leider 85 perfect ooit screen gemeente enzo 82 ouwe log zit late trending knuffel coronavirus zin plus netjes later porno welterusten gezocht linkse nen schade kkk ivan voodoo 68 next superjan gas jr spotify johnny sterk 76 type nel special bakr 000 gevonden prima hobi adnl zalig zoekt internet vooral outdoor heineken goe rose merci groen 4ever 53 chips white vocal dating 84 65 tom nodig bazaar zekers vanaf geweldige hou np 51 lag zegt cupcakke_rapper maat bent woonhuis ex huis groenlinks newprofilepic vraag v5 nederlands kpophappenings kop krijgt pt geniaal bed maal blijkbaar mega meter koffie des precies garden tv women erikmouthaanrtl jack haarlem kat kong 63 ij zero vminkook ms little ronde ofzo college denk playing bighitent friends woman shirt insta 61 letterlijk geworden dam joebiden 41 rug vd eng groot 43 jaaaa robin zag zoveel konnect_danielk maandag land lekkere paul zelfde hets slaapwel gerapporteerd cm jones gewonnen 110 volunteer rest if reis bts_jp_official job west 2000 woeee raar ab 777 winter'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(list(lexicon.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÄ\n",
      "‡πà\n",
      "¬•\n",
      "¬ø\n",
      "‚öΩ\n",
      "üí§\n",
      "üåû\n",
      "‚ñ∂\n",
      "üèÜ\n",
      "¬ª\n",
      "‚Å¶\n",
      "üë©\n",
      "üå∫\n",
      "ü§´\n",
      "üñï\n"
     ]
    }
   ],
   "source": [
    "for token in lexicon:\n",
    "    if len(token) < 2: print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26370010787486514 rt\n",
      "0.28060740272065804 1\n",
      "0.1268478107841757 omg\n",
      "0.19753086419753085 üòÇ\n",
      "0.1472161680206063 _\n",
      "0.1305528134254689 Ô∏è\n",
      "0.22074074074074074 2\n",
      "0.3265228906545592 ja\n",
      "0.2545779365788298 ameen\n",
      "0.10779111979893885 üò≠\n",
      "0.2482614742698192 me\n",
      "0.10048201705598814 hahaha\n",
      "0.1424706943192065 u\n",
      "0.11897779639715124 ‚ù§\n",
      "0.10287664553876158 i\n",
      "0.19045120671563484 3\n",
      "0.0712979890310786 c\n",
      "0.3823088455772114 weer\n",
      "0.11793611793611794 haha\n",
      "0.12236503856041131 a\n"
     ]
    }
   ],
   "source": [
    "for token in list(skipTokens.keys())[:20]:\n",
    "    print(skipTokens[token],token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFile = open(\"tmp.txt\",\"w\")\n",
    "print(\"track=\",end=\"\",file=outFile)\n",
    "print(\",\".join([lexicon[i] for i in range(0,len(lexicon)) if i % 4 == 0 or i % 4 == 3]),file=outFile)\n",
    "print(\"track=\",end=\"\",file=outFile)\n",
    "print(\",\".join([lexicon[i] for i in range(0,len(lexicon)) if i % 4 == 1 or i % 4 == 2]),file=outFile)\n",
    "outFile.close()\n",
    "print(\" \".join([lexicon[i] for i in range(0,len(lexicon)) if i % 4 == 0 or i % 4 == 3]))\n",
    "print(\" \".join([lexicon[i] for i in range(0,len(lexicon)) if i % 4 == 1 or i % 4 == 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsCopy = tweets\n",
    "for i in range(0,len(lexicon)):\n",
    "    if i % 100 == 0: print(i,len(tweetsCopy))\n",
    "    toBeDeleted = []\n",
    "    for text in tweetsCopy.keys():\n",
    "        tokens = text.split()\n",
    "        if len(set([lexicon[i]]).intersection(tokens)) > 0:\n",
    "            toBeDeleted.append(text)\n",
    "    for text in toBeDeleted:\n",
    "        del(tweetsCopy[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i,len(tweetsCopy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join([str(processedTweetCounts[i]) for i in range(0,800,100)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedFrequencies = {k:frequencies[k] for k in sorted(frequencies.keys(),key=lambda k:frequencies[k],reverse=True)}\n",
    "topTokens800 = [k for k in sortedFrequencies.keys() if re.search(r\"[a-z0-9]\",k) or \\\n",
    "                                                       (len(k) > 1 and k != \"..\" and k != \"...\" or\n",
    "                                                       (len(k) == 1 and ord(k) >= 127000 and ord(k) < 130000))][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\",\".join(topTokens100))\n",
    "print(\",\".join(topTokens200))\n",
    "print(\",\".join(topTokens300))\n",
    "print(\",\".join(topTokens400))\n",
    "print(\",\".join(topTokens500))\n",
    "print(\",\".join(topTokens600))\n",
    "print(\",\".join(topTokens700))\n",
    "print(\",\".join(topTokens800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in topTokens100+topTokens200+topTokens300+topTokens400: print(token,end=\",\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 479 0.9979166666666667 jarige\n",
      "795 479 0.9979166666666667 stukje\n",
      "796 479 0.9958419958419958 beschikbaar\n",
      "797 478 1.0 geschreven\n",
      "798 477 1.0 lijst\n",
      "799 477 1.0 sluiten\n",
      "800 476 0.9937369519832986 waarvan\n"
     ]
    }
   ],
   "source": [
    "THRESHOLDTEXTCAT = 0.99\n",
    "MAXLEXICONTEXTCAT = 800\n",
    "\n",
    "tweetsTextCat = dict(tweetsLangOrg)\n",
    "\n",
    "tokenFreqs = {}\n",
    "for text in tweetsTextCat.keys():\n",
    "    if tweetsTextCat[text] == DUTCH:\n",
    "        for token in text.split():\n",
    "            if token in tokenFreqs: tokenFreqs[token] += 1\n",
    "            else: tokenFreqs[token] = 1\n",
    "\n",
    "#discarded = []\n",
    "#selected = []\n",
    "for token in sorted(tokenFreqs.keys(),key=lambda k:tokenFreqs[k],reverse=True)[807+len(discarded):]:\n",
    "    coverageDutchScore = coverageDutch(token,tweetsTextCat)\n",
    "    if coverageDutchScore < THRESHOLDTEXTCAT: \n",
    "        print(\"          \",end=\"\")\n",
    "        discarded.append(token)\n",
    "    else:\n",
    "        selected.append(token)\n",
    "    print(len(selected),tokenFreqs[token],coverageDutch(token,tweetsTextCat),token)\n",
    "    if len(selected) >= MAXLEXICONTEXTCAT: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENSIGNORE = \"‚Äò ‚Ä¶ ‚Ç¨ üçÄ ‚Äì ¬∞ blm corona covid √©n √©√©n etc euro z'n 1,5\".split()\n",
    "\n",
    "toBeDeleted = []\n",
    "for i in range(len(selected)-1,-1,-1):\n",
    "    if selected[i] in TOKENSIGNORE: toBeDeleted.append(i)\n",
    "for i in toBeDeleted: del(selected[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "en\n",
      "op\n",
      "te\n",
      "er\n",
      "ze\n",
      "zo\n",
      "al\n",
      "nl\n",
      "2e\n"
     ]
    }
   ],
   "source": [
    "for token in selected:\n",
    "    if len(token) <= 2: print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de en van op voor zijn er wel ze geen over meer heb door mijn mensen dus wordt veel hier mij jaar heel alleen hun iets maken onze jullie alle zelf altijd via zien denk omdat staat zit zeker steeds iedereen zeggen allemaal helemaal hem hele hebt geld doet eerste zoals zegt lees misschien kijk verder graag kijken grote goede zeg geven gedaan zwarte snel eerst slavernij zelfs minder werd eigenlijk binnen genoeg waren jouw wereld jaren nl denken samen bijna welke soort vaak fijne juist paar achter geweest excuses idee blij dingen ziet mauricedehond groenlinks tijdens werkt dacht op1npo lezen fijn duidelijk soms links vrouw buiten nieuw zouden racismedebat ging thuis zetten witte geval sterkte aantal artikel ligt volgende maanden sinds bedankt aandacht vanuit prima vrouwen slecht zorg mening rutte thierrybaudet partij anderen benieuwd eten boek echte zei ieder geschiedenis minpres zet rest kwam geef belangrijk groep denkt discriminatie zodat trots totaal blijkbaar gisteren heerlijk zoeken ergens geloof gemeente jezelf hetzelfde ter wilders mannen hugodejonge moeder adnl volgen idd liever hond moeilijk zomer rivm bestaat recht persoon belgi√´ onzin miljoen sommige hen drie racist grootste discussie zichzelf meter toekomst meeste ipv rechts enkele begint vanavond kant zaken reactie wierdduk liggen vele hoog bekend gesprek brengen gertjansegers overal stad familie burgemeester wilde afstand terecht wonen elk meest delen 1,5 hoeft huidige onderwijs feit rotterdam gevoel neemt vroeger jongeren raad informatie blijkt namelijk racistisch gebeuren voorbij deed maatregelen verwacht juni richting blanken nergens kreeg respect afrika turkije verschillende haag gevonden voelt klaver seizoen actie beleid mocht gedrag vertellen stond politici straat contact wellicht langer beeld zolang ziek genomen kosten lieve letterlijk feiten sterk lange collega kajsaollongren cda marcel makkelijk bijzonder juiste gegeven slechts zon tegenwoordig rechter betaald nieuwsblik bepaalde prachtige lodewijka wens gezet pakken moeite gelezen hopen voordat bekijk verplicht kwijt vorm pijn pieteromtzigt schrijven geweld belang vraagt teveel binnenkort kennen komende klinkt cijfers natuur behalve gegaan pvda plezier ondertussen trekken jongens mezelf energie houd kijkt hulp terzaketv welk economie waard extreem begrijpen ervaring niveau zomaar interessant zulke ondanks vaker voorstellen nogal burgers buurt zelfde geldt helft eind betere dochter hoogte voorouders koti dikke asscher slechte gevallen laviejanroos verdienen jndkgrf dieren gezicht franckentheo persoonlijk vreemd agenda rijk doden vrijdag zowel inwoners erop parool vandaan crisis bewust gevraagd trouw gebied jongen nieuwsblad_be harryhol rust angst speelt agenten fvdemocratie enorme samvanrooy zoekt ongeveer ingeborgvraagt jesse eruit kansen programma gehaald 2ekamertweets beschikbaar geschreven waarvan\n",
      "het een dat niet met te als aan bij zo al naar heeft hebben deze uit worden gaat hij eens zou kunnen gewoon jij vandaag moeten tot tegen nieuwe wij andere zich nederland tijd zal komen anders zie willen laten racisme bent telegraaf eigen onder beter niets zonder keer land krijgen leven zij weten staan lijkt mooie vanaf natuurlijk beetje elkaar volgens houden zitten vinden kinderen vooral blijven laatste gelijk werken mogen jesseklaver inderdaad twee blijft tussen gefeliciteerd per gezien probleem geleden vragen kunt gemaakt goedemorgen zo'n geertwilderspvv mogelijk d66 politie precies krijgt krijg terwijl helaas zoveel robjetten weinig gehad zullen nederlandse zeer geeft bezig tweede vast onderzoek dagen politiek hadden zin kamer debat media deel eindelijk betalen vindt moment linkse wilt manier verhaal piet blanke wachten woord straks plaats valt helpen gebruiken eerder afgelopen vol kans ouders punt extra zat vakantie overheid vrij weken alsof nederlanders hoeveel stemmen landen geworden zoek kleine enkel moest gezegd woorden rond volk oude verleden ketikoti trouwens reden partijen praten problemen leren druk zwart meteen groen vond zorgen lopen gratis noemen zag blijf vergeten politieke hopelijk beginnen waarschijnlijk slaven stoppen minister heen inmiddels volkskrant spelen hoofd dezelfde boven daarna gebruikt houdt overigens fout samenleving kleur joostniemoller direct begrijp rtlnieuws europa lectrr gebeurt ogen hoort naast vanwege proberen regen nporadio gehoord vrijheid bericht tja groningen kopen sturen iedere voorbeeld vader vrienden nederlands website werden harte ruimte kennis eerlijk kabinet opnieuw congo bedrijven stellen erbij pvv fvd keuze betekent waarin jonge vallen volledig verschil basis ervan cdavandaag oplossing ewindt vacature sociale gekregen bevolking daarmee spreken sowieso luisteren slavernijverleden uiteraard zoiets regels voelen handen betreft cultuur schuld stuur dragen hln_be zwaar koning enorm bijvoorbeeld ineens helpt rijden minuten uiteindelijk kimboon bestaan loopt klm trein kent mond chrisaalberts wind steun blank akwasi kiezen zoon advies rol waarheid veranderen grond stap vrije dicht maurice bedrijf op1 duitsland racistische 2e tijden leggen zaak echter destandaard motie avond genieten fiets viruswaanzin coronacrisis daarvoor gekomen meerdere baan ontvangen moeva vervolgens gezond situatie ewdevlieger reageren rekening bewijs geloven kost vieren doel democratie coronavirus volgers groter begonnen meneer baudet macht keti dagelijks alvast de_nva zjosdekker verkiezingen vertrouwen vier verkeerde muziek meestal systeem volgend licht bouwen prijs maatschappij plaatsen gerard halve bron verstand roepen ervoor verboden noemt ananninga voorkomen dankzij lid hoge kracht gesproken taal 020 bellen biomassa gevolgen samenwerking miljard lucht waarbij verantwoordelijk belangrijke erikmouthaanrtl voeren midden afschaffing tip gezondheid jarige stukje lijst sluiten\n"
     ]
    }
   ],
   "source": [
    "outFile = open(\"tmp.txt\",\"w\")\n",
    "print(\"track=\",end=\"\",file=outFile)\n",
    "print(\",\".join([selected[i] for i in range(0,len(selected)) if i % 4 == 0 or i % 4 == 3]),file=outFile)\n",
    "print(\"track=\",end=\"\",file=outFile)\n",
    "print(\",\".join([selected[i] for i in range(0,len(selected)) if i % 4 == 1 or i % 4 == 2]),file=outFile)\n",
    "outFile.close()\n",
    "print(\" \".join([selected[i] for i in range(0,len(selected)) if i % 4 == 0 or i % 4 == 3]))\n",
    "print(\" \".join([selected[i] for i in range(0,len(selected)) if i % 4 == 1 or i % 4 == 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200711-01.out.gz\n"
     ]
    }
   ],
   "source": [
    "tweetsTextCatNew = getTweets(filePattern=\"20200711\",dataDir=DATADIRCOVERAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912 vast\n",
      "0.85 nieuw\n",
      "0.947 vrouwen\n",
      "0.917 woord\n",
      "0.926 zat\n",
      "0.935 ter\n",
      "0.895 idd\n",
      "0.941 zag\n",
      "0.941 reactie\n",
      "0.931 gesprek\n",
      "0.929 wilde\n",
      "0.929 gevoel\n",
      "0 congo\n",
      "0.917 sowieso\n",
      "0.929 cultuur\n",
      "0.944 bestaan\n",
      "0.889 trein\n",
      "0.938 mond\n",
      "0.923 waarheid\n",
      "0.933 macht\n",
      "0 zjosdekker\n",
      "0 asscher\n",
      "0.923 licht\n",
      "0.909 vandaan\n",
      "0 ananninga\n",
      "0 afschaffing\n",
      "0.857 tip\n",
      "0 2ekamertweets\n",
      "0.909 waarvan\n"
     ]
    }
   ],
   "source": [
    "for token in selected:\n",
    "    coverageDutchScore = coverageDutch(token,tweetsTextCatNew)\n",
    "    if coverageDutchScore < 0.95:\n",
    "        print(round(coverageDutchScore,3),token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
