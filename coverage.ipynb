{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage tests for collected tweets\n",
    "\n",
    "Estimate what percentage of Dutch tweets are collected by twiqs.nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/erikt/projects/puregome/data/text/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDSTR = \"id_str\"\n",
    "INREPLYTOSTATUSIDSTR = \"in_reply_to_status_id_str\"\n",
    "\n",
    "def getReplyPercentage(filePattern,filePatternReference):\n",
    "    files = sorted(os.listdir(DATADIR))\n",
    "    targetFiles = {}\n",
    "    counter = 0\n",
    "    for inFileName in files:\n",
    "        if re.search(filePattern,inFileName):\n",
    "            counter += 1\n",
    "            df = pd.read_csv(DATADIR+inFileName,dtype={INREPLYTOSTATUSIDSTR:object})\n",
    "            counter += len(df)\n",
    "            for idStr in df[INREPLYTOSTATUSIDSTR]:\n",
    "                if type(idStr) == type(\"abc\"):\n",
    "                    targetFiles[idStr] = False\n",
    "    for inFileName in files:\n",
    "        if re.search(filePatternReference,inFileName):\n",
    "            df = pd.read_csv(DATADIR+inFileName,dtype={IDSTR:object})\n",
    "            for idStr in df[IDSTR]: \n",
    "                if idStr in targetFiles: targetFiles[idStr] = True\n",
    "            squeal(inFileName)\n",
    "    squeal(\"\")\n",
    "    return(len([x for x in targetFiles if targetFiles[x]]),len(targetFiles),counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePattern = \"20200609\"\n",
    "filePatternReference = \"202006\"\n",
    "lenPart,lenAll,counter = getReplyPercentage(filePattern,filePatternReference)\n",
    "print(\"target date: {0}; reference: {1}; percentage: {2}%; total count: {3}\".format(filePattern,filePatternReference,\\\n",
    "                                                                                   round(100*lenPart/lenAll,1),counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePattern = \"20200610\"\n",
    "lenPart,lenAll,counter = getReplyPercentage(filePattern,filePatternReference)\n",
    "print(\"target date: {0}; reference: {1}; percentage: {2}%; total count: {3}\".format(filePattern,filePatternReference,\\\n",
    "                                                                                   round(100*lenPart/lenAll,1),counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePattern = \"20200611\"\n",
    "lenPart,lenAll,counter = getReplyPercentage(filePattern,filePatternReference)\n",
    "print(\"target date: {0}; reference: {1}; percentage: {2}%; total count: {3}\".format(filePattern,filePatternReference,\\\n",
    "                                                                                   round(100*lenPart/lenAll,1),counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109099"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILEPATTERN = \"202006\"\n",
    "TEXT = \"text\"\n",
    "BASELEXICON = set(topTokens100 + topTokens200 + topTokens300 + topTokens400)\n",
    "ALLCOUNT = 596893 # 5623571\n",
    "LEFT200 = 61599\n",
    "LEFT100 = 80258 # 349598\n",
    "LEFT200100 = 43622 # 179089\n",
    "LEFT300200100 = 34583 # 130887\n",
    "LEFT400300200100 = 29528 # 109099\n",
    "\n",
    "def getTweets():\n",
    "    files = sorted(os.listdir(DATADIR))\n",
    "    tweets = {}\n",
    "    for inFileName in files:\n",
    "        if re.search(FILEPATTERN,inFileName):\n",
    "            squeal(inFileName)\n",
    "            df = pd.read_csv(DATADIR+inFileName)\n",
    "            for text in df[TEXT]:\n",
    "                text = re.sub(r\"\\\\n\",\" \",text.lower())\n",
    "                text = re.sub(r\"[#@]\",\" \",text)\n",
    "                tweets[text] = True\n",
    "    return(tweets)\n",
    "\n",
    "# tweets = getTweets()\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "frequencies = {}\n",
    "processedTweetCount = 0\n",
    "toBeDeleted = []\n",
    "counter = 0\n",
    "for text in tweets.keys():\n",
    "    counter += 1\n",
    "    if counter%10000 == 0: squeal(str(counter)+\"/\"+str(len(tweets)))\n",
    "    tokens = set(tokenizer.tokenize(text.lower()))\n",
    "    if len(BASELEXICON.intersection(tokens)) > 0:\n",
    "        toBeDeleted.append(text)\n",
    "    else:\n",
    "        processedTweetCount += 1\n",
    "        for token in tokens:\n",
    "            if token in frequencies: frequencies[token] += 1\n",
    "            else: frequencies[token] = 1\n",
    "for text in toBeDeleted: del(tweets[text])\n",
    "squeal()\n",
    "processedTweetCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0000,1,10,11,12,18,19,2,20,2020,2020-06-,3,4,5,6,7,71,8,9,:(,:),<3,a,a1,a2,aan,af,al,alle,alleen,allemaal,alles,als,altijd,alweer,ameen,amsterdam,an,and,b,baby,bark,bedankt,beetje,beke,ben,best,beter,beterschap,biep,bij,bijna,black,blonde,boep,buiten,by,c,code,corona,da,daar,dag,dan,daniel,dank,dankje,dankjewel,dat,de,den,deze,die,dit,do,doe,doen,doet,door,dus,e,echt,ee,een,eens,eerst,eerste,eindelijk,en,er,erg,es,et,even,ewdevlieger,ff,fijn,fijne,for,foto,ga,gaan,gaat,ge,gecondoleerd,gedaan,geen,geertwilderspvv,gefeliciteerd,gelijk,gelukkig,geniet,geweldig,gewoon,gezellig,gij,goed,goede,goedemorgen,goeie,goeiemorgen,graag,gwn,h,haar,haattweetje,had,haha,hahaha,hahahah,hahahaha,hahahahah,hahahahaha,hahahahahaha,halsema,he,heb,hebben,heeft,heel,heerlijk,hele,helemaal,help,herkenbaar,het,hi,hier,hij,hoe,hoezo,hoop,hoor,hun,hè,i,ie,iedereen,iemand,iets,ig,ik,im,in,inderdaad,ingeborgvraagt,is,ja,jaa,jaar,jazeker,je,jij,jndkgrf,joonie,joostniemoller,jou,jullie,k,ka,kan,kangen,ke,kijk,kijken,klaar,klopt,km,komen,komt,kunnen,kut,kween,laat,lang,lekker,letsel,leuk,leuke,links,m,maak,maakt,maam,maar,maken,man,me,mee,meer,mensen,met,mij,mijn,minpres,misschien,mm,moet,moeten,mood,mooi,mooie,morgen,my,n,na,naar,natuurlijk,ne,nederland,nee,nemen,net,netflixlifee,ni,nie,niemand,niet,nieuw,nieuwe,nieuws,niks,no,nog,nooit,nos,nou,nowplaying,nu,nvm,o,oeps,of,oh,ok,om,omg,on,onder,ons,onze,oof,ook,op,open,over,p2000,pfft,prachtig,queen,rit,rotterdam,rt,s,se,shet,slaap,smakelijk,snel,so,staat,stan,sterkte,stop,super,t,te,teen,tegen,telegraaf,ter,terug,the,thuis,tijd,to,toch,toe,top,tot,tsla,tuig,tuurlijk,tweet,twitter,tz,u,uit,uiteraard,update,utrecht,uur,uw,v,vacature,van,vandaag,veel,ver,via,volgende,voor,vreselijk,vroom,vs,waar,waarom,wanneer,was,wassup,wat,wauw,we,weer,weet,weg,wel,welke,welkom,werk,wet,what,wie,wierdduk,wij,wil,wind,wolf,woof,worden,wordt,wtaf,wtf,x,xxx,yes,you,zal,ze,zeer,zeg,zegt,zeker,zelf,zie,zijn,zo,zonder,zou,🍀,🏻,🏼,👇,👍,💋,💕,💚,💜,🔥,🔴,😁,😂,😅,😉,😊,😍,😎,😔,😘,😡,😭,😳,🙄,🙏,🤔,🤗,🤣,🥰,🥺,\n"
     ]
    }
   ],
   "source": [
    "for token in sorted(BASELEXICON): print(token,end=\",\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedFrequencies = {k:frequencies[k] for k in sorted(frequencies.keys(),key=lambda k:frequencies[k],reverse=True)}\n",
    "topTokens500 = [k for k in sortedFrequencies.keys() if re.search(r\"[a-z0-9]\",k) or \\\n",
    "                                                       (len(k) > 1 and k != \"..\" and k != \"...\" or\n",
    "                                                       (len(k) == 1 and ord(k) >= 127000 and ord(k) < 130000))][0:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
