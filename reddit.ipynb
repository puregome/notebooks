{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Reddit posts\n",
    "\n",
    "Reddit threads have been collected with the script `get_subreddit_ids.py` and stored in files named `submissions_ids_ThreadName.txt`. The IDs of the Megathread have been collected manually. Next, subreddit posts have been collected with the script `coronamessagesnl.py` and stored in the directory `downloads`. Threads from different downloads directories have been combined with the script `combineRedditPosts.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import pipes\n",
    "import re\n",
    "import sys\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import clear_output\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIRIN = \"../data/reddit/downloads/\"\n",
    "DATADIRTEXT = \"../data/reddit/text/\"\n",
    "DATEFORMATOUT = \"%Y%m%d-%H\"\n",
    "SUBREDDIT = \"subreddit\"\n",
    "CREATED = \"created\"\n",
    "ID = \"id\"\n",
    "AUTHOR = \"author\"\n",
    "BODY = \"body\"\n",
    "PARENT = \"parent\"\n",
    "FILESUFFIX = \".out.gz\"\n",
    "IDSTR = \"id_str\"\n",
    "REPLYID = \"in_reply_to_status_id_str\"\n",
    "USER = \"user\"\n",
    "VERIFIED = \"verified\"\n",
    "TEXT = \"text\"\n",
    "DELETED = \"[deleted]\"\n",
    "REMOVED = \"[removed]\"\n",
    "NEWLINE = \" [NL] \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDateString(date):\n",
    "    return(datetime.datetime.strftime(datetime.datetime.fromtimestamp(date),DATEFORMATOUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    text = re.sub(r\"\\n\",NEWLINE,re.sub(r\"\\r\",NEWLINE,text))\n",
    "    text = re.sub(r\"https://\\S+\",\"\",text)\n",
    "    text = re.sub(r\"\\s+\",\" \",text)\n",
    "    text = text.strip()\n",
    "    return(text)\n",
    "\n",
    "def tokenize(text):\n",
    "    return(\" \".join(TweetTokenizer().tokenize(text)))\n",
    "\n",
    "def preprocess(text):\n",
    "    return(tokenize(cleanup(text)).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language identification with langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL = \"nl\"\n",
    "DE = \"de\"\n",
    "AF = \"af\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all posts from downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084 61372\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "files = sorted(os.listdir(DATADIRIN))\n",
    "for i in range(0,len(files)):\n",
    "    inFileName = files[i]\n",
    "    squeal(\" \".join([str(i),str(len(posts)),inFileName]))\n",
    "    try:\n",
    "        df = pd.read_csv(DATADIRIN+inFileName)\n",
    "    except:\n",
    "        next\n",
    "    for j in range(0,len(df)):\n",
    "        date = df.iloc[j][CREATED]\n",
    "        subReddit = df.iloc[j][SUBREDDIT]\n",
    "        idStr = subReddit+\"_\"+df.iloc[j][ID]\n",
    "        parent = subReddit+\"_\"+df.iloc[j][PARENT].split(\"_\")[1]\n",
    "        user = df.iloc[j][AUTHOR]\n",
    "        text = cleanup(df.iloc[j][BODY])\n",
    "        if text == DELETED or text == REMOVED: continue\n",
    "        preprocessedText = preprocess(text)\n",
    "        language = langid.classify(preprocessedText)[0]\n",
    "        if language in [NL,AF,DE]:\n",
    "            posts.append((makeDateString(date),idStr,parent,user,None,text))\n",
    "squeal(\" \".join([str(i),str(len(posts))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store all posts in hour files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61371\n"
     ]
    }
   ],
   "source": [
    "verified = \"\"\n",
    "dataPerHour = {}\n",
    "monthCounts = {}\n",
    "for i in range(0,len(posts)):\n",
    "    if i%1000 == 0: squeal(i)\n",
    "    post = posts[i]\n",
    "    date = post[0]\n",
    "    idStr = post[1]\n",
    "    replyId = post[2]\n",
    "    user = post[3]\n",
    "    text = cleanup(post[5])\n",
    "    if not date in dataPerHour: dataPerHour[date] = []\n",
    "    data = {IDSTR:idStr,REPLYID:replyId,USER:user,VERIFIED:verified,TEXT:text}\n",
    "    if not data in dataPerHour[date]: \n",
    "        dataPerHour[date].append(data)\n",
    "        month = date[0:6]\n",
    "        if not month in monthCounts: monthCounts[month] = 0\n",
    "        monthCounts[month] += 1\n",
    "squeal(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202002: 5\n",
      "202003: 27996\n",
      "202004: 11938\n",
      "202005: 6442\n",
      "202006: 3214\n",
      "202007: 2929\n",
      "202008: 4723\n",
      "202009: 1484\n"
     ]
    }
   ],
   "source": [
    "for month in sorted(monthCounts.keys()):\n",
    "    print(f\"{month}: {monthCounts[month]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200915-12\n"
     ]
    }
   ],
   "source": [
    "for date in sorted(dataPerHour.keys()):\n",
    "    squeal(date)\n",
    "    outFileName = DATADIRTEXT+date+FILESUFFIX\n",
    "    pd.DataFrame(dataPerHour[date]).to_csv(outFileName,index=False,compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize number of posts per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileNameToHourString(fileName):\n",
    "    return(fileName[0:11])\n",
    "\n",
    "dataPerHour = {}\n",
    "inFileNames = sorted(os.listdir(DATADIRTEXT))\n",
    "for inFileName in inFileNames:\n",
    "    squeal(inFileName)\n",
    "    hourString = fileNameToHourString(inFileName)\n",
    "    df = pd.read_csv(DATADIRTEXT+inFileName)\n",
    "    dataPerHour[hourString] = list(df.T.to_dict(orient=\"dict\").values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsDays = []\n",
    "for post in posts:\n",
    "    post = list(post)\n",
    "    post[0] = post[0][:8]\n",
    "    postsDays.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(postsDays)\n",
    "groups = df.groupby(0).groups\n",
    "dates = {f:len(groups[f]) for f in groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEFORMATDAY = \"%Y%m%d\"\n",
    "PLOTFILENAME = \"frequency-reddit.png\"\n",
    "UNTILDATE = \"20200901\"\n",
    "\n",
    "x = [datetime.datetime.strptime(d,DATEFORMATDAY) for d in dates if d < UNTILDATE]\n",
    "y = [dates[d] for d in dates if d < UNTILDATE]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "plt.plot_date(x,y,fmt=\"-\")\n",
    "plt.xlabel(\"day/month\")\n",
    "plt.ylabel(\"count per day\")\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "plt.title(\"Dutch Reddit posts on the COVID-19 pandemic per day\")\n",
    "plt.savefig(PLOTFILENAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize query words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = \"topic\"\n",
    "QUERYLIST = (\"corona covid mondkapje rivm blijfthuis houvol huisarts flattenthecurve \"+TOPIC).split()\n",
    "QUERYTOPIC = \"corona|covid|mondkapje|rivm|blijfthuis|houvol|huisarts|flattenthecurve\"\n",
    "TOTAL = \"total\"\n",
    "\n",
    "def makeDateFromHour(hour):\n",
    "    return(hour[0:8])\n",
    "\n",
    "queryCounts ={}\n",
    "for query in QUERYLIST:\n",
    "    queryCounts[query] = {}\n",
    "    querySearch = query\n",
    "    if query == TOPIC: querySearch = QUERYTOPIC\n",
    "    for post in posts:\n",
    "        text = post[5]\n",
    "        if re.search(querySearch,text,flags=re.IGNORECASE):\n",
    "            date = makeDateFromHour(post[0])\n",
    "            if not date in queryCounts[query]: queryCounts[query][date] = 0\n",
    "            queryCounts[query][date] += 1\n",
    "\n",
    "queryCounts[TOTAL] = {}\n",
    "for post in posts:\n",
    "    date = makeDateFromHour(post[0])\n",
    "    if not date in queryCounts[TOTAL]: queryCounts[TOTAL][date] = 0\n",
    "    queryCounts[TOTAL][date] += 1\n",
    "\n",
    "totals = {}\n",
    "for query in QUERYLIST+[TOTAL]:\n",
    "    totals[query] = sum(queryCounts[query].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingAverage(numberList,size):\n",
    "    newList = []\n",
    "    for i in range(0,len(numberList)):\n",
    "        numberUsed = 1\n",
    "        newList.append(numberList[i])\n",
    "        for j in range(1,size):\n",
    "            if i-j >= 0:\n",
    "                newList[i] += numberList[i-j]\n",
    "                numberUsed += 1\n",
    "        newList[i] /= numberUsed\n",
    "    return(newList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEEKSIZE = 7\n",
    "\n",
    "queryCounts7 = {}\n",
    "for query in QUERYLIST+[TOTAL]:\n",
    "    try:\n",
    "        sortedKeys = list(sorted(queryCounts[query].keys()))\n",
    "        sortedValues = [queryCounts[query][d] for d in sortedKeys]\n",
    "        newSortedValues = movingAverage(sortedValues,WEEKSIZE)\n",
    "        queryCounts7[query] = {sortedKeys[i]:newSortedValues[i] for i in range(0,len(sortedKeys))}\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITDAYSSKIPPED = 0\n",
    "PLOTFILENAME = \"term-frequency-reddit.png\"\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "for query in (TOPIC+\" corona covid mondkapje rivm\").split():\n",
    "    try:\n",
    "        x = [datetime.datetime.strptime(d,DATEFORMATDAY) for d in queryCounts7[query] if d < UNTILDATE][INITDAYSSKIPPED:]\n",
    "        y = [queryCounts7[query][d] for d in queryCounts7[query] if d < UNTILDATE][INITDAYSSKIPPED:]\n",
    "        plt.plot_date(x,y,fmt=\"-\",label=f\"{query} ({totals[query]})\")\n",
    "    except: pass\n",
    "plt.xlabel(\"day/month\")\n",
    "plt.ylabel(\"count per day\")\n",
    "plt.title(f\"Terms in Dutch Reddit posts (average over {WEEKSIZE} days)\")\n",
    "plt.legend()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "plt.savefig(PLOTFILENAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFCOMBINEDITEMS = 7\n",
    "\n",
    "def summarizeXY(x,y,nbrOfCombinedItems=NBROFCOMBINEDITEMS):\n",
    "    summarizedX = []\n",
    "    summarizedY = []\n",
    "    yCombined = 0\n",
    "    for i in range(0,len(y)):\n",
    "        yCombined += y[i]\n",
    "        if (i+1)%nbrOfCombinedItems == 0:\n",
    "            summarizedX.append(x[i])\n",
    "            summarizedY.append(yCombined)\n",
    "            yCombined = 0\n",
    "    if len(y)%nbrOfCombinedItems != 0:\n",
    "        summarizedX.append(x[i])\n",
    "        summarizedY.append(yCombined)\n",
    "    return(summarizedX,summarizedY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITDAYSSKIPPED = 0\n",
    "PLOTFILENAME = \"term-percentages-reddit.png\"\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "for query in (TOPIC+\" corona covid mondkapje rivm\").split():\n",
    "    try:\n",
    "        x = [datetime.datetime.strptime(d,DATEFORMATDAY) for d in queryCounts7[query]][INITDAYSSKIPPED:]\n",
    "        y = [queryCounts[query][d]/queryCounts[TOTAL][d] for d in queryCounts[query]][INITDAYSSKIPPED:]\n",
    "        summarizedX,summarizedY = summarizeXY(x,y)\n",
    "        plt.plot_date(summarizedX,summarizedY,fmt=\"-\",label=f\"{query} ({totals[query]})\")\n",
    "    except: pass\n",
    "plt.xlabel(\"day/month\")\n",
    "plt.ylabel(\"count per day\")\n",
    "plt.title(f\"Percentage of terms in Dutch Reddit posts (per week)\")\n",
    "plt.legend()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "plt.savefig(PLOTFILENAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
