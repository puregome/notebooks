{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo analysis\n",
    "\n",
    "Estimate the geographical region of tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToLower(listOfStrings):\n",
    "    return([x.lower() for x in listOfStrings])\n",
    "\n",
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BELGIUMLIST = \"BelgiÃ« Belgique Belgium Belgia Belgio Belgien belgium Vlaanderen Belgie ðŸ‡§ðŸ‡ª\".split()\n",
    "BELGIUMLIST.extend([])\n",
    "BELGIUMLIST = listToLower(BELGIUMLIST)\n",
    "NETHERLANDSLIST = \"Nederland Netherlands Holanda NederlÃ¤nderna Nederlandene Pays-Bas ðŸ‡³ðŸ‡± Holland NL nederland netherlands netherland\".split()\n",
    "NETHERLANDSLIST.extend([\"The Netherlands\",\"Pays Bas\",\"Holanda (PaÃ­ses Baixos)\",\"Paesi Bassi\",\"the Netherlands\",\"the netherlands\",\n",
    "                       \"Nederland \",\"The Netherlands \",\"Kingdom of the Netherlands\"])\n",
    "NETHERLANDSLIST = listToLower(NETHERLANDSLIST)\n",
    "BELGIUM = \"Belgium\"\n",
    "NETHERLANDS = \"Netherlands\"\n",
    "OTHER = \"Other\"\n",
    "CITIES = \"cities\"\n",
    "REGIONS = \"regions\"\n",
    "COUNTRIES = \"countries\"\n",
    "LOCATION = \"location\"\n",
    "REGION = \"region\"\n",
    "MUNICIPALITY = \"municipality\"\n",
    "COUNTRY = \"country\"\n",
    "NIELSEN = \"nielsen\"\n",
    "USER = \"user\"\n",
    "USERID = \"userid\"\n",
    "TWEETCOUNT = \"tweetcount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources of municipality names:\n",
    "* https://nl.wikipedia.org/wiki/Tabel_van_Nederlandse_gemeenten\n",
    "* https://nl.wikipedia.org/wiki/Lijst_van_gemeenten_in_het_Vlaams_Gewest\n",
    "* https://nl.wikipedia.org/wiki/Lijst_van_gemeenten_in_het_Waals_Gewest\n",
    "* https://nl.wikipedia.org/wiki/Lijst_van_gemeenten_in_het_Brussels_Hoofdstedelijk_Gewest\n",
    "* https://iisg.amsterdam/en/hsn/data/place-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONFILE = \"regions.csv\"\n",
    "MUNICIPALITYFILE = \"municipalities.csv\"\n",
    "TOPONYMFILE = \"ToponymsNL1812-2012SpatioTemporal.txt\"\n",
    "MUNICIPALITYFILE2 = \"MunicipalitiesNL1812-2012SpatioTemporeel.txt\"\n",
    "MUNICIPALITY2 = \"Municipality\"\n",
    "PROVINCE = \"Province\"\n",
    "TOPONYM = \"Toponym (city,town,village,hamlet)\"\n",
    "MINPARTLEN = 5\n",
    "\n",
    "class nielsen:\n",
    "    def getNielsenLocation(self,location):\n",
    "        location = location.lower().strip()\n",
    "        if location in self.cache: \n",
    "            return(self.cache[location])\n",
    "        if location in NETHERLANDSLIST:\n",
    "            self.cache[location] = NETHERLANDS\n",
    "            return(self.cache[location])\n",
    "        if location in BELGIUMLIST:\n",
    "            self.cache[location] = BELGIUM\n",
    "            return(self.cache[location])\n",
    "        if location in self.municipalitiesLowered: \n",
    "            self.cache[location] = self.municipalitiesLowered[location]\n",
    "            return(self.cache[location])\n",
    "        if location in self.regionsLowered: \n",
    "            self.cache[location] = self.regionsLowered[location]\n",
    "            return(self.cache[location])\n",
    "        for splitChar in [\",\",\" \",\"-\"]:\n",
    "            fields = location.split(splitChar)\n",
    "            for i in range(1,len(fields)):\n",
    "                locationPart = (splitChar.join(fields[:i])).strip()\n",
    "                if len(locationPart) >= MINPARTLEN:\n",
    "                    if locationPart in self.municipalitiesLowered: \n",
    "                        self.cache[location] = self.municipalitiesLowered[locationPart]\n",
    "                        return(self.cache[location])\n",
    "                    if locationPart in self.regionsLowered: \n",
    "                        self.cache[location] = self.regionsLowered[locationPart]\n",
    "                        return(self.cache[location])\n",
    "                locationPart = (splitChar.join(fields[-i:])).strip()\n",
    "                if len(locationPart) >= MINPARTLEN:\n",
    "                    if locationPart in self.municipalitiesLowered: \n",
    "                        self.cache[location] = self.municipalitiesLowered[locationPart]\n",
    "                        return(self.cache[location])\n",
    "                    if locationPart in self.regionsLowered: \n",
    "                        self.cache[location] = self.regionsLowered[locationPart]\n",
    "                        return(self.cache[location])\n",
    "        for splitChar in [\",\",\" \",\"-\"]:\n",
    "            fields = location.split(splitChar)\n",
    "            for i in range(1,len(fields)):\n",
    "                locationPart = (splitChar.join(fields[:i])).strip()\n",
    "                if len(locationPart) >= MINPARTLEN:\n",
    "                    if locationPart in NETHERLANDSLIST: \n",
    "                        self.cache[location] = NETHERLANDS\n",
    "                        return(self.cache[location])\n",
    "                    if locationPart in BELGIUMLIST: \n",
    "                        self.cache[location] = BELGIUM\n",
    "                        return(self.cache[location])\n",
    "                locationPart = (splitChar.join(fields[-i:])).strip()\n",
    "                if len(locationPart) >= MINPARTLEN:\n",
    "                    if locationPart in NETHERLANDSLIST: \n",
    "                        self.cache[location] = NETHERLANDS\n",
    "                        return(self.cache[location])\n",
    "                    if locationPart in BELGIUMLIST: \n",
    "                        self.cache[location] = BELGIUM\n",
    "                        return(self.cache[location])\n",
    "        if re.search(\"nether\",location,flags=re.IGNORECASE) or re.search(\"neder\",location,flags=re.IGNORECASE):\n",
    "            self.cache[location] = NETHERLANDS\n",
    "            return(self.cache[location])\n",
    "        if re.search(\"belgi\",location,flags=re.IGNORECASE):\n",
    "            self.cache[location] = BELGIUM\n",
    "            return(self.cache[location])\n",
    "        self.cache[location] = location\n",
    "        return(self.cache[location])\n",
    "    \n",
    "    def readCsvFile(inFileName): return(pd.read_csv(inFileName))\n",
    "    \n",
    "    def getNielsenPerRegion(df,fieldName):\n",
    "        return({df.iloc[i][fieldName].lower():\",\".join([df.iloc[i][COUNTRY],df.iloc[i][NIELSEN]]) \n",
    "                for i in range(0,len(df))})\n",
    "    \n",
    "    def readToponyms(inFileName,regionsLowered,municipalitiesLowered):\n",
    "        df = pd.read_csv(inFileName,sep=\";\")\n",
    "        for i in range(0,len(df)):\n",
    "            region = df.iloc[i][PROVINCE].lower()\n",
    "            toponym = df.iloc[i][TOPONYM].lower()\n",
    "            municipality = df.iloc[i][MUNICIPALITY2].lower()\n",
    "            if region in regionsLowered:\n",
    "                if not toponym in municipalitiesLowered:\n",
    "                    municipalitiesLowered[toponym] = regionsLowered[region]\n",
    "                if not municipality in municipalitiesLowered:\n",
    "                    municipalitiesLowered[municipality] = regionsLowered[region]\n",
    "        return(municipalitiesLowered)\n",
    "\n",
    "    def readMunicipalities(inFileName,regionsLowered,municipalitiesLowered):\n",
    "        df = pd.read_csv(inFileName,sep=\";\")\n",
    "        for i in range(0,len(df)):\n",
    "            region = df.iloc[i][PROVINCE].lower()\n",
    "            municipality = df.iloc[i][MUNICIPALITY].lower()\n",
    "            if region in regionsLowered:\n",
    "                if not municipality in municipalitiesLowered:\n",
    "                    municipalitiesLowered[municipality] = regionsLowered[region]\n",
    "        return(municipalitiesLowered)\n",
    "\n",
    "    cache = {}\n",
    "    municipalities = readCsvFile(MUNICIPALITYFILE)\n",
    "    municipalitiesLowered = getNielsenPerRegion(municipalities,MUNICIPALITY)\n",
    "    regions = readCsvFile(REGIONFILE)\n",
    "    regionsLowered = getNielsenPerRegion(regions,REGION)\n",
    "    municipalitiesLowered = readToponyms(TOPONYMFILE,regionsLowered,municipalitiesLowered)\n",
    "    municipalitiesLowered = readMunicipalities(MUNICIPALITYFILE2,regionsLowered,municipalitiesLowered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count tweets per user (takes several minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200831-23.out.gz\n"
     ]
    }
   ],
   "source": [
    "TWEETTEXTDIR = \"../data/text/\"\n",
    "FILEPATTERN = \"202008\"\n",
    "\n",
    "users = {}\n",
    "fileList = sorted(os.listdir(TWEETTEXTDIR))\n",
    "for inFileName in fileList:\n",
    "    if re.search(FILEPATTERN,inFileName):\n",
    "        squeal(inFileName)\n",
    "        usersInFile = pd.read_csv(TWEETTEXTDIR+inFileName).groupby(USER).groups\n",
    "        for user in usersInFile:\n",
    "            if not user in users: users[user] = 0\n",
    "            users[user] += len(usersInFile[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 20314042 tweets from 1280839 users\n"
     ]
    }
   ],
   "source": [
    "print(f\"read {sum([users[user] for user in users])} tweets from {len(users)} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILENAME = \"/home/erikt/tmp/locations-202008-dutch.txt\"\n",
    "\n",
    "inFile = open(INFILENAME,\"r\")\n",
    "locations = {}\n",
    "nielsenClass = nielsen()\n",
    "for line in inFile:\n",
    "    fields = line.strip().split(\",\")\n",
    "    userId = fields.pop(-1)\n",
    "    screenName = fields.pop(-1)\n",
    "    country = \",\".join(fields)\n",
    "    while re.search(\"^-,\",country): country = re.sub(\"^-,\",\"\",country)\n",
    "    while re.search(\",-$\",country): country = re.sub(\",-$\",\"\",country)\n",
    "    if screenName in users:\n",
    "        nielsenDistrict = nielsenClass.getNielsenLocation(country)\n",
    "        if nielsenDistrict in BELGIUMLIST: nielsenDistrict = BELGIUM\n",
    "        if nielsenDistrict in NETHERLANDSLIST: nielsenDistrict = NETHERLANDS\n",
    "        locations[screenName] = {NIELSEN:nielsenDistrict,COUNTRY:country,USERID:userId,TWEETCOUNT:users[screenName]}\n",
    "inFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show number of users with region information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Netherlands,Nielsen II': 44754,\n",
       " 'Netherlands': 37662,\n",
       " 'Netherlands,Nielsen IV': 36275,\n",
       " 'Netherlands,Nielsen I': 35482,\n",
       " 'Netherlands,Nielsen V': 23260,\n",
       " 'Belgium': 22433,\n",
       " 'Belgium,Nielsen II': 21247,\n",
       " 'Netherlands,Nielsen III': 17172,\n",
       " 'Belgium,Nielsen I': 13467,\n",
       " 'Belgium,Nielsen III': 6214,\n",
       " 'Belgium,Nielsen V': 1267,\n",
       " 'Belgium,Nielsen IV': 372}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nielsenDistricts = [locations[key][NIELSEN] for key in locations]\n",
    "groups = pd.DataFrame(nielsenDistricts).groupby(0).groups\n",
    "selected = {key:len(groups[key]) for key in sorted(groups.keys(),key=lambda k:len(groups[k]),reverse=True) \\\n",
    "                                 if re.search(\"Belgium|Netherlands\",key)}\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65000 Belgium (all users)\n",
      "194605 Netherlands (all users)\n"
     ]
    }
   ],
   "source": [
    "for country in[BELGIUM,NETHERLANDS]:\n",
    "    print(sum([selected[location] for location in selected if re.search(country,location)]),country+\" (all users)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show number of tweets with region information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601021 Netherlands,Nielsen II\n",
      "1954072 Netherlands\n",
      "1358055 Netherlands,Nielsen IV\n",
      "1575784 Netherlands,Nielsen I\n",
      "743604 Netherlands,Nielsen V\n",
      "729413 Belgium\n",
      "648275 Belgium,Nielsen II\n",
      "631854 Netherlands,Nielsen III\n",
      "381909 Belgium,Nielsen I\n",
      "138988 Belgium,Nielsen III\n",
      "56339 Belgium,Nielsen V\n",
      "3318 Belgium,Nielsen IV\n"
     ]
    }
   ],
   "source": [
    "tweetCounts = [locations[key][TWEETCOUNT] for key in locations]\n",
    "\n",
    "netherlandsTotal = 0\n",
    "belgiumTotal = 0\n",
    "for region in selected:\n",
    "    nbrOfTweets = 0\n",
    "    for thisId in groups[region]: nbrOfTweets += tweetCounts[thisId]\n",
    "    print(nbrOfTweets,region)\n",
    "    if re.search(NETHERLANDS,region): netherlandsTotal += nbrOfTweets\n",
    "    if re.search(BELGIUM,region): belgiumTotal += nbrOfTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7864390 Netherlands (all tweets)\n",
      "1958242 Belgium (all tweets)\n"
     ]
    }
   ],
   "source": [
    "print(netherlandsTotal,NETHERLANDS+\" (all tweets)\")\n",
    "print(belgiumTotal,BELGIUM+\" (all tweets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent unclassified locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nedeland': 5,\n",
       " 'annede eÄŸik kuleler': 1,\n",
       " 'Velp-Zuid beneden spoorlijn': 1,\n",
       " 'Kern Beneden-Leeuwen, West Maa': 1,\n",
       " 'Assenede/Eeklo/Gent': 1,\n",
       " 'Buitengebied Beneden-Leeuwen, ': 1,\n",
       " 'Hier beneden is het niet...': 1,\n",
       " 'San Benedetto del Tronto, Marc': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = \"nede\"\n",
    "\n",
    "countries = [locations[key][COUNTRY] for key in locations]\n",
    "countryTweets = {}\n",
    "for i in range(0,len(countries)):\n",
    "    nielsenDistrict = nielsenClass.getNielsenLocation(countries[i])\n",
    "    if not re.search(\"Nielsen\",nielsenDistrict) and nielsenDistrict != BELGIUM and nielsenDistrict != NETHERLANDS:\n",
    "        if not countries[i] in countryTweets: countryTweets[countries[i]] = 0\n",
    "        countryTweets[countries[i]] += 1 # tweets[i]\n",
    "{key:countryTweets[key] for key in sorted(countryTweets.keys(),key=lambda k:countryTweets[k],reverse=True) \n",
    "                        if re.search(QUERY,key,flags=re.IGNORECASE)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280839"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILENAME = \"locations.csv\"\n",
    "\n",
    "#locations = {}\n",
    "#for i in range(0,len(nielsenDistricts)):\n",
    "#    if re.search(f\"{NETHERLANDS}|{BELGIUM}\",nielsenDistricts[i]):\n",
    "#        locations[screenNames[i]] = {NIELSEN:nielsenDistricts[i],COUNTRY:countries[i]}\n",
    "pd.DataFrame(locations).T.to_csv(OUTFILENAME,index_label=\"screenname\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = {key:len(groups[key]) for key in sorted(groups.keys(),key=lambda k:len(groups[k]),reverse=True) \\\n",
    "                             if not re.search(\"Belgium|Netherlands\",key)}\n",
    "restTotal = sum([rest[key] for key in rest])\n",
    "print(restTotal)\n",
    "rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fasttext experiment per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELPREFIX = \"__label__\"\n",
    "LARGEINT = 9999999999\n",
    "TRAIN = \"TRAIN\"+str(int(random.random()*LARGEINT))\n",
    "TEST = \"TEST\"+str(int(random.random()*LARGEINT))\n",
    "VALIDATION = \"VALIDATION\"+str(int(random.random()*LARGEINT))\n",
    "\n",
    "trainFile = open(TRAIN,\"w\")\n",
    "testFile = open(TEST,\"w\")\n",
    "validationFile = open(VALIDATION,\"w\")\n",
    "validationData = []\n",
    "testData = []\n",
    "for i in range(0,round(len(countries)/10)):\n",
    "    print(LABELPREFIX+countries[i],texts[i],file=testFile)\n",
    "    testData.append(LABELPREFIX+countries[i]+\" \"+texts[i])\n",
    "for i in range(round(len(countries)/10),round(2*len(countries)/10)):\n",
    "    print(LABELPREFIX+countries[i],texts[i],file=validationFile)\n",
    "    validationData.append(LABELPREFIX+countries[i]+\" \"+texts[i])\n",
    "for i in range(round(2*len(countries)/10),len(countries)):\n",
    "    print(LABELPREFIX+countries[i],texts[i],file=trainFile)\n",
    "validationFile.close()\n",
    "testFile.close()\n",
    "trainFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in [10,20,50,100,200,300]:\n",
    "    for epoch in [10,20,50,100,200,300]:\n",
    "        for lr in [0.05,0.1,0.2]:\n",
    "            model = fasttext.train_supervised(TRAIN,dim=dim,epoch=epoch,lr=lr)\n",
    "            print(dim,epoch,lr,model.test(VALIDATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 10 0.05 (96576, 0.7760313121272365, 0.7760313121272365)\n",
    "10 10 0.1 (96576, 0.7733701954937044, 0.7733701954937044)\n",
    "10 10 0.2 (96576, 0.7715788601722995, 0.7715788601722995)\n",
    "10 20 0.05 (96576, 0.7695079522862823, 0.7695079522862823)\n",
    "10 20 0.1 (96576, 0.7672506626905236, 0.7672506626905236)\n",
    "10 20 0.2 (96576, 0.7629742379058979, 0.7629742379058979)\n",
    "10 50 0.05 (96576, 0.7603545394300861, 0.7603545394300861)\n",
    "10 50 0.1 (96576, 0.7594640490390987, 0.7594640490390987)\n",
    "10 50 0.2 (96576, 0.7574656229290921, 0.7574656229290921)\n",
    "10 100 0.05 (96576, 0.7555396785950961, 0.7555396785950961)\n",
    "10 100 0.1 (96576, 0.7547423790589795, 0.7547423790589795)\n",
    "10 100 0.2 (96576, 0.7534377070907886, 0.7534377070907886)\n",
    "10 200 0.05 (96576, 0.7507558813783963, 0.7507558813783963)\n",
    "10 200 0.1 (96576, 0.7494719184890656, 0.7494719184890656)\n",
    "10 200 0.2 (96576, 0.7495651093439364, 0.7495651093439364)\n",
    "10 300 0.05 (96576, 0.7471732107355865, 0.7471732107355865)\n",
    "10 300 0.1 (96576, 0.7471317925778661, 0.7471317925778661)\n",
    "10 300 0.2 (96576, 0.7491923459244533, 0.7491923459244533)\n",
    "20 10 0.05 (96576, 0.777884774685222, 0.777884774685222)\n",
    "20 10 0.1 (96576, 0.7735255135851558, 0.7735255135851558)\n",
    "20 10 0.2 (96576, 0.7726143141153081, 0.7726143141153081)\n",
    "20 20 0.05 (96576, 0.7678305168986084, 0.7678305168986084)\n",
    "20 20 0.1 (96576, 0.7667536447978794, 0.7667536447978794)\n",
    "20 20 0.2 (96576, 0.763823310139165, 0.763823310139165)\n",
    "20 50 0.05 (96576, 0.7601681577203446, 0.7601681577203446)\n",
    "20 50 0.1 (96576, 0.7599507123923128, 0.7599507123923128)\n",
    "20 50 0.2 (96576, 0.758169731610338, 0.758169731610338)\n",
    "20 100 0.05 (96576, 0.7558088966202783, 0.7558088966202783)\n",
    "20 100 0.1 (96576, 0.7542867793240556, 0.7542867793240556)\n",
    "20 100 0.2 (96576, 0.7545663518886679, 0.7545663518886679)\n",
    "20 200 0.05 (96576, 0.7506419814446653, 0.7506419814446653)\n",
    "20 200 0.1 (96576, 0.7496272365805169, 0.7496272365805169)\n",
    "20 200 0.2 (96576, 0.7499482273028496, 0.7499482273028496)\n",
    "20 300 0.05 (96576, 0.7481361829025845, 0.7481361829025845)\n",
    "20 300 0.1 (96576, 0.7469143472498343, 0.7469143472498343)\n",
    "20 300 0.2 (96576, 0.7488920642809808, 0.7488920642809808)\n",
    "50 10 0.05 (96576, 0.7768079025844931, 0.7768079025844931)\n",
    "50 10 0.1 (96576, 0.7724175778661365, 0.7724175778661365)\n",
    "50 10 0.2 (96576, 0.7727696322067594, 0.7727696322067594)\n",
    "50 20 0.05 (96576, 0.7678822895957588, 0.7678822895957588)\n",
    "50 20 0.1 (96576, 0.7673438535453942, 0.7673438535453942)\n",
    "50 20 0.2 (96576, 0.764775927766733, 0.764775927766733)\n",
    "50 50 0.05 (96576, 0.760696239231279, 0.760696239231279)\n",
    "50 50 0.1 (96576, 0.7589463220675944, 0.7589463220675944)\n",
    "50 50 0.2 (96576, 0.7583664678595096, 0.7583664678595096)\n",
    "50 100 0.05 (96576, 0.7560159874088801, 0.7560159874088801)\n",
    "50 100 0.1 (96576, 0.7537690523525513, 0.7537690523525513)\n",
    "50 100 0.2 (96576, 0.7543903247183565, 0.7543903247183565)\n",
    "50 200 0.05 (96576, 0.74879887342611, 0.74879887342611)\n",
    "50 200 0.1 (96576, 0.7493166003976143, 0.7493166003976143)\n",
    "50 200 0.2 (96576, 0.7503002816434725, 0.7503002816434725)\n",
    "50 300 0.05 (96576, 0.7481361829025845, 0.7481361829025845)\n",
    "50 300 0.1 (96576, 0.7482811464546058, 0.7482811464546058)\n",
    "50 300 0.2 (96576, 0.7503002816434725, 0.7503002816434725)\n",
    "100 10 0.05 (96576, 0.7770564115308151, 0.7770564115308151)\n",
    "100 10 0.1 (96576, 0.7752236580516899, 0.7752236580516899)\n",
    "100 10 0.2 (96576, 0.7721069416832339, 0.7721069416832339)\n",
    "100 20 0.05 (96576, 0.7670849900596421, 0.7670849900596421)\n",
    "100 20 0.1 (96576, 0.7645584824387012, 0.7645584824387012)\n",
    "100 20 0.2 (96576, 0.7649726640159046, 0.7649726640159046)\n",
    "100 50 0.05 (96576, 0.7614831842279656, 0.7614831842279656)\n",
    "100 50 0.1 (96576, 0.7600231941683234, 0.7600231941683234)\n",
    "100 50 0.2 (96576, 0.7591534128561962, 0.7591534128561962)\n",
    "100 100 0.05 (96576, 0.7554154241219351, 0.7554154241219351)\n",
    "100 100 0.1 (96576, 0.7544731610337972, 0.7544731610337972)\n",
    "100 100 0.2 (96576, 0.7547423790589795, 0.7547423790589795)\n",
    "100 200 0.05 (96576, 0.7503106361829026, 0.7503106361829026)\n",
    "100 200 0.1 (96576, 0.7503831179589132, 0.7503831179589132)\n",
    "100 200 0.2 (96576, 0.7509526176275679, 0.7509526176275679)\n",
    "100 300 0.05 (96576, 0.7479394466534128, 0.7479394466534128)\n",
    "100 300 0.1 (96576, 0.7476081013916501, 0.7476081013916501)\n",
    "100 300 0.2 (96576, 0.7490266732935719, 0.7490266732935719)\n",
    "200 10 0.05 (96576, 0.7748301855533466, 0.7748301855533466)\n",
    "200 10 0.1 (96576, 0.7721897779986746, 0.7721897779986746)\n",
    "200 10 0.2 (96576, 0.7729145957587806, 0.7729145957587806)\n",
    "200 20 0.05 (96576, 0.7685553346587144, 0.7685553346587144)\n",
    "200 20 0.1 (96576, 0.7664533631544069, 0.7664533631544069)\n",
    "200 20 0.2 (96576, 0.7651072730284957, 0.7651072730284957)\n",
    "200 50 0.05 (96576, 0.7612036116633533, 0.7612036116633533)\n",
    "200 50 0.1 (96576, 0.7594122763419483, 0.7594122763419483)\n",
    "200 50 0.2 (96576, 0.7585735586481114, 0.7585735586481114)\n",
    "200 100 0.05 (96576, 0.7555500331345262, 0.7555500331345262)\n",
    "200 100 0.1 (96576, 0.7531995526838966, 0.7531995526838966)\n",
    "200 100 0.2 (96576, 0.7537069251159708, 0.7537069251159708)\n",
    "200 200 0.05 (96576, 0.7505694996686547, 0.7505694996686547)\n",
    "200 200 0.1 (96576, 0.7487160371106694, 0.7487160371106694)\n",
    "200 200 0.2 (96576, 0.7502795725646123, 0.7502795725646123)\n",
    "200 300 0.05 (96576, 0.7476391650099403, 0.7476391650099403)\n",
    "200 300 0.1 (96576, 0.7474113651424784, 0.7474113651424784)\n",
    "200 300 0.2 (96576, 0.7491923459244533, 0.7491923459244533)\n",
    "300 10 0.05 (96576, 0.7755653578528827, 0.7755653578528827)\n",
    "300 10 0.1 (96576, 0.7753479125248509, 0.7753479125248509)\n",
    "300 10 0.2 (96576, 0.7723865142478462, 0.7723865142478462)\n",
    "300 20 0.05 (96576, 0.767312789927104, 0.767312789927104)\n",
    "300 20 0.1 (96576, 0.7669917992047713, 0.7669917992047713)\n",
    "300 20 0.2 (96576, 0.7659977634194831, 0.7659977634194831)\n",
    "300 50 0.05 (96576, 0.7603648939695162, 0.7603648939695162)\n",
    "300 50 0.1 (96576, 0.7593501491053678, 0.7593501491053678)\n",
    "300 50 0.2 (96576, 0.7592880218687873, 0.7592880218687873)\n",
    "300 100 0.05 (96576, 0.755280815109344, 0.755280815109344)\n",
    "300 100 0.1 (96576, 0.7545974155069582, 0.7545974155069582)\n",
    "300 100 0.2 (96576, 0.754328197481776, 0.754328197481776)\n",
    "300 200 0.05 (96576, 0.7500621272365805, 0.7500621272365805)\n",
    "300 200 0.1 (96576, 0.7499275182239894, 0.7499275182239894)\n",
    "300 200 0.2 (96576, 0.7490266732935719, 0.7490266732935719)\n",
    "300 300 0.05 (96576, 0.7475045559973492, 0.7475045559973492)\n",
    "300 300 0.1 (96576, 0.7483950463883366, 0.7483950463883366)\n",
    "300 300 0.2 (96576, 0.7492337640821736, 0.7492337640821736)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best: 20 10 0.05 (96576, 0.777884774685222, 0.777884774685222) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.unlink(TRAIN)\n",
    "os.unlink(TEST)\n",
    "os.unlink(VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fasttext experiment per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userDict = {}\n",
    "for i in range(0,len(users)):\n",
    "    user = users[i]\n",
    "    if user in userDict: userDict[user] += \" \"+texts[i]\n",
    "    else: userDict[user] = LABELPREFIX+countries[i]+\" \"+texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFile = open(TRAIN,\"w\")\n",
    "testFile = open(TEST,\"w\")\n",
    "validationFile = open(VALIDATION,\"w\")\n",
    "userTextList = list(userDict.values())\n",
    "for i in range(0,round(len(userTextList)/10)):\n",
    "    print(userTextList[i],file=testFile)\n",
    "for i in range(round(len(userTextList)/10),round(2*len(userTextList)/10)):\n",
    "    print(userTextList[i],file=validationFile)\n",
    "for i in range(round(2*len(userTextList)/10),len(userTextList)):\n",
    "    print(userTextList[i],file=trainFile)\n",
    "validationFile.close()\n",
    "testFile.close()\n",
    "trainFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in [10,20,50,100,200,300]:\n",
    "    for epoch in [10,20,50,100,200,300]:\n",
    "        for lr in [0.05,0.1,0.2]:\n",
    "            model = fasttext.train_supervised(TRAIN,dim=dim,epoch=epoch,lr=lr)\n",
    "            print(dim,epoch,lr,model.test(VALIDATION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 10 0.05 (10432, 0.8002300613496932, 0.8002300613496932)\n",
    "10 10 0.1 (10432, 0.80329754601227, 0.80329754601227)\n",
    "10 10 0.2 (10432, 0.8001342024539877, 0.8001342024539877)\n",
    "10 20 0.05 (10432, 0.8029141104294478, 0.8029141104294478)\n",
    "10 20 0.1 (10432, 0.8008052147239264, 0.8008052147239264)\n",
    "10 20 0.2 (10432, 0.7972584355828221, 0.7972584355828221)\n",
    "10 50 0.05 (10432, 0.7994631901840491, 0.7994631901840491)\n",
    "10 50 0.1 (10432, 0.7991756134969326, 0.7991756134969326)\n",
    "10 50 0.2 (10432, 0.7951495398773006, 0.7951495398773006)\n",
    "10 100 0.05 (10432, 0.7986004601226994, 0.7986004601226994)\n",
    "10 100 0.1 (10432, 0.7962039877300614, 0.7962039877300614)\n",
    "10 100 0.2 (10432, 0.7950536809815951, 0.7950536809815951)\n",
    "10 200 0.05 (10432, 0.7951495398773006, 0.7951495398773006)\n",
    "10 200 0.1 (10432, 0.7957246932515337, 0.7957246932515337)\n",
    "10 200 0.2 (10432, 0.7941909509202454, 0.7941909509202454)\n",
    "10 300 0.05 (10432, 0.7958205521472392, 0.7958205521472392)\n",
    "10 300 0.1 (10432, 0.7950536809815951, 0.7950536809815951)\n",
    "10 300 0.2 (10432, 0.7937116564417178, 0.7937116564417178)\n",
    "20 10 0.05 (10432, 0.8030099693251533, 0.8030099693251533)\n",
    "20 10 0.1 (10432, 0.8061733128834356, 0.8061733128834356)\n",
    "20 10 0.2 (10432, 0.8024348159509203, 0.8024348159509203)\n",
    "20 20 0.05 (10432, 0.8048312883435583, 0.8048312883435583)\n",
    "20 20 0.1 (10432, 0.8005176380368099, 0.8005176380368099)\n",
    "20 20 0.2 (10432, 0.7969708588957055, 0.7969708588957055)\n",
    "20 50 0.05 (10432, 0.8002300613496932, 0.8002300613496932)\n",
    "20 50 0.1 (10432, 0.7991756134969326, 0.7991756134969326)\n",
    "20 50 0.2 (10432, 0.7965874233128835, 0.7965874233128835)\n",
    "20 100 0.05 (10432, 0.7987921779141104, 0.7987921779141104)\n",
    "20 100 0.1 (10432, 0.7958205521472392, 0.7958205521472392)\n",
    "20 100 0.2 (10432, 0.7965874233128835, 0.7965874233128835)\n",
    "20 200 0.05 (10432, 0.7976418711656442, 0.7976418711656442)\n",
    "20 200 0.1 (10432, 0.7960122699386503, 0.7960122699386503)\n",
    "20 200 0.2 (10432, 0.7944785276073619, 0.7944785276073619)\n",
    "20 300 0.05 (10432, 0.7952453987730062, 0.7952453987730062)\n",
    "20 300 0.1 (10432, 0.7962039877300614, 0.7962039877300614)\n",
    "20 300 0.2 (10432, 0.7940950920245399, 0.7940950920245399)\n",
    "50 10 0.05 (10432, 0.8045437116564417, 0.8045437116564417)\n",
    "50 10 0.1 (10432, 0.8061733128834356, 0.8061733128834356)\n",
    "50 10 0.2 (10432, 0.8020513803680982, 0.8020513803680982)\n",
    "50 20 0.05 (10432, 0.8047354294478528, 0.8047354294478528)\n",
    "50 20 0.1 (10432, 0.8006134969325154, 0.8006134969325154)\n",
    "50 20 0.2 (10432, 0.7985046012269938, 0.7985046012269938)\n",
    "50 50 0.05 (10432, 0.8006134969325154, 0.8006134969325154)\n",
    "50 50 0.1 (10432, 0.7986004601226994, 0.7986004601226994)\n",
    "50 50 0.2 (10432, 0.7957246932515337, 0.7957246932515337)\n",
    "50 100 0.05 (10432, 0.7958205521472392, 0.7958205521472392)\n",
    "50 100 0.1 (10432, 0.7980253067484663, 0.7980253067484663)\n",
    "50 100 0.2 (10432, 0.7959164110429447, 0.7959164110429447)\n",
    "50 200 0.05 (10432, 0.7979294478527608, 0.7979294478527608)\n",
    "50 200 0.1 (10432, 0.7975460122699386, 0.7975460122699386)\n",
    "50 200 0.2 (10432, 0.7962039877300614, 0.7962039877300614)\n",
    "50 300 0.05 (10432, 0.7956288343558282, 0.7956288343558282)\n",
    "50 300 0.1 (10432, 0.7940950920245399, 0.7940950920245399)\n",
    "50 300 0.2 (10432, 0.7943826687116564, 0.7943826687116564)\n",
    "100 10 0.05 (10432, 0.803489263803681, 0.803489263803681)\n",
    "100 10 0.1 (10432, 0.8043519938650306, 0.8043519938650306)\n",
    "100 10 0.2 (10432, 0.8009969325153374, 0.8009969325153374)\n",
    "100 20 0.05 (10432, 0.8020513803680982, 0.8020513803680982)\n",
    "100 20 0.1 (10432, 0.7983128834355828, 0.7983128834355828)\n",
    "100 20 0.2 (10432, 0.7984087423312883, 0.7984087423312883)\n",
    "100 50 0.05 (10432, 0.8000383435582822, 0.8000383435582822)\n",
    "100 50 0.1 (10432, 0.7992714723926381, 0.7992714723926381)\n",
    "100 50 0.2 (10432, 0.796875, 0.796875)\n",
    "100 100 0.05 (10432, 0.7964915644171779, 0.7964915644171779)\n",
    "100 100 0.1 (10432, 0.7955329754601227, 0.7955329754601227)\n",
    "100 100 0.2 (10432, 0.7960122699386503, 0.7960122699386503)\n",
    "100 200 0.05 (10432, 0.7960122699386503, 0.7960122699386503)\n",
    "100 200 0.1 (10432, 0.7950536809815951, 0.7950536809815951)\n",
    "100 200 0.2 (10432, 0.7964915644171779, 0.7964915644171779)\n",
    "100 300 0.05 (10432, 0.796875, 0.796875)\n",
    "100 300 0.1 (10432, 0.7941909509202454, 0.7941909509202454)\n",
    "100 300 0.2 (10432, 0.7929447852760736, 0.7929447852760736)\n",
    "200 10 0.05 (10432, 0.8029141104294478, 0.8029141104294478)\n",
    "200 10 0.1 (10432, 0.8048312883435583, 0.8048312883435583)\n",
    "200 10 0.2 (10432, 0.8005176380368099, 0.8005176380368099)\n",
    "200 20 0.05 (10432, 0.8028182515337423, 0.8028182515337423)\n",
    "200 20 0.1 (10432, 0.8020513803680982, 0.8020513803680982)\n",
    "200 20 0.2 (10432, 0.7971625766871165, 0.7971625766871165)\n",
    "200 50 0.05 (10432, 0.8004217791411042, 0.8004217791411042)\n",
    "200 50 0.1 (10432, 0.7962039877300614, 0.7962039877300614)\n",
    "200 50 0.2 (10432, 0.7985046012269938, 0.7985046012269938)\n",
    "200 100 0.05 (10432, 0.7976418711656442, 0.7976418711656442)\n",
    "200 100 0.1 (10432, 0.7982170245398773, 0.7982170245398773)\n",
    "200 100 0.2 (10432, 0.7964915644171779, 0.7964915644171779)\n",
    "200 200 0.05 (10432, 0.796875, 0.796875)\n",
    "200 200 0.1 (10432, 0.7948619631901841, 0.7948619631901841)\n",
    "200 200 0.2 (10432, 0.7963957055214724, 0.7963957055214724)\n",
    "200 300 0.05 (10432, 0.7972584355828221, 0.7972584355828221)\n",
    "200 300 0.1 (10432, 0.7948619631901841, 0.7948619631901841)\n",
    "200 300 0.2 (10432, 0.7947661042944786, 0.7947661042944786)\n",
    "300 10 0.05 (10432, 0.8022430981595092, 0.8022430981595092)\n",
    "300 10 0.1 (10432, 0.8040644171779141, 0.8040644171779141)\n",
    "300 10 0.2 (10432, 0.8007093558282209, 0.8007093558282209)\n",
    "300 20 0.05 (10432, 0.8043519938650306, 0.8043519938650306)\n",
    "300 20 0.1 (10432, 0.8002300613496932, 0.8002300613496932)\n",
    "300 20 0.2 (10432, 0.7974501533742331, 0.7974501533742331)\n",
    "300 50 0.05 (10432, 0.7983128834355828, 0.7983128834355828)\n",
    "300 50 0.1 (10432, 0.7974501533742331, 0.7974501533742331)\n",
    "300 50 0.2 (10432, 0.7931365030674846, 0.7931365030674846)\n",
    "300 100 0.05 (10432, 0.7993673312883436, 0.7993673312883436)\n",
    "300 100 0.1 (10432, 0.7957246932515337, 0.7957246932515337)\n",
    "300 100 0.2 (10432, 0.7939033742331288, 0.7939033742331288)\n",
    "300 200 0.05 (10432, 0.7944785276073619, 0.7944785276073619)\n",
    "300 200 0.1 (10432, 0.7956288343558282, 0.7956288343558282)\n",
    "300 200 0.2 (10432, 0.7963957055214724, 0.7963957055214724)\n",
    "300 300 0.05 (10432, 0.7967791411042945, 0.7967791411042945)\n",
    "300 300 0.1 (10432, 0.7944785276073619, 0.7944785276073619)\n",
    "300 300 0.2 (10432, 0.7945743865030674, 0.7945743865030674)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check friends of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRYFILE = \"/home/erikt/tmp/countries-202009-week1.txt\"\n",
    "UNKNOWN = \"-\"\n",
    "\n",
    "idStrs = {}\n",
    "screenNames = {}\n",
    "countries = {}\n",
    "inFile = open(COUNTRYFILE,\"r\")\n",
    "for line in inFile:\n",
    "    fields = line.strip().split(\",\")\n",
    "    userId = fields.pop(-1)\n",
    "    screenName = fields.pop(-1)\n",
    "    country = \",\".join(fields)\n",
    "    screenNames[userId] = screenName\n",
    "    idStrs[screenName] = userId\n",
    "    if country in BELGIUMLIST: \n",
    "        if not userId in countries: countries[userId] = [BELGIUM]\n",
    "        elif not BELGIUM in countries[userId]: countries[userId].append(BELGIUM) \n",
    "    elif country in NETHERLANDSLIST: \n",
    "        if not userId in countries: countries[userId] = [NETHERLANDS]\n",
    "        elif not NETHERLANDS in countries[userId]: countries[userId].append(NETHERLANDS) \n",
    "    elif country != UNKNOWN:\n",
    "        if not userId in countries: countries[userId] = [OTHER]\n",
    "        elif not OTHER in countries[userId]: countries[userId].append(OTHER)         \n",
    "inFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRIENDSFILE = \"getFriends.py.out\"\n",
    "\n",
    "countriesFound = {}\n",
    "inFile = open(FRIENDSFILE,\"r\")\n",
    "countriesFound = {}\n",
    "for line in inFile:\n",
    "    userIds = line.strip().split()\n",
    "    screenName = userIds.pop(0)\n",
    "    countriesFound[screenName] = {}\n",
    "    for userId in userIds:\n",
    "        if userId in countries:\n",
    "            countryString = \" \".join(sorted(countries[userId]))\n",
    "            if not countryString in countriesFound[screenName]: countriesFound[screenName][countryString] = 0\n",
    "            countriesFound[screenName][countryString] += 1\n",
    "    countriesFound[screenName] = {k:countriesFound[screenName][k] \n",
    "                                  for k in sorted(countriesFound[screenName].keys(),\n",
    "                                                  key=lambda k:countriesFound[screenName][k],reverse=True)}\n",
    "inFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINFRIENDS = 5\n",
    "MINFACTOR = 2\n",
    "\n",
    "correctGuesses = 0\n",
    "incorrectGuesses = 0\n",
    "for screenName in countriesFound:\n",
    "    if screenName in idStrs and idStrs[screenName] in countries:\n",
    "        totalLabeledFriends = sum(countriesFound[screenName].values())\n",
    "        if totalLabeledFriends >= MINFRIENDS:\n",
    "            guessedLabel = UNKNOWN\n",
    "            topLabel = list(countriesFound[screenName].keys())[0]\n",
    "            if len(countriesFound[screenName]) == 1: guessedLabel = topLabel\n",
    "            else:\n",
    "                secondLabel = list(countriesFound[screenName].keys())[1]\n",
    "                if countriesFound[screenName][topLabel] >= MINFACTOR*countriesFound[screenName][secondLabel]: guessedLabel = topLabel\n",
    "            if guessedLabel != UNKNOWN:\n",
    "                if guessedLabel in countries[idStrs[screenName]]: correctGuesses += 1\n",
    "                else: \n",
    "                    incorrectGuesses += 1\n",
    "                    print(guessedLabel,countries[idStrs[screenName]])\n",
    "print(f\"{correctGuesses/(correctGuesses+incorrectGuesses)} {correctGuesses} {incorrectGuesses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
