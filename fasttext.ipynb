{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext tweet classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pipes\n",
    "import random\n",
    "import re\n",
    "import tempfile\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"../data/\"\n",
    "DISTANCE = \"distance\"\n",
    "FACEMASK = \"mondkapje\"\n",
    "TOPIC = DISTANCE\n",
    "#TOPIC = FACEMASK\n",
    "if TOPIC == FACEMASK: FILETWEETS = TOPIC+\"-tweets+nunl.csv\"\n",
    "else: FILETWEETS = TOPIC+\"-tweets.csv\"\n",
    "FILEANNOTATIONS = FILETWEETS+\".human-labels.txt\"\n",
    "FILEFASTTEXT = \"fasttext-\"+TOPIC+\".csv\"\n",
    "LABELPREFIX = \"__label__\"\n",
    "LARGEINT = 9999999999\n",
    "LABEL = \"label\"\n",
    "TEXT = \"text\"\n",
    "USER = \"user\"\n",
    "IDSTR = \"id_str\"\n",
    "IRRELEVANT = \"IRRELEVANT\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "ANDERS = \"ANDERS\"\n",
    "EENS = \"EENS\"\n",
    "ONEENS = \"ONEENS\"\n",
    "SUPPORTS = \"SUPPORTS\"\n",
    "REJECTS = \"REJECTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(DATADIR+FILETWEETS,index_col=IDSTR)\n",
    "annotations = pd.read_csv(DATADIR+FILEANNOTATIONS,header=None,sep=\" \")\n",
    "mainAnnotator = annotations.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    text = re.sub(r\"\\\\n\",\" \",text)\n",
    "    text = re.sub(r\"https://\\S+\",\"\",text)\n",
    "    text = re.sub(r\"\\s+\",\" \",text)\n",
    "    text = text.strip()\n",
    "    return(text)\n",
    "\n",
    "def tokenize(text):\n",
    "    return(\" \".join(TweetTokenizer().tokenize(text)))\n",
    "\n",
    "def preprocess(text):\n",
    "    return(tokenize(cleanup(text)).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttextData = {}\n",
    "for i in range(0,len(annotations)):\n",
    "    annotator = annotations.iloc[i][0]\n",
    "    tweetId = annotations.iloc[i][2]\n",
    "    if annotator == mainAnnotator and tweetId in list(tweets.index):\n",
    "        tweetUser = tweets.loc[tweetId][1]\n",
    "        tweetLabel = annotations.iloc[i][4]\n",
    "        if tweetLabel == NEUTRAL: tweetLabel = IRRELEVANT\n",
    "        if tweetLabel == ANDERS: tweetLabel = IRRELEVANT\n",
    "        if tweetLabel == EENS: tweetLabel = SUPPORTS\n",
    "        if tweetLabel == ONEENS: tweetLabel = REJECTS\n",
    "        fasttextData[tweetId] = {LABEL:LABELPREFIX+tweetLabel,\\\n",
    "                                 USER:tweetUser,\\\n",
    "                                 TEXT:preprocess(tweets.loc[tweetId][TEXT])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5977, 6835, 6726)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasttextData),len(tweets),len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFile = open(FILEFASTTEXT,\"w\")\n",
    "seenTexts = {}\n",
    "for tweetId in fasttextData:\n",
    "    text = cleanup(fasttextData[tweetId][TEXT])\n",
    "    if not text in seenTexts:\n",
    "        print(fasttextData[tweetId][LABEL],text,file=outFile)\n",
    "        seenTexts[text] = True\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets annotated per minute: 5.3 ; 1000 tweets take: 189 minutes\n"
     ]
    }
   ],
   "source": [
    "annotations1 = annotations[annotations[0]==mainAnnotator]\n",
    "nbrOfAnnotationMinutes = len(set([str(x)[:12] for x in annotations1[1]]))\n",
    "nbrOfAnnotatedTweets = len(set([str(x)[:12] for x in annotations1[2]]))\n",
    "print(\"tweets annotated per minute:\",round(nbrOfAnnotatedTweets/nbrOfAnnotationMinutes,1),\"; 1000 tweets take:\",\\\n",
    "      round(1000/(nbrOfAnnotatedTweets/nbrOfAnnotationMinutes)),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets annotated per minute: 3.0 ; 1000 tweets take: 329 minutes\n"
     ]
    }
   ],
   "source": [
    "annotations2 = annotations[annotations[0]!=mainAnnotator]\n",
    "nbrOfAnnotationMinutes = len(set([str(x)[:12] for x in annotations2[1]]))\n",
    "nbrOfAnnotatedTweets = len(set([str(x)[:12] for x in annotations2[2]]))\n",
    "print(\"tweets annotated per minute:\",round(nbrOfAnnotatedTweets/nbrOfAnnotationMinutes,1),\"; 1000 tweets take:\",\\\n",
    "      round(1000/(nbrOfAnnotatedTweets/nbrOfAnnotationMinutes)),\"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext run and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINEDDIR = \"/home/erikt/projects/newsgac/fasttext-runs/\"\n",
    "WIKIFILENAME = \"wiki.nl.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5731"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttextData = []\n",
    "inFile = open(FILEFASTTEXT,\"r\")\n",
    "for line in inFile: fasttextData.append(line.strip())\n",
    "inFile.close()\n",
    "len(fasttextData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 100\n",
    "EPOCH = 100\n",
    "LR = 0.05\n",
    "N = 10\n",
    "TRAIN = \"TRAIN\"+str(int(random.random()*LARGEINT))\n",
    "TEST = \"TEST\"+str(int(random.random()*LARGEINT))\n",
    "VALIDATION = \"VALIDATION\"+str(int(random.random()*LARGEINT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranSelect(inList,size):\n",
    "    outList = []\n",
    "    selectionList = list(inList)\n",
    "    while len(outList) < size and len(selectionList) > 0:\n",
    "        index = int(random.random()*len(selectionList))\n",
    "        outList.append(selectionList[index])\n",
    "        del(selectionList[index])\n",
    "    return(outList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFasttext(fasttextData,dim=DIM,epoch=EPOCH,lr=LR,n=N,squealFlag=True,maxTrain=None):\n",
    "    predictionCountsTest = []\n",
    "    predictionLabelsTest = []\n",
    "    predictionCountsValidation = []\n",
    "    predictionLabelsValidation = []\n",
    "    for fold in range(0,n):\n",
    "        if squealFlag:\n",
    "            clear_output(wait=True)\n",
    "            print(\"starting fold\",fold)\n",
    "        validationStart = round(fold*len(fasttextData)/n)\n",
    "        validationEnd = round((fold+1)*len(fasttextData)/n)\n",
    "        if fold < n-1: nextFold = fold+1\n",
    "        else: nextFold = 0\n",
    "        testStart = round(nextFold*len(fasttextData)/n)\n",
    "        testEnd = round((nextFold+1)*len(fasttextData)/n)\n",
    "        trainFile = open(TRAIN,\"w\")\n",
    "        testFile = open(TEST,\"w\")\n",
    "        validationFile = open(VALIDATION,\"w\")\n",
    "        trainData = []\n",
    "        validationData = []\n",
    "        testData = []\n",
    "        for i in range(0,len(fasttextData)):\n",
    "            data = fasttextData[i]\n",
    "            if i >= testStart and i < testEnd: \n",
    "                print(data,file=testFile)\n",
    "                testData.append(data)\n",
    "            elif i >= validationStart and i < validationEnd: \n",
    "                print(data,file=validationFile)\n",
    "                validationData.append(data)\n",
    "            else: \n",
    "                print(data,file=trainFile)\n",
    "                trainData.append(data)\n",
    "        testFile.close()\n",
    "        trainFile.close()\n",
    "        validationFile.close()\n",
    "        if not maxTrain == None and maxTrain < len(trainData):\n",
    "            trainData = ranSelect(trainData,maxTrain)\n",
    "            trainFile = open(TRAIN,\"w\")\n",
    "            for i in range(0,len(trainData)):\n",
    "                print(trainData[i],file=trainFile)\n",
    "            trainFile.close()\n",
    "        model = fasttext.train_supervised(TRAIN,dim=dim,epoch=epoch,lr=lr)\n",
    "        predictionCountsValidation.append([*model.test(VALIDATION)])\n",
    "        predictionLabelsValidation.append(model.predict(validationData))\n",
    "        predictionCountsTest.append([*model.test(TEST)])\n",
    "        predictionLabelsTest.append(model.predict(testData))\n",
    "        os.unlink(TRAIN)\n",
    "        os.unlink(TEST)\n",
    "        os.unlink(VALIDATION)\n",
    "    if squealFlag:\n",
    "        clear_output(wait=True)\n",
    "        print(\"finished\")\n",
    "    return(predictionCountsValidation,predictionLabelsValidation,predictionCountsTest,predictionLabelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeConfusionMatrix(fasttextData,predictionLabels):\n",
    "    goldLabels = pd.Series([fasttextData[i].split()[0] for i in range(0,len(fasttextData))])\n",
    "    predictedLabels = pd.Series([x[0] for row in predictionLabels for x in row[0]])\n",
    "    return(pd.crosstab(goldLabels,predictedLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictionCounts,predictionLabels,fasttextData,printResults=True):\n",
    "    caseTotal = 0\n",
    "    pTotal = 0\n",
    "    rTotal = 0\n",
    "    for i in range(0,len(predictionCounts)):\n",
    "        caseTotal += predictionCounts[i][0]\n",
    "        pTotal += predictionCounts[i][0]*predictionCounts[i][1]\n",
    "        rTotal += predictionCounts[i][0]*predictionCounts[i][2]\n",
    "    precision = round(pTotal/caseTotal,3)\n",
    "    recall = round(rTotal/caseTotal,3)\n",
    "    cf = makeConfusionMatrix(fasttextData,predictionLabels)\n",
    "    for label in ['__label__REJECTS','__label__SUPPORTS','__label__IRRELEVANT']:\n",
    "        if not label in cf: cf[label] = [0 for i in range(0,len(cf))]\n",
    "    factor = sum(cf.loc['__label__SUPPORTS'])*sum([cf.iloc[i]['__label__REJECTS'] for i in range(0,len(cf))])/\\\n",
    "             (sum(cf.loc['__label__REJECTS'])*sum([cf.iloc[i]['__label__SUPPORTS'] for i in range(0,len(cf))]))\n",
    "    if printResults: print(\"cases: {0}; precision: {1}; recall: {2}; factor: {3:0.3f}\".format(caseTotal,precision,recall,factor))\n",
    "    return((precision,factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 0.05 cases: 5731; precision: 0.62; recall: 0.62; factor: 0.454\n",
      "cases: 5731; precision: 0.618; recall: 0.618; factor: 0.436\n",
      "10 10 0.1 cases: 5731; precision: 0.641; recall: 0.641; factor: 0.623\n",
      "cases: 5731; precision: 0.648; recall: 0.648; factor: 0.597\n",
      "10 10 0.2 cases: 5731; precision: 0.65; recall: 0.65; factor: 0.716\n",
      "cases: 5731; precision: 0.651; recall: 0.651; factor: 0.690\n",
      "10 20 0.05 cases: 5731; precision: 0.642; recall: 0.642; factor: 0.632\n",
      "cases: 5731; precision: 0.648; recall: 0.648; factor: 0.607\n",
      "10 20 0.1 cases: 5731; precision: 0.644; recall: 0.644; factor: 0.785\n",
      "cases: 5731; precision: 0.648; recall: 0.648; factor: 0.762\n",
      "10 20 0.2 cases: 5731; precision: 0.638; recall: 0.638; factor: 0.832\n",
      "cases: 5731; precision: 0.639; recall: 0.639; factor: 0.805\n",
      "10 50 0.05 cases: 5731; precision: 0.638; recall: 0.638; factor: 0.795\n",
      "cases: 5731; precision: 0.64; recall: 0.64; factor: 0.776\n",
      "10 50 0.1 cases: 5731; precision: 0.631; recall: 0.631; factor: 0.832\n",
      "cases: 5731; precision: 0.631; recall: 0.631; factor: 0.811\n",
      "10 50 0.2 cases: 5731; precision: 0.626; recall: 0.626; factor: 0.845\n",
      "cases: 5731; precision: 0.631; recall: 0.631; factor: 0.805\n",
      "10 100 0.05 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.827\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.812\n",
      "10 100 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.833\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.817\n",
      "10 100 0.2 cases: 5731; precision: 0.631; recall: 0.631; factor: 0.861\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.821\n",
      "10 200 0.05 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.838\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.817\n",
      "10 200 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.849\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.814\n",
      "10 200 0.2 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.852\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.819\n",
      "10 300 0.05 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.840\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.813\n",
      "10 300 0.1 cases: 5731; precision: 0.63; recall: 0.63; factor: 0.844\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.821\n",
      "10 300 0.2 cases: 5731; precision: 0.631; recall: 0.631; factor: 0.865\n",
      "cases: 5731; precision: 0.625; recall: 0.625; factor: 0.830\n",
      "20 10 0.05 cases: 5731; precision: 0.616; recall: 0.616; factor: 0.461\n",
      "cases: 5731; precision: 0.614; recall: 0.614; factor: 0.421\n",
      "20 10 0.1 cases: 5731; precision: 0.642; recall: 0.642; factor: 0.661\n",
      "cases: 5731; precision: 0.649; recall: 0.649; factor: 0.628\n",
      "20 10 0.2 cases: 5731; precision: 0.648; recall: 0.648; factor: 0.730\n",
      "cases: 5731; precision: 0.646; recall: 0.646; factor: 0.700\n",
      "20 20 0.05 cases: 5731; precision: 0.644; recall: 0.644; factor: 0.634\n",
      "cases: 5731; precision: 0.649; recall: 0.649; factor: 0.602\n",
      "20 20 0.1 cases: 5731; precision: 0.646; recall: 0.646; factor: 0.743\n",
      "cases: 5731; precision: 0.649; recall: 0.649; factor: 0.718\n",
      "20 20 0.2 cases: 5731; precision: 0.633; recall: 0.633; factor: 0.829\n",
      "cases: 5731; precision: 0.639; recall: 0.639; factor: 0.794\n",
      "20 50 0.05 cases: 5731; precision: 0.639; recall: 0.639; factor: 0.773\n",
      "cases: 5731; precision: 0.64; recall: 0.64; factor: 0.747\n",
      "20 50 0.1 cases: 5731; precision: 0.631; recall: 0.631; factor: 0.836\n",
      "cases: 5731; precision: 0.633; recall: 0.633; factor: 0.807\n",
      "20 50 0.2 cases: 5731; precision: 0.63; recall: 0.63; factor: 0.846\n",
      "cases: 5731; precision: 0.628; recall: 0.628; factor: 0.813\n",
      "20 100 0.05 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.841\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.807\n",
      "20 100 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.853\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.813\n",
      "20 100 0.2 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.849\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.838\n",
      "20 200 0.05 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.854\n",
      "cases: 5731; precision: 0.631; recall: 0.631; factor: 0.816\n",
      "20 200 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.859\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.817\n",
      "20 200 0.2 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.867\n",
      "cases: 5731; precision: 0.626; recall: 0.626; factor: 0.816\n",
      "20 300 0.05 cases: 5731; precision: 0.63; recall: 0.63; factor: 0.853\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.813\n",
      "20 300 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.860\n",
      "cases: 5731; precision: 0.628; recall: 0.628; factor: 0.819\n",
      "20 300 0.2 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.867\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.838\n",
      "50 10 0.05 cases: 5731; precision: 0.616; recall: 0.616; factor: 0.487\n",
      "cases: 5731; precision: 0.612; recall: 0.612; factor: 0.449\n",
      "50 10 0.1 cases: 5731; precision: 0.64; recall: 0.64; factor: 0.633\n",
      "cases: 5731; precision: 0.648; recall: 0.648; factor: 0.600\n",
      "50 10 0.2 cases: 5731; precision: 0.651; recall: 0.651; factor: 0.752\n",
      "cases: 5731; precision: 0.655; recall: 0.655; factor: 0.722\n",
      "50 20 0.05 cases: 5731; precision: 0.642; recall: 0.642; factor: 0.631\n",
      "cases: 5731; precision: 0.649; recall: 0.649; factor: 0.598\n",
      "50 20 0.1 cases: 5731; precision: 0.646; recall: 0.646; factor: 0.758\n",
      "cases: 5731; precision: 0.648; recall: 0.648; factor: 0.736\n",
      "50 20 0.2 cases: 5731; precision: 0.635; recall: 0.635; factor: 0.813\n",
      "cases: 5731; precision: 0.636; recall: 0.636; factor: 0.786\n",
      "50 50 0.05 cases: 5731; precision: 0.639; recall: 0.639; factor: 0.792\n",
      "cases: 5731; precision: 0.638; recall: 0.638; factor: 0.769\n",
      "50 50 0.1 cases: 5731; precision: 0.63; recall: 0.63; factor: 0.832\n",
      "cases: 5731; precision: 0.633; recall: 0.633; factor: 0.811\n",
      "50 50 0.2 cases: 5731; precision: 0.63; recall: 0.63; factor: 0.842\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.814\n",
      "50 100 0.05 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.836\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.812\n",
      "50 100 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.847\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.810\n",
      "50 100 0.2 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.855\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.817\n",
      "50 200 0.05 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.849\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.815\n",
      "50 200 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.850\n",
      "cases: 5731; precision: 0.628; recall: 0.628; factor: 0.819\n",
      "50 200 0.2 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.848\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.819\n",
      "50 300 0.05 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.860\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.813\n",
      "50 300 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.854\n",
      "cases: 5731; precision: 0.628; recall: 0.628; factor: 0.823\n",
      "50 300 0.2 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.869\n",
      "cases: 5731; precision: 0.623; recall: 0.623; factor: 0.821\n",
      "100 10 0.05 cases: 5731; precision: 0.607; recall: 0.607; factor: 0.521\n",
      "cases: 5731; precision: 0.605; recall: 0.605; factor: 0.481\n",
      "100 10 0.1 cases: 5731; precision: 0.641; recall: 0.641; factor: 0.635\n",
      "cases: 5731; precision: 0.645; recall: 0.645; factor: 0.612\n",
      "100 10 0.2 cases: 5731; precision: 0.649; recall: 0.649; factor: 0.735\n",
      "cases: 5731; precision: 0.652; recall: 0.652; factor: 0.712\n",
      "100 20 0.05 cases: 5731; precision: 0.639; recall: 0.639; factor: 0.635\n",
      "cases: 5731; precision: 0.649; recall: 0.649; factor: 0.606\n",
      "100 20 0.1 cases: 5731; precision: 0.644; recall: 0.644; factor: 0.735\n",
      "cases: 5731; precision: 0.646; recall: 0.646; factor: 0.697\n",
      "100 20 0.2 cases: 5731; precision: 0.633; recall: 0.633; factor: 0.812\n",
      "cases: 5731; precision: 0.637; recall: 0.637; factor: 0.791\n",
      "100 50 0.05 cases: 5731; precision: 0.639; recall: 0.639; factor: 0.782\n",
      "cases: 5731; precision: 0.64; recall: 0.64; factor: 0.744\n",
      "100 50 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.843\n",
      "cases: 5731; precision: 0.633; recall: 0.633; factor: 0.806\n",
      "100 50 0.2 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.853\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.820\n",
      "100 100 0.05 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.839\n",
      "cases: 5731; precision: 0.631; recall: 0.631; factor: 0.807\n",
      "100 100 0.1 cases: 5731; precision: 0.626; recall: 0.626; factor: 0.845\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.816\n",
      "100 100 0.2 cases: 5731; precision: 0.63; recall: 0.63; factor: 0.861\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.822\n",
      "100 200 0.05 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.852\n",
      "cases: 5731; precision: 0.631; recall: 0.631; factor: 0.812\n",
      "100 200 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.851\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.820\n",
      "100 200 0.2 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.855\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.831\n",
      "100 300 0.05 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.854\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.814\n",
      "100 300 0.1 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.852\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.817\n",
      "100 300 0.2 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.865\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.832\n",
      "200 10 0.05 cases: 5731; precision: 0.603; recall: 0.603; factor: 0.588\n",
      "cases: 5731; precision: 0.603; recall: 0.603; factor: 0.545\n",
      "200 10 0.1 cases: 5731; precision: 0.638; recall: 0.638; factor: 0.622\n",
      "cases: 5731; precision: 0.65; recall: 0.65; factor: 0.613\n",
      "200 10 0.2 cases: 5731; precision: 0.65; recall: 0.65; factor: 0.788\n",
      "cases: 5731; precision: 0.652; recall: 0.652; factor: 0.743\n",
      "200 20 0.05 cases: 5731; precision: 0.639; recall: 0.639; factor: 0.683\n",
      "cases: 5731; precision: 0.647; recall: 0.647; factor: 0.653\n",
      "200 20 0.1 cases: 5731; precision: 0.648; recall: 0.648; factor: 0.784\n",
      "cases: 5731; precision: 0.646; recall: 0.646; factor: 0.727\n",
      "200 20 0.2 cases: 5731; precision: 0.632; recall: 0.632; factor: 0.828\n",
      "cases: 5731; precision: 0.632; recall: 0.632; factor: 0.792\n",
      "200 50 0.05 cases: 5731; precision: 0.64; recall: 0.64; factor: 0.781\n",
      "cases: 5731; precision: 0.642; recall: 0.642; factor: 0.758\n",
      "200 50 0.1 cases: 5731; precision: 0.63; recall: 0.63; factor: 0.840\n",
      "cases: 5731; precision: 0.631; recall: 0.631; factor: 0.807\n",
      "200 50 0.2 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.847\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.816\n",
      "200 100 0.05 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.832\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.810\n",
      "200 100 0.1 cases: 5731; precision: 0.626; recall: 0.626; factor: 0.847\n",
      "cases: 5731; precision: 0.628; recall: 0.628; factor: 0.815\n",
      "200 100 0.2 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.862\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.818\n",
      "200 200 0.05 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.848\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.815\n",
      "200 200 0.1 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.848\n",
      "cases: 5731; precision: 0.628; recall: 0.628; factor: 0.816\n",
      "200 200 0.2 cases: 5731; precision: 0.631; recall: 0.631; factor: 0.864\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.834\n",
      "200 300 0.05 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.854\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.818\n",
      "200 300 0.1 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.853\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.815\n",
      "200 300 0.2 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.867\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.826\n",
      "300 10 0.05 cases: 5731; precision: 0.601; recall: 0.601; factor: 0.604\n",
      "cases: 5731; precision: 0.603; recall: 0.603; factor: 0.560\n",
      "300 10 0.1 cases: 5731; precision: 0.638; recall: 0.638; factor: 0.652\n",
      "cases: 5731; precision: 0.646; recall: 0.646; factor: 0.633\n",
      "300 10 0.2 cases: 5731; precision: 0.652; recall: 0.652; factor: 0.766\n",
      "cases: 5731; precision: 0.654; recall: 0.654; factor: 0.714\n",
      "300 20 0.05 cases: 5731; precision: 0.639; recall: 0.639; factor: 0.682\n",
      "cases: 5731; precision: 0.646; recall: 0.646; factor: 0.651\n",
      "300 20 0.1 cases: 5731; precision: 0.648; recall: 0.648; factor: 0.765\n",
      "cases: 5731; precision: 0.649; recall: 0.649; factor: 0.734\n",
      "300 20 0.2 cases: 5731; precision: 0.636; recall: 0.636; factor: 0.827\n",
      "cases: 5731; precision: 0.638; recall: 0.638; factor: 0.806\n",
      "300 50 0.05 cases: 5731; precision: 0.641; recall: 0.641; factor: 0.757\n",
      "cases: 5731; precision: 0.64; recall: 0.64; factor: 0.745\n",
      "300 50 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.826\n",
      "cases: 5731; precision: 0.634; recall: 0.634; factor: 0.804\n",
      "300 50 0.2 cases: 5731; precision: 0.626; recall: 0.626; factor: 0.855\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.815\n",
      "300 100 0.05 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.833\n",
      "cases: 5731; precision: 0.631; recall: 0.631; factor: 0.800\n",
      "300 100 0.1 cases: 5731; precision: 0.626; recall: 0.626; factor: 0.855\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.811\n",
      "300 100 0.2 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.866\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.831\n",
      "300 200 0.05 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.849\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.812\n",
      "300 200 0.1 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.855\n",
      "cases: 5731; precision: 0.629; recall: 0.629; factor: 0.816\n",
      "300 200 0.2 cases: 5731; precision: 0.628; recall: 0.628; factor: 0.856\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.829\n",
      "300 300 0.05 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.856\n",
      "cases: 5731; precision: 0.63; recall: 0.63; factor: 0.818\n",
      "300 300 0.1 cases: 5731; precision: 0.629; recall: 0.629; factor: 0.852\n",
      "cases: 5731; precision: 0.627; recall: 0.627; factor: 0.821\n",
      "300 300 0.2 cases: 5731; precision: 0.627; recall: 0.627; factor: 0.873\n",
      "cases: 5731; precision: 0.626; recall: 0.626; factor: 0.833\n"
     ]
    }
   ],
   "source": [
    "scoresValidation = {}\n",
    "scoresTest = {}\n",
    "for dim in [10,20,50,100,200,300]:\n",
    "    for epoch in [10,20,50,100,200,300]:\n",
    "        for lr in [0.05,0.1,0.2]:\n",
    "            predictionCountsValidation,predictionLabelsValidation,predictionCountsTest,predictionLabelsTest = \\\n",
    "                runFasttext(fasttextData,dim=dim,epoch=epoch,lr=lr,squealFlag=False)\n",
    "            print(dim,epoch,lr,end=\" \")\n",
    "            key = \",\".join([str(dim),str(epoch),str(lr)])\n",
    "            scoresValidation[key] = evaluate(predictionCountsValidation,predictionLabelsValidation,fasttextData)\n",
    "            scoresTest[key] = evaluate(predictionCountsTest,predictionLabelsTest,fasttextData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.652, 0.7659559153777942), '300,10,0.2'),\n",
       " ((0.651, 0.7515804619841587), '50,10,0.2'),\n",
       " ((0.65, 0.7162866025512842), '10,10,0.2'),\n",
       " ((0.65, 0.7884518650363721), '200,10,0.2'),\n",
       " ((0.649, 0.7352314707919649), '100,10,0.2'),\n",
       " ((0.648, 0.7303549676437), '20,10,0.2'),\n",
       " ((0.648, 0.7835739239468164), '200,20,0.1'),\n",
       " ((0.648, 0.7647916424164823), '300,20,0.1'),\n",
       " ((0.646, 0.7433294529863305), '20,20,0.1'),\n",
       " ((0.646, 0.7582149948329715), '50,20,0.1')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(scoresValidation[k],k) for k in sorted(scoresValidation.keys(),\\\n",
    "                                         key=lambda k:scoresValidation[k][0],reverse=True)][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.655, 0.7216019305818581), '50,10,0.2'),\n",
       " ((0.654, 0.7142148418528412), '300,10,0.2'),\n",
       " ((0.652, 0.7115461939664086), '100,10,0.2'),\n",
       " ((0.652, 0.743293548758491), '200,10,0.2'),\n",
       " ((0.651, 0.6899390747469893), '10,10,0.2'),\n",
       " ((0.65, 0.613217564954619), '200,10,0.1'),\n",
       " ((0.649, 0.6276167644162849), '20,10,0.1'),\n",
       " ((0.649, 0.602163551652118), '20,20,0.05'),\n",
       " ((0.649, 0.7180754984452168), '20,20,0.1'),\n",
       " ((0.649, 0.5979183141336639), '50,20,0.05'),\n",
       " ((0.649, 0.6061398649080565), '100,20,0.05'),\n",
       " ((0.649, 0.7340539688156245), '300,20,0.1'),\n",
       " ((0.648, 0.5973590225895589), '10,10,0.1'),\n",
       " ((0.648, 0.6071934543179424), '10,20,0.05'),\n",
       " ((0.648, 0.7616283768182868), '10,20,0.1'),\n",
       " ((0.648, 0.600145536352102), '50,10,0.1'),\n",
       " ((0.648, 0.7363818355243421), '50,20,0.1'),\n",
       " ((0.647, 0.6526908915421463), '200,20,0.05'),\n",
       " ((0.646, 0.7003014605177273), '20,10,0.2'),\n",
       " ((0.646, 0.6972606016533986), '100,20,0.1'),\n",
       " ((0.646, 0.7272546099345938), '200,20,0.1'),\n",
       " ((0.646, 0.6334301782675035), '300,10,0.1'),\n",
       " ((0.646, 0.6511584667174345), '300,20,0.05'),\n",
       " ((0.645, 0.6120803079345639), '100,10,0.1'),\n",
       " ((0.642, 0.7580121683819607), '200,50,0.05'),\n",
       " ((0.64, 0.7757702340525365), '10,50,0.05'),\n",
       " ((0.64, 0.7466031483015741), '20,50,0.05'),\n",
       " ((0.64, 0.7439692701664533), '100,50,0.05'),\n",
       " ((0.64, 0.7445558417619813), '300,50,0.05'),\n",
       " ((0.639, 0.8048782670607093), '10,20,0.2'),\n",
       " ((0.639, 0.7940329299742115), '20,20,0.2'),\n",
       " ((0.638, 0.768786281880472), '50,50,0.05'),\n",
       " ((0.638, 0.8061360533929772), '300,20,0.2'),\n",
       " ((0.637, 0.7906150460646699), '100,20,0.2'),\n",
       " ((0.636, 0.7864424588533478), '50,20,0.2'),\n",
       " ((0.634, 0.803736245126067), '300,50,0.1'),\n",
       " ((0.633, 0.8068797399783315), '20,50,0.1'),\n",
       " ((0.633, 0.8107060849598163), '50,50,0.1'),\n",
       " ((0.633, 0.8058124868614673), '100,50,0.1'),\n",
       " ((0.632, 0.791667338124859), '200,20,0.2'),\n",
       " ((0.631, 0.8105884661603635), '10,50,0.1'),\n",
       " ((0.631, 0.804628635120073), '10,50,0.2'),\n",
       " ((0.631, 0.8163115132939259), '20,200,0.05'),\n",
       " ((0.631, 0.8067490114186697), '100,100,0.05'),\n",
       " ((0.631, 0.8123372843259327), '100,200,0.05'),\n",
       " ((0.631, 0.807350528068468), '200,50,0.1'),\n",
       " ((0.631, 0.7998737042051448), '300,100,0.05'),\n",
       " ((0.63, 0.8171294607020361), '10,100,0.1'),\n",
       " ((0.63, 0.8133893985315808), '20,300,0.05'),\n",
       " ((0.63, 0.8145556779434514), '50,200,0.05'),\n",
       " ((0.63, 0.8187792750155388), '50,200,0.2'),\n",
       " ((0.63, 0.8202747248297143), '100,50,0.2'),\n",
       " ((0.63, 0.8156071892962607), '100,100,0.1'),\n",
       " ((0.63, 0.8139727059509777), '100,300,0.05'),\n",
       " ((0.63, 0.8104706444532636), '200,100,0.05'),\n",
       " ((0.63, 0.8150243520964683), '200,200,0.05'),\n",
       " ((0.63, 0.8183072200861554), '200,300,0.05'),\n",
       " ((0.63, 0.8151383147982462), '300,50,0.2'),\n",
       " ((0.63, 0.8108192778902032), '300,100,0.1'),\n",
       " ((0.63, 0.8121046578493387), '300,200,0.05'),\n",
       " ((0.63, 0.8179596761416494), '300,300,0.05'),\n",
       " ((0.629, 0.8116383993666617), '10,100,0.05'),\n",
       " ((0.629, 0.8205455662069442), '10,100,0.2'),\n",
       " ((0.629, 0.8173647412838679), '10,200,0.05'),\n",
       " ((0.629, 0.8188902869667574), '10,200,0.2'),\n",
       " ((0.629, 0.8129216645473762), '10,300,0.05'),\n",
       " ((0.629, 0.8207645991254532), '10,300,0.1'),\n",
       " ((0.629, 0.8068697283990476), '20,100,0.05'),\n",
       " ((0.629, 0.812803876677642), '20,100,0.1'),\n",
       " ((0.629, 0.8380719920099468), '20,100,0.2'),\n",
       " ((0.629, 0.8384629516227802), '20,300,0.2'),\n",
       " ((0.629, 0.8139727059509777), '50,50,0.2'),\n",
       " ((0.629, 0.8121037219882871), '50,100,0.05'),\n",
       " ((0.629, 0.809653637755226), '50,100,0.1'),\n",
       " ((0.629, 0.8133863473693149), '50,300,0.05'),\n",
       " ((0.629, 0.8199454727790206), '100,200,0.1'),\n",
       " ((0.629, 0.830771063628736), '100,200,0.2'),\n",
       " ((0.629, 0.8155008795199812), '200,50,0.2'),\n",
       " ((0.629, 0.8184185759719608), '200,100,0.2'),\n",
       " ((0.629, 0.8260222527907288), '200,300,0.2'),\n",
       " ((0.629, 0.8312126585676345), '300,100,0.2'),\n",
       " ((0.629, 0.8160850918660754), '300,200,0.1'),\n",
       " ((0.628, 0.8132710053423993), '20,50,0.2'),\n",
       " ((0.628, 0.8194883794684968), '20,300,0.1'),\n",
       " ((0.628, 0.8190971843117274), '50,200,0.1'),\n",
       " ((0.628, 0.822877269384986), '50,300,0.1'),\n",
       " ((0.628, 0.8150371030341494), '200,100,0.1'),\n",
       " ((0.628, 0.8158498410468576), '200,200,0.1'),\n",
       " ((0.627, 0.813508064516129), '10,200,0.1'),\n",
       " ((0.627, 0.8172525063928238), '20,200,0.1'),\n",
       " ((0.627, 0.8174655166138952), '50,100,0.2'),\n",
       " ((0.627, 0.8221658481146243), '100,100,0.2'),\n",
       " ((0.627, 0.8166689673932903), '100,300,0.1'),\n",
       " ((0.627, 0.8318333489510974), '100,300,0.2'),\n",
       " ((0.627, 0.8341029952534681), '200,200,0.2'),\n",
       " ((0.627, 0.8147958355319236), '200,300,0.1'),\n",
       " ((0.627, 0.828648335097289), '300,200,0.2'),\n",
       " ((0.627, 0.820655177458287), '300,300,0.1'),\n",
       " ((0.626, 0.8159715870983477), '20,200,0.2'),\n",
       " ((0.626, 0.8330382060613973), '300,300,0.2'),\n",
       " ((0.625, 0.8304672920095231), '10,300,0.2'),\n",
       " ((0.623, 0.8210197329600254), '50,300,0.2'),\n",
       " ((0.618, 0.4358626450605039), '10,10,0.05'),\n",
       " ((0.614, 0.42053698136816564), '20,10,0.05'),\n",
       " ((0.612, 0.44943180964119833), '50,10,0.05'),\n",
       " ((0.605, 0.4810708851974767), '100,10,0.05'),\n",
       " ((0.603, 0.5446905350679139), '200,10,0.05'),\n",
       " ((0.603, 0.5596535634368939), '300,10,0.05')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(scoresTest[k],k) for k in sorted(scoresTest.keys(),\\\n",
    "                                         key=lambda k:scoresTest[k][0],reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facemasks: best validation accuracy 0.56 for '300,20,0.2', associated test accuracy 0.55 (15th score).\n",
    "\n",
    "Social distancing: best validation accuracy 0.65 for '300,10,0.2', associated test accuracy 0.65 (2nd score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.62, 0.4537883439426595), '10,10,0.05'),\n",
       " ((0.616, 0.46079177769318613), '20,10,0.05'),\n",
       " ((0.616, 0.4874906538931474), '50,10,0.05'),\n",
       " ((0.607, 0.5205476475876536), '100,10,0.05'),\n",
       " ((0.603, 0.5882633630944304), '200,10,0.05'),\n",
       " ((0.601, 0.6044297025465439), '300,10,0.05'),\n",
       " ((0.638, 0.6216561290528942), '200,10,0.1'),\n",
       " ((0.641, 0.6230211409586551), '10,10,0.1'),\n",
       " ((0.642, 0.6312127182773815), '50,20,0.05'),\n",
       " ((0.642, 0.6316999596338683), '10,20,0.05')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(scoresValidation[k],k) for k in sorted(scoresValidation.keys(),\n",
    "                                         key=lambda k:scoresValidation[k][1])][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.614, 0.42053698136816564), '20,10,0.05'),\n",
       " ((0.618, 0.4358626450605039), '10,10,0.05'),\n",
       " ((0.612, 0.44943180964119833), '50,10,0.05'),\n",
       " ((0.605, 0.4810708851974767), '100,10,0.05'),\n",
       " ((0.603, 0.5446905350679139), '200,10,0.05'),\n",
       " ((0.603, 0.5596535634368939), '300,10,0.05'),\n",
       " ((0.648, 0.5973590225895589), '10,10,0.1'),\n",
       " ((0.649, 0.5979183141336639), '50,20,0.05'),\n",
       " ((0.648, 0.600145536352102), '50,10,0.1'),\n",
       " ((0.649, 0.602163551652118), '20,20,0.05')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(scoresTest[k],k) for k in sorted(scoresTest.keys(),\n",
    "                                         key=lambda k:scoresTest[k][1])][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "scoresN = {} \n",
    "triplets = [(20,300,0.2),(50,200,0.2),(300,200,0.2),(20,200,0.05),(10,300,0.2)]\n",
    "\n",
    "for triplet in triplets:\n",
    "    dim,epoch,lr = triplet\n",
    "    key = \" \".join([str(dim),str(epoch),str(lr)])\n",
    "    scoresN[key] = []\n",
    "    for i in range(0,N): \n",
    "        predictionCounts,predictionLabels = runFasttext(fasttextData,dim=dim,epoch=epoch,lr=lr,squealFlag=False)\n",
    "        print(dim,epoch,lr,end=\" \")\n",
    "        scoresN[key].append(evaluate(predictionCounts,predictionLabels,fasttextData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresNaverage = {}\n",
    "for key in scoresN: scoresNaverage[key] = round(np.average([x[1] for x in scoresN[key]]),3)\n",
    "{key:scoresNaverage[key] for key in sorted(scoresNaverage.keys(),key=lambda k:scoresNaverage[k],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in [10]:\n",
    "    for epoch in [900]:\n",
    "        for lr in [0.2]:\n",
    "            predictionCounts,predictionLabels = runFasttext(fasttextData,dim=dim,epoch=epoch,lr=lr,squealFlag=False)\n",
    "            print(dim,epoch,lr,end=\" \")\n",
    "            key = \",\".join([str(dim),str(epoch),str(lr)])\n",
    "            scores[key] = evaluate(predictionCounts,predictionLabels,fasttextData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TOPIC == DISTANCE:\n",
    "    # social distancing\n",
    "    BESTDIM = 20\n",
    "    BESTEPOCH = 300\n",
    "    BESTLR = 0.9\n",
    "elif TOPIC == FACEMASK:\n",
    "    # facemasks\n",
    "    BESTDIM = 10\n",
    "    BESTEPOCH = 900\n",
    "    BESTLR = 0.2\n",
    "else:\n",
    "    print(\"unknown topic!\",file=sys.stderr)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionCounts,predictionLabels = runFasttext(fasttextData,dim=BESTDIM,epoch=BESTEPOCH,lr=BESTLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predictionCounts,predictionLabels,fasttextData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCountsGold = {}\n",
    "for i in range(0,len(fasttextData)):\n",
    "    label = fasttextData[i].split()[0]\n",
    "    if label in labelCountsGold: labelCountsGold[label] += 1\n",
    "    else: labelCountsGold[label] = 1\n",
    "labelCountsGold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"baseline accuracy:\",round(max(labelCountsGold.values())/sum(labelCountsGold.values()),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCountsPredicted = {}\n",
    "for i in range(0,len(predictionLabels)):\n",
    "    for label in predictionLabels[i][0]:\n",
    "        if label[0] in labelCountsPredicted: labelCountsPredicted[label[0]] += 1\n",
    "        else: labelCountsPredicted[label[0]] = 1\n",
    "labelCountsPredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total absolute deviation\",sum([abs(labelCountsPredicted[l]-labelCountsGold[l]) for l in labelCountsGold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"relative deviation per label:\",\\\n",
    "      {l:round(abs(labelCountsPredicted[l]-labelCountsGold[l])/labelCountsGold[l],3) for l in labelCountsGold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeConfusionMatrix(fasttextData,predictionLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mondkapje data, fasttext predicts 63% of the labels correctly without external dictionary and 66% with a Wikipedia dictionary (baseline: 46%). It overestimates the presence of negative labels and underestimates the level of positive and neutral labels. The amount of irrelevant labels is about right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicationFactors = {}\n",
    "for label in labelCountsGold:\n",
    "    multiplicationFactors[label] = labelCountsGold[label]/labelCountsPredicted[label]\n",
    "multiplicationFactors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mondkapje tweets, the multiplication factor for the positive label is unrealistically high so we will not use these factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedNumberOfLabels = 0\n",
    "for label in labelCountsGold:\n",
    "    predictedNumberOfLabels += multiplicationFactors[label]*labelCountsPredicted[label]\n",
    "print(predictedNumberOfLabels,sum(labelCountsGold.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation data size - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "expResultsAll = {}\n",
    "for trainingSize in [100,200,500,1000,2000,5000,10000]:\n",
    "    expResultsTrainingSize = []\n",
    "    for i in range(0,N):\n",
    "        selection = ranSelect(fasttextData,trainingSize)\n",
    "        predictionCounts,predictionLabels = runFasttext(fasttextData,dim=BESTDIM,epoch=BESTEPOCH,lr=BESTLR,squealFlag=False,maxTrain=trainingSize)\n",
    "        expResultsTrainingSize.append(evaluate(predictionCounts,predictionLabels,fasttextData,printResults=False))\n",
    "    average = (np.average([x[0] for x in expResultsTrainingSize]),np.average([x[1] for x in expResultsTrainingSize]))\n",
    "    expResultsAll[len(selection)] = average\n",
    "    print(\"{0:4} {1:0.3f} {2:0.3f}\".format(len(selection),average[0],average[1]))\n",
    "    if len(selection) >= len(fasttextData): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(expResultsAll[list(expResultsAll.keys())[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "plt.plot(list(expResultsAll.keys()),[x[0] for x in list(expResultsAll.values())])\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"training data size\")\n",
    "plt.title(\"Accuracy related to training size\")\n",
    "\n",
    "ax1 = plt.subplot(122)\n",
    "plt.plot(list(expResultsAll.keys()),[x[1] for x in list(expResultsAll.values())])\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"fraction\")\n",
    "plt.xlabel(\"training data size\")\n",
    "plt.title(\"Rejects/Supports fraction related to training size\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying unlabeled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE = \"distance\"\n",
    "FACEMASK = \"mondkapje\"\n",
    "\n",
    "TOPIC = DISTANCE\n",
    "TOPIC = FACEMASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = \"/home/erikt/projects/puregome/data/\"\n",
    "DATADIRECTORY = BASEDIR+\"text/\"\n",
    "DATADIRECTORYREDDIT = BASEDIR+\"reddit/text/\"\n",
    "DATADIRECTORYNUNL = BASEDIR+\"nunl/text/\"\n",
    "TWITTER = \"twitter\"\n",
    "REDDIT = \"reddit\"\n",
    "NUNL = \"nunl\"\n",
    "SOURCES = [TWITTER,REDDIT,NUNL]\n",
    "DATADIRECTORIES = {TWITTER:DATADIRECTORY,REDDIT:DATADIRECTORYREDDIT,NUNL:DATADIRECTORYNUNL}\n",
    "FILEFASTTEXT = \"fasttext-\"+TOPIC+\".csv\"\n",
    "LABELPREFIX = \"__label__\"\n",
    "NEGATIVE = LABELPREFIX+\"NEGATIVE\"\n",
    "POSITIVE = LABELPREFIX+\"POSITIVE\"\n",
    "NEUTRAL = LABELPREFIX+\"NEUTRAL\"\n",
    "IRRELEVANT = LABELPREFIX+\"IRRELEVANT\"\n",
    "SUPPORTS = LABELPREFIX+\"SUPPORTS\"\n",
    "REJECTS = LABELPREFIX+\"REJECTS\"\n",
    "TEXT = \"text\"\n",
    "USER = \"user\"\n",
    "TOTAL = \"total\"\n",
    "DIM = BESTDIM\n",
    "EPOCH = BESTEPOCH\n",
    "LR = BESTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    text = re.sub(r\"\\\\n\",\" \",text)\n",
    "    text = re.sub(r\"https://\\S+\",\"\",text)\n",
    "    text = re.sub(r\"\\s+\",\" \",text)\n",
    "    text = text.strip()\n",
    "    return(text)\n",
    "\n",
    "def tokenize(text):\n",
    "    return(\" \".join(TweetTokenizer().tokenize(text)))\n",
    "\n",
    "def preprocess(text):\n",
    "    return(tokenize(cleanup(text)).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrepCommandFromQuery(query):\n",
    "    grepCommand = \"grep\"\n",
    "    for orPart in query.split(\"|\"):\n",
    "        grepCommand += ' -e \"'+orPart+'\"'\n",
    "    return(grepCommand)\n",
    "\n",
    "def readData(datePattern,query,dataDirectory=DATADIRECTORY):\n",
    "    fileList = sorted(os.listdir(dataDirectory))\n",
    "    testData = []\n",
    "    for inFileName in fileList:\n",
    "        if re.search(datePattern,inFileName) and os.path.exists(dataDirectory+inFileName):\n",
    "            try:\n",
    "                fileData = pd.read_csv(dataDirectory+inFileName).drop_duplicates()\n",
    "                matchedText = [line for line in fileData[TEXT] if re.search(query,line,flags=re.IGNORECASE)]\n",
    "                matchedTextPreprocessed = [preprocess(line) for line in matchedText]\n",
    "                testData.extend(matchedTextPreprocessed)\n",
    "            except:\n",
    "                pass\n",
    "    return(testData)\n",
    "    \n",
    "def classify(datePattern,query,model,dataDirectory=DATADIRECTORY):\n",
    "    testData = readData(datePattern,query,dataDirectory)\n",
    "    predictedLabels = model.predict(testData)\n",
    "    predictedGroups = pd.DataFrame(predictedLabels[0]).groupby(0).groups\n",
    "    labelCountsPredicted = {label:len(predictedGroups[label]) for label in predictedGroups}\n",
    "    nbrOfLabels = sum([labelCountsPredicted[label] for label in labelCountsPredicted if label != IRRELEVANT])\n",
    "    labelPercentages = { label:round(100*labelCountsPredicted[label]/nbrOfLabels,1) for label in labelCountsPredicted}\n",
    "    labelPercentages[TOTAL] = nbrOfLabels\n",
    "    return(labelPercentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXDAYSPERMONTH = 31\n",
    "\n",
    "if TOPIC == DISTANCE:\n",
    "    QUERY = \"1[.,]5[ -]*m|afstand.*hou|hou.*afstand|anderhalve[ -]*meter\"\n",
    "elif TOPIC == FACEMASK:\n",
    "    QUERY = TOPIC\n",
    "else:\n",
    "    print(\"unknown topic!\",file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "MAXDAYSPERMONTH = 31\n",
    "\n",
    "model = fasttext.train_supervised(FILEFASTTEXT,dim=BESTDIM,epoch=BESTEPOCH,lr=BESTLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "totals = {}\n",
    "for source in SOURCES:\n",
    "    dataDirectory = DATADIRECTORIES[source]\n",
    "    total = 0\n",
    "    results[source] = {}\n",
    "    for month in \"202002 202003 202004 202005 202006 202007\".split():\n",
    "        for day in range(1,MAXDAYSPERMONTH+1):\n",
    "            date = month+str(day).zfill(2)\n",
    "            try:\n",
    "                labels = classify(date,QUERY,model,dataDirectory=dataDirectory)\n",
    "                if not REJECTS in labels: labels[REJECTS] = 0\n",
    "                if not SUPPORTS in labels: labels[SUPPORTS] = 0\n",
    "                if not IRRELEVANT in labels: labels[IRRELEVANT] = 0\n",
    "                if labels[REJECTS]+labels[SUPPORTS]+labels[IRRELEVANT] > 0:\n",
    "                    results[source][date] = labels\n",
    "                    print(source,date,labels[REJECTS],labels[SUPPORTS],labels[IRRELEVANT],labels[TOTAL])\n",
    "                    total += labels[TOTAL]\n",
    "            except:\n",
    "                print(source,date,\"error\")\n",
    "    totals[source] = total\n",
    "    print(\"total relevant found:\",total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingAverage(numberList,size):\n",
    "    newList = []\n",
    "    for i in range(0,len(numberList)):\n",
    "        numberUsed = 1\n",
    "        newList.append(numberList[i])\n",
    "        for j in range(1,size):\n",
    "            if i-j >= 0:\n",
    "                newList[i] += numberList[i-j]\n",
    "                numberUsed += 1\n",
    "        newList[i] /= numberUsed\n",
    "    return(newList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEFORMAT = \"%Y%m%d\"\n",
    "DAYSCOMBINED = 7\n",
    "STARTDATE = \"20200310\"\n",
    "LABELS = {TWITTER:\"Twitter ({0})\".format(totals[TWITTER]),\\\n",
    "          NUNL:\"Nu.nl ({0})\".format(totals[NUNL]),\\\n",
    "          REDDIT:\"Reddit ({0})\".format(totals[REDDIT])}\n",
    "if TOPIC == DISTANCE:\n",
    "    PLOTFILENAME = \"social-distancing-all.png\"\n",
    "elif TOPIC == FACEMASK:\n",
    "    PLOTFILENAME = \"mondkapje-all.png\"\n",
    "else:\n",
    "    print(\"unknown topic!\",file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "x = {}\n",
    "ySupports = {}\n",
    "plt.subplots(figsize=(12,6))\n",
    "font = {\"size\":12}\n",
    "matplotlib.rc(\"font\",**font)\n",
    "ax = plt.subplot(111)\n",
    "for source in [REDDIT,NUNL,TWITTER]:\n",
    "    x[source] = [datetime.datetime.strptime(k,DATEFORMAT) for k in results[source].keys()]\n",
    "    ySupports[source] = movingAverage([results[source][k][SUPPORTS] for k in results[source].keys()],DAYSCOMBINED)\n",
    "    xPart = [x[source][i] for i in range(0,len(x[source])) if x[source][i] >= datetime.datetime.strptime(STARTDATE,DATEFORMAT)] \n",
    "    ySupportsPart = [ySupports[source][i] for i in range(0,len(x[source])) if x[source][i] >= datetime.datetime.strptime(STARTDATE,DATEFORMAT)] \n",
    "    plt.plot_date(xPart,ySupportsPart,fmt=\"-\",label=LABELS[source])\n",
    "plt.legend()\n",
    "plt.ylabel(\"percentage\")\n",
    "plt.xlabel(\"day/month\")\n",
    "if TOPIC == FACEMASK:\n",
    "    plt.title(\"Support for general public not wearing face masks per medium over time (average over \"+str(DAYSCOMBINED)+\" days)\")\n",
    "elif TOPIC == DISTANCE:\n",
    "    plt.title(\"Support for social distancing per medium over time (average over \"+str(DAYSCOMBINED)+\" days)\")\n",
    "else:\n",
    "    print(\"unknown topic!\",file=sys.stderr)\n",
    "    sys.exit(1)    \n",
    "plt.xticks([datetime.datetime.strptime(d,DATEFORMAT) for d in \"20200301 2020401 20200501 20200601 20200701 20200801\".split()])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "plt.savefig(PLOTFILENAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED = \"annotated\"\n",
    "ANNOTATEDFILE = \"manual-annotation.csv\"\n",
    "DATE = \"date\"\n",
    "EENS = \"EENS\"\n",
    "ONEENS = \"ONEENS\"\n",
    "ANDERS = \"ANDERS\"\n",
    "TOTAL = \"total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ANNOTATEDFILE,index_col=DATE,dtype={EENS:\"float\",ONEENS:\"float\",ANDERS:\"float\"})\n",
    "totals = []\n",
    "for i in range(0,len(df)):\n",
    "    total = df.iloc[i][EENS]+df.iloc[i][ONEENS]+df.iloc[i][ANDERS]\n",
    "    if df.iloc[i][EENS]+df.iloc[i][ONEENS] > 0:\n",
    "        df.iloc[i][EENS] = 100*df.iloc[i][EENS]/(total-df.iloc[i][ANDERS])\n",
    "        df.iloc[i][ONEENS] = 100*df.iloc[i][ONEENS]/(total-df.iloc[i][ANDERS])\n",
    "        df.iloc[i][ANDERS] = 100*df.iloc[i][ANDERS]/(total-df.iloc[i][ANDERS])\n",
    "    else: \n",
    "        df.iloc[i][ANDERS] = 100\n",
    "    totals.append(total)\n",
    "df[TOTAL] = totals\n",
    "annotatedDict = df.T.to_dict(orient=\"dict\")\n",
    "annotatedDict = {d:annotatedDict[d] for d in sorted(annotatedDict.keys())}\n",
    "results[ANNOTATED] = annotatedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTFILEANNOTATED = \"manual-annotation.png\"\n",
    "\n",
    "x = {}\n",
    "ySupports = {}\n",
    "plt.subplots(figsize=(12,6))\n",
    "font = {\"size\":12}\n",
    "matplotlib.rc(\"font\",**font)\n",
    "ax = plt.subplot(111)\n",
    "for source in [TWITTER]:\n",
    "    x[source] = [datetime.datetime.strptime(k,DATEFORMAT) for k in results[source].keys()]\n",
    "    ySupports[source] = movingAverage([results[source][k][SUPPORTS] for k in results[source].keys()],DAYSCOMBINED)\n",
    "    xPart = [x[source][i] for i in range(0,len(x[source])) if x[source][i] >= datetime.datetime.strptime(STARTDATE,DATEFORMAT)] \n",
    "    ySupportsPart = [ySupports[source][i] for i in range(0,len(x[source])) if x[source][i] >= datetime.datetime.strptime(STARTDATE,DATEFORMAT)] \n",
    "    plt.plot_date(xPart,ySupportsPart,fmt=\"-\",label=\"predicted\")\n",
    "for source in [ANNOTATED]:\n",
    "    x[source] = [datetime.datetime.strptime(str(k),DATEFORMAT) for k in results[source].keys()]\n",
    "    ySupports[source] = movingAverage([results[source][k][EENS] for k in results[source].keys()],DAYSCOMBINED)\n",
    "    xPart = [x[source][i] for i in range(0,len(x[source])) if x[source][i] >= datetime.datetime.strptime(STARTDATE,DATEFORMAT)] \n",
    "    ySupportsPart = [ySupports[source][i] for i in range(0,len(x[source])) if x[source][i] >= datetime.datetime.strptime(STARTDATE,DATEFORMAT)] \n",
    "    plt.plot_date(xPart,ySupportsPart,fmt=\"-\",label=ANNOTATED)\n",
    "plt.title(\"Support for social distancing per medium over time (average over \"+str(DAYSCOMBINED)+\" days)\")\n",
    "plt.legend()\n",
    "plt.savefig(PLOTFILEANNOTATED)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotatedValues = []\n",
    "twitterValues = []\n",
    "\n",
    "for i in range(0,len(x[TWITTER])):\n",
    "    date = x[TWITTER][i]\n",
    "    if date >= datetime.datetime.strptime(\"20200310\",DATEFORMAT):\n",
    "        for j in range(0,len(x[ANNOTATED])):\n",
    "            if x[ANNOTATED][j] == date:\n",
    "                twitterValues.append(ySupports[TWITTER][i])\n",
    "                annotatedValues.append(ySupports[ANNOTATED][j])\n",
    "np.corrcoef(annotatedValues,twitterValues)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTFILENAME = \"plot.png\"\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(annotatedValues,twitterValues)\n",
    "plt.ylabel(\"Predicted support percentages\")\n",
    "plt.xlabel(\"Annotated support percentages\")\n",
    "plt.title(\"Annotated and predicted support for social distancing\")\n",
    "plt.savefig(PLOTFILENAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = results\n",
    "results = results[TWITTER]\n",
    "x = [datetime.datetime.strptime(k,DATEFORMAT) for k in results.keys()]\n",
    "ySupports = movingAverage([results[k][SUPPORTS] for k in results.keys()],DAYSCOMBINED)\n",
    "yRejects = movingAverage([results[k][REJECTS] for k in results.keys()],DAYSCOMBINED)\n",
    "yIrrelevant = movingAverage([results[k][IRRELEVANT] for k in results.keys()],DAYSCOMBINED)\n",
    "\n",
    "keyDates = []\n",
    "for i in range(0,len(yIrrelevant)):\n",
    "    if i < len(yIrrelevant)-1 and \\\n",
    "       (yIrrelevant[i] < 100 and yIrrelevant[i+1] >= 100 or yIrrelevant[i] >= 100 and yIrrelevant[i+1] < 100):\n",
    "        keyDates.append(list(results.keys())[i])\n",
    "        print(keyDates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTDATE = \"20200310\" # keyDates[0]\n",
    "ENDDATE = \"20201231\"\n",
    "PLOTFILEOUT = \"social-distancing.png\"\n",
    "PLOTFILEOUT = \"mondkapje.png\"\n",
    "\n",
    "results = {k:results[k] for k in sorted(results.keys())}\n",
    "font = {\"size\":14}\n",
    "matplotlib.rc(\"font\",**font)\n",
    "plt.subplots(figsize=(14,7))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "plt.plot_date(x,ySupports,fmt=\"-\",label=\"Supports\")\n",
    "plt.plot_date(x,yRejects,fmt=\"-\",label=\"Rejects\")\n",
    "plt.plot_date(x,yIrrelevant,fmt=\"-\",label=\"Other\")\n",
    "plt.plot_date(x,[100 for i in x],fmt=\"-\",label=\"100%\",color=\"black\")\n",
    "for date in [STARTDATE]:\n",
    "    plt.plot_date([datetime.datetime.strptime(date,DATEFORMAT)],[100],color=\"black\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"percentage\")\n",
    "plt.xlabel(\"day/month\")\n",
    "plt.title(\"stance on the RIVM policy on \"+\"social\")\n",
    "\n",
    "dates = [d for d in results.keys()]\n",
    "xPart = [x[i] for i in range(0,len(dates)) if dates[i] >= STARTDATE and dates[i] <= ENDDATE]\n",
    "ySupportsPart = [ySupports[i] for i in range(0,len(dates)) if dates[i] >= STARTDATE and dates[i] <= ENDDATE] \n",
    "yRejectsPart = [yRejects[i] for i in range(0,len(dates)) if dates[i] >= STARTDATE and dates[i] <= ENDDATE]\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "plt.plot_date(xPart,ySupportsPart,fmt=\"-\",label=\"Supports\")\n",
    "plt.plot_date(xPart,yRejectsPart,fmt=\"-\",label=\"Rejects\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"percentage\")\n",
    "plt.xlabel(\"day/month\")\n",
    "plt.title(\"Nu.nl on social distancing (average over \"+str(DAYSCOMBINED)+\" days)\")\n",
    "plt.xticks([datetime.datetime.strptime(d,DATEFORMAT) for d in \"20200301 2020401 20200501 20200601 20200701 20200801\".split()])\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "\n",
    "plt.savefig(PLOTFILEOUT)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for text in fasttextData:\n",
    "    label = text.split()[0]\n",
    "    if label in counts: counts[label] += 1\n",
    "    else: counts[label] = 1\n",
    "for label in counts: print(round(counts[label]/len(fasttextData),3),label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotator comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFTESTDATA = 100\n",
    "\n",
    "annotators = []\n",
    "annotatorData = {}\n",
    "kappaData = [{},{}]\n",
    "blockedTweetIds = {}\n",
    "for i in range(0,len(annotations)):\n",
    "    annotator = annotations.iloc[i][0]\n",
    "    tweetId = annotations.iloc[i][2]\n",
    "    tweetLabel = annotations.iloc[i][4]\n",
    "    if not annotator in annotatorData: \n",
    "        annotatorData[annotator] = {}\n",
    "        annotators.append(annotator)\n",
    "    annotatorData[annotator][tweetId] = tweetLabel\n",
    "    if len(annotatorData[annotator]) <= NBROFTESTDATA: blockedTweetIds[tweetId] = True\n",
    "    if len(annotators) >= 2 and not tweetId in blockedTweetIds and \\\n",
    "       tweetId in annotatorData[annotators[0]] and tweetId in annotatorData[annotators[1]]:\n",
    "        kappaData[0][tweetId] = annotatorData[annotators[0]][tweetId]\n",
    "        kappaData[1][tweetId] = annotatorData[annotators[1]][tweetId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotator in annotatorData:\n",
    "    labelCount = {}\n",
    "    for tweetId in annotatorData[annotator]:\n",
    "        label = annotatorData[annotator][tweetId]\n",
    "        if not label in labelCount: labelCount[label] = 0\n",
    "        labelCount[label] += 1\n",
    "    print(len(annotatorData[annotator]))\n",
    "    for label in labelCount: print(round(labelCount[label]/len(annotatorData[annotator]),3),label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cohen_kappa_score([kappaData[0][tweetId] for tweetId in kappaData[0]],[kappaData[1][tweetId] for tweetId in kappaData[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 100\n",
    "\n",
    "total = 0\n",
    "identical = 0\n",
    "for tweetId in annotatorData[mainAnnotator]:\n",
    "    for annotator in annotators:\n",
    "        if not annotator == mainAnnotator and tweetId in annotatorData[annotator]:\n",
    "            total += 1\n",
    "            if total <= MAX:\n",
    "                if annotatorData[annotator][tweetId] == annotatorData[mainAnnotator][tweetId]: identical += 1\n",
    "                else: \n",
    "                    print(tweetId,annotatorData[mainAnnotator][tweetId],annotatorData[annotator][tweetId])\n",
    "                    #print(tweets.loc[tweetId][TEXT])\n",
    "print(total,identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
