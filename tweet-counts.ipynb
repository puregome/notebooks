{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count terms appearing in tweets\n",
    "\n",
    "This notebook produces the graph with frequency counts of Dutch tweets related to the COVID-19 crisis. It relies on the texts of the tweets in the directory data/text and will count all the tweets in that directory. The notebook should be run every month after the tweets in the directory have been updated. Tweet counts are cached but generating the counts for one month will still take more than seven hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "DATADIR = \"../data/text/\"\n",
    "CSVDIR = \"csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"text\"\n",
    "FULLTEXT = \"full_text\"\n",
    "EXTENDEDTWEET = \"extended_tweet\"\n",
    "RETWEETEDSTATUS = \"retweeted_status\"\n",
    "\n",
    "def getTweetText(jsonData):\n",
    "    text = \"\"\n",
    "    if TEXT in jsonData: \n",
    "        text = jsonData[TEXT]\n",
    "    if EXTENDEDTWEET in jsonData and \\\n",
    "       FULLTEXT in jsonData[EXTENDEDTWEET]:\n",
    "        text = jsonData[EXTENDEDTWEET][FULLTEXT]\n",
    "    if RETWEETEDSTATUS in jsonData and \\\n",
    "       EXTENDEDTWEET in jsonData[RETWEETEDSTATUS] and \\\n",
    "       FULLTEXT in jsonData[RETWEETEDSTATUS][EXTENDEDTWEET]:\n",
    "        text = jsonData[RETWEETEDSTATUS][EXTENDEDTWEET][FULLTEXT]\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "DATEFORMAT = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "SUMMERTIMEDATE = datetime.strptime(\"Sun Mar 29 02:00:00 +0000 2020\",DATEFORMAT)\n",
    "WINTERTIMEDATE = datetime.strptime(\"Sun Oct 25 03:00:00 +0000 2020\",DATEFORMAT)\n",
    "\n",
    "def getTweetDate(jsonData):\n",
    "    dateString = jsonData[\"created_at\"]\n",
    "    dateData = datetime.strptime(dateString,DATEFORMAT)+timedelta(hours=1)\n",
    "    if dateData >= SUMMERTIMEDATE:\n",
    "        if dateData >= WINTERTIMEDATE: sys.exit(\"cannot happen\")\n",
    "        dateData += timedelta(hours=1)\n",
    "    return(int(dateData.strftime(\"%Y%m%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSVSUFFIX = \".csv\"\n",
    "DUTCH = \"nl\"\n",
    "IDSTR = \"id_str\"\n",
    "TOPIC = \"topic\"\n",
    "DISTANCE = \"distance\"\n",
    "LOCKDOWN = \"lockdown\"\n",
    "VACCIN = \"vaccin\"\n",
    "TEST = \"test\"\n",
    "TOPICQUERY = \"corona|covid|huisarts|mondkapje|rivm|blijfthuis|flattenthecurve|houvol\"\n",
    "DISTANCEQUERY = \"1[.,]5[ -]*m|afstand.*hou|hou.*afstand|anderhalve[ -]*meter\"\n",
    "LOCKDOWNQUERY = \"lock.down|lockdown\"\n",
    "VACCINQUERY = \"vaccin|pfizer|ingeÃ«nt|ingeent|inent|prik|spuit|bijwerking|-->|ðŸ’‰\"\n",
    "TESTQUERY = r'\\btest|getest|sneltest|pcr'\n",
    "\n",
    "fileNames = sorted(os.listdir(DATADIR))\n",
    "\n",
    "def saveCounts(counts,outFileName):\n",
    "    pd.DataFrame.from_dict(counts,orient=\"index\").to_csv(CSVDIR+outFileName,header=False)\n",
    "\n",
    "def readCounts(inFileName):\n",
    "    countsDf = pd.read_csv(CSVDIR+inFileName,header=None,index_col=0)\n",
    "    return(countsDf.to_dict()[1])\n",
    "\n",
    "def combineDicts(a,b):\n",
    "    return(dict(list(a.items())+list(b.items())))\n",
    "\n",
    "def search(query,countsIn):\n",
    "    countsOut = {}\n",
    "    countsInKeys = [ str(x) for x in countsIn ]\n",
    "    seen = {}\n",
    "    for inFileName in fileNames:\n",
    "        date = inFileName[0:8]\n",
    "        if re.search(r\"2*z\",inFileName) and not date in countsInKeys:\n",
    "            inFile = gzip.open(DATADIR+inFileName,mode=\"rt\")\n",
    "            for line in inFile:\n",
    "                jsonData = json.loads(line)\n",
    "                tweetText = getTweetText(jsonData)\n",
    "                tweetDate = getTweetDate(jsonData)\n",
    "                tweetLang = jsonData[\"lang\"]\n",
    "                if tweetLang == DUTCH and re.search(query,tweetText,flags=re.IGNORECASE):\n",
    "                    if tweetDate in countsOut: countsOut[tweetDate] += 1\n",
    "                    else: countsOut[tweetDate] = 1\n",
    "            inFile.close()\n",
    "            if not date in seen:\n",
    "                print(date)\n",
    "                seen[date] = True\n",
    "    countsOut = combineDicts(countsIn,countsOut)\n",
    "    countsOut = {k:v for k, v in sorted(countsOut.items(), key=lambda item: item[0])}\n",
    "    return(countsOut)\n",
    "\n",
    "def searchText(query,countsIn):\n",
    "    countsOut = {}\n",
    "    countsInKeys = [ str(x) for x in countsIn ]\n",
    "    if query == TOPIC: query = TOPICQUERY\n",
    "    elif query == DISTANCE: query = DISTANCEQUERY\n",
    "    elif query == LOCKDOWN: query = LOCKDOWNQUERY\n",
    "    elif query == VACCIN: query = VACCINQUERY\n",
    "    elif query == TEST: query = TESTQUERY\n",
    "    for inFileName in fileNames:\n",
    "        date = inFileName[0:8]\n",
    "        if re.search(r\"2*z\",inFileName) and not date in countsInKeys and inFileName > \"20200201\":\n",
    "            if not date in countsOut: \n",
    "                countsOut[date] = 0\n",
    "                print(date,query)\n",
    "            df = pd.read_csv(DATADIR+inFileName,index_col=IDSTR)\n",
    "            countsOut[date] += len(df[df[TEXT].str.contains(query, flags=re.IGNORECASE)])\n",
    "            #for i in range(0,len(df)):\n",
    "            #    if re.search(query,str(df.iloc[i][TEXT]).lower()):\n",
    "            #        countsOut[date] += 1\n",
    "    countsOut = combineDicts(countsIn,countsOut)\n",
    "    countsOut = {str(k):v for k, v in sorted(countsOut.items(), key=lambda item: str(item[0]))}\n",
    "    return(countsOut)\n",
    "\n",
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201014-19.out.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-76d9f23232dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmonth_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"counts\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hours\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dates\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATADIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmonth_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"counts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmonth_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hours\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   2556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2558\u001b[0;31m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2559\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   3303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3304\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3305\u001b[0;31m                             \u001b[0mnew_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3306\u001b[0m                             \u001b[0mrows\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m   3014\u001b[0m         \"\"\"\n\u001b[1;32m   3015\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3016\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3017\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "month_data = {}\n",
    "for file_name in fileNames:\n",
    "    if re.search(\"^20201\",file_name):\n",
    "        squeal(file_name)\n",
    "        month = file_name[:6]\n",
    "        if not month in month_data:\n",
    "            month_data[month] = { \"counts\":0, \"hours\":0, \"dates\":{} }  \n",
    "        df = pd.read_csv(DATADIR+file_name, compression=\"gzip\", engine=\"python\")\n",
    "        month_data[month][\"counts\"] += len(df)\n",
    "        month_data[month][\"hours\"] += 1\n",
    "        date = file_name[:8]\n",
    "        month_data[month][\"dates\"][date] = True\n",
    "\n",
    "for month in month_data: # extra hour for change to Winter time\n",
    "    if re.search(\"10$\",month): month_data[month][\"hours\"] += 1\n",
    "\n",
    "{m:[month_data[m][\"counts\"], int(month_data[m][\"counts\"]/len(month_data[m][\"dates\"])), int(month_data[m][\"counts\"]/month_data[m][\"hours\"])] for m in month_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivm = readCounts(\"rivm.csv\")\n",
    "corona = readCounts(\"corona.csv\")\n",
    "covid = readCounts(\"covid.csv\")\n",
    "mondkapje = readCounts(\"mondkapje.csv\")\n",
    "topic = readCounts(TOPIC+CSVSUFFIX)\n",
    "distance = readCounts(DISTANCE+CSVSUFFIX)\n",
    "lockdown = readCounts(LOCKDOWN+CSVSUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200201 \\btest|getest|sneltest|pcr\n",
      "20200202 \\btest|getest|sneltest|pcr\n",
      "20200203 \\btest|getest|sneltest|pcr\n",
      "20200204 \\btest|getest|sneltest|pcr\n",
      "20200205 \\btest|getest|sneltest|pcr\n",
      "20200206 \\btest|getest|sneltest|pcr\n",
      "20200207 \\btest|getest|sneltest|pcr\n",
      "20200208 \\btest|getest|sneltest|pcr\n",
      "20200209 \\btest|getest|sneltest|pcr\n",
      "20200210 \\btest|getest|sneltest|pcr\n",
      "20200211 \\btest|getest|sneltest|pcr\n",
      "20200212 \\btest|getest|sneltest|pcr\n",
      "20200213 \\btest|getest|sneltest|pcr\n",
      "20200214 \\btest|getest|sneltest|pcr\n",
      "20200215 \\btest|getest|sneltest|pcr\n",
      "20200216 \\btest|getest|sneltest|pcr\n",
      "20200217 \\btest|getest|sneltest|pcr\n",
      "20200218 \\btest|getest|sneltest|pcr\n",
      "20200219 \\btest|getest|sneltest|pcr\n",
      "20200220 \\btest|getest|sneltest|pcr\n",
      "20200221 \\btest|getest|sneltest|pcr\n",
      "20200222 \\btest|getest|sneltest|pcr\n",
      "20200223 \\btest|getest|sneltest|pcr\n",
      "20200224 \\btest|getest|sneltest|pcr\n",
      "20200225 \\btest|getest|sneltest|pcr\n",
      "20200226 \\btest|getest|sneltest|pcr\n",
      "20200227 \\btest|getest|sneltest|pcr\n",
      "20200228 \\btest|getest|sneltest|pcr\n",
      "20200229 \\btest|getest|sneltest|pcr\n",
      "20200301 \\btest|getest|sneltest|pcr\n",
      "20200302 \\btest|getest|sneltest|pcr\n",
      "20200303 \\btest|getest|sneltest|pcr\n",
      "20200304 \\btest|getest|sneltest|pcr\n",
      "20200305 \\btest|getest|sneltest|pcr\n",
      "20200306 \\btest|getest|sneltest|pcr\n",
      "20200307 \\btest|getest|sneltest|pcr\n",
      "20200308 \\btest|getest|sneltest|pcr\n",
      "20200309 \\btest|getest|sneltest|pcr\n",
      "20200310 \\btest|getest|sneltest|pcr\n",
      "20200311 \\btest|getest|sneltest|pcr\n",
      "20200312 \\btest|getest|sneltest|pcr\n",
      "20200313 \\btest|getest|sneltest|pcr\n",
      "20200314 \\btest|getest|sneltest|pcr\n",
      "20200315 \\btest|getest|sneltest|pcr\n",
      "20200316 \\btest|getest|sneltest|pcr\n",
      "20200317 \\btest|getest|sneltest|pcr\n",
      "20200318 \\btest|getest|sneltest|pcr\n",
      "20200319 \\btest|getest|sneltest|pcr\n",
      "20200320 \\btest|getest|sneltest|pcr\n",
      "20200321 \\btest|getest|sneltest|pcr\n",
      "20200322 \\btest|getest|sneltest|pcr\n",
      "20200323 \\btest|getest|sneltest|pcr\n",
      "20200324 \\btest|getest|sneltest|pcr\n",
      "20200325 \\btest|getest|sneltest|pcr\n",
      "20200326 \\btest|getest|sneltest|pcr\n",
      "20200327 \\btest|getest|sneltest|pcr\n",
      "20200328 \\btest|getest|sneltest|pcr\n",
      "20200329 \\btest|getest|sneltest|pcr\n",
      "20200330 \\btest|getest|sneltest|pcr\n",
      "20200331 \\btest|getest|sneltest|pcr\n",
      "20200401 \\btest|getest|sneltest|pcr\n",
      "20200402 \\btest|getest|sneltest|pcr\n",
      "20200403 \\btest|getest|sneltest|pcr\n",
      "20200404 \\btest|getest|sneltest|pcr\n",
      "20200405 \\btest|getest|sneltest|pcr\n",
      "20200406 \\btest|getest|sneltest|pcr\n",
      "20200407 \\btest|getest|sneltest|pcr\n",
      "20200408 \\btest|getest|sneltest|pcr\n",
      "20200409 \\btest|getest|sneltest|pcr\n",
      "20200410 \\btest|getest|sneltest|pcr\n",
      "20200411 \\btest|getest|sneltest|pcr\n",
      "20200412 \\btest|getest|sneltest|pcr\n",
      "20200413 \\btest|getest|sneltest|pcr\n",
      "20200414 \\btest|getest|sneltest|pcr\n",
      "20200415 \\btest|getest|sneltest|pcr\n",
      "20200416 \\btest|getest|sneltest|pcr\n",
      "20200417 \\btest|getest|sneltest|pcr\n",
      "20200418 \\btest|getest|sneltest|pcr\n",
      "20200419 \\btest|getest|sneltest|pcr\n",
      "20200420 \\btest|getest|sneltest|pcr\n",
      "20200421 \\btest|getest|sneltest|pcr\n",
      "20200422 \\btest|getest|sneltest|pcr\n",
      "20200423 \\btest|getest|sneltest|pcr\n",
      "20200424 \\btest|getest|sneltest|pcr\n",
      "20200425 \\btest|getest|sneltest|pcr\n",
      "20200426 \\btest|getest|sneltest|pcr\n",
      "20200427 \\btest|getest|sneltest|pcr\n",
      "20200428 \\btest|getest|sneltest|pcr\n",
      "20200429 \\btest|getest|sneltest|pcr\n",
      "20200430 \\btest|getest|sneltest|pcr\n",
      "20200501 \\btest|getest|sneltest|pcr\n",
      "20200502 \\btest|getest|sneltest|pcr\n",
      "20200503 \\btest|getest|sneltest|pcr\n",
      "20200504 \\btest|getest|sneltest|pcr\n",
      "20200505 \\btest|getest|sneltest|pcr\n",
      "20200506 \\btest|getest|sneltest|pcr\n",
      "20200507 \\btest|getest|sneltest|pcr\n",
      "20200508 \\btest|getest|sneltest|pcr\n",
      "20200509 \\btest|getest|sneltest|pcr\n",
      "20200510 \\btest|getest|sneltest|pcr\n",
      "20200511 \\btest|getest|sneltest|pcr\n",
      "20200512 \\btest|getest|sneltest|pcr\n",
      "20200513 \\btest|getest|sneltest|pcr\n",
      "20200514 \\btest|getest|sneltest|pcr\n",
      "20200515 \\btest|getest|sneltest|pcr\n",
      "20200516 \\btest|getest|sneltest|pcr\n",
      "20200517 \\btest|getest|sneltest|pcr\n",
      "20200518 \\btest|getest|sneltest|pcr\n",
      "20200519 \\btest|getest|sneltest|pcr\n",
      "20200520 \\btest|getest|sneltest|pcr\n",
      "20200521 \\btest|getest|sneltest|pcr\n",
      "20200522 \\btest|getest|sneltest|pcr\n",
      "20200523 \\btest|getest|sneltest|pcr\n",
      "20200524 \\btest|getest|sneltest|pcr\n",
      "20200525 \\btest|getest|sneltest|pcr\n",
      "20200526 \\btest|getest|sneltest|pcr\n",
      "20200527 \\btest|getest|sneltest|pcr\n",
      "20200528 \\btest|getest|sneltest|pcr\n",
      "20200529 \\btest|getest|sneltest|pcr\n",
      "20200530 \\btest|getest|sneltest|pcr\n",
      "20200531 \\btest|getest|sneltest|pcr\n",
      "20200601 \\btest|getest|sneltest|pcr\n",
      "20200602 \\btest|getest|sneltest|pcr\n",
      "20200603 \\btest|getest|sneltest|pcr\n",
      "20200604 \\btest|getest|sneltest|pcr\n",
      "20200605 \\btest|getest|sneltest|pcr\n",
      "20200606 \\btest|getest|sneltest|pcr\n",
      "20200607 \\btest|getest|sneltest|pcr\n",
      "20200608 \\btest|getest|sneltest|pcr\n",
      "20200609 \\btest|getest|sneltest|pcr\n",
      "20200610 \\btest|getest|sneltest|pcr\n",
      "20200611 \\btest|getest|sneltest|pcr\n",
      "20200612 \\btest|getest|sneltest|pcr\n",
      "20200613 \\btest|getest|sneltest|pcr\n",
      "20200614 \\btest|getest|sneltest|pcr\n",
      "20200615 \\btest|getest|sneltest|pcr\n",
      "20200616 \\btest|getest|sneltest|pcr\n",
      "20200617 \\btest|getest|sneltest|pcr\n",
      "20200618 \\btest|getest|sneltest|pcr\n",
      "20200619 \\btest|getest|sneltest|pcr\n",
      "20200620 \\btest|getest|sneltest|pcr\n",
      "20200621 \\btest|getest|sneltest|pcr\n",
      "20200622 \\btest|getest|sneltest|pcr\n",
      "20200623 \\btest|getest|sneltest|pcr\n",
      "20200624 \\btest|getest|sneltest|pcr\n",
      "20200625 \\btest|getest|sneltest|pcr\n",
      "20200626 \\btest|getest|sneltest|pcr\n",
      "20200627 \\btest|getest|sneltest|pcr\n",
      "20200628 \\btest|getest|sneltest|pcr\n",
      "20200629 \\btest|getest|sneltest|pcr\n",
      "20200630 \\btest|getest|sneltest|pcr\n",
      "20200701 \\btest|getest|sneltest|pcr\n",
      "20200702 \\btest|getest|sneltest|pcr\n",
      "20200703 \\btest|getest|sneltest|pcr\n",
      "20200704 \\btest|getest|sneltest|pcr\n",
      "20200705 \\btest|getest|sneltest|pcr\n",
      "20200706 \\btest|getest|sneltest|pcr\n",
      "20200707 \\btest|getest|sneltest|pcr\n",
      "20200708 \\btest|getest|sneltest|pcr\n",
      "20200709 \\btest|getest|sneltest|pcr\n",
      "20200710 \\btest|getest|sneltest|pcr\n",
      "20200711 \\btest|getest|sneltest|pcr\n",
      "20200712 \\btest|getest|sneltest|pcr\n",
      "20200713 \\btest|getest|sneltest|pcr\n",
      "20200714 \\btest|getest|sneltest|pcr\n",
      "20200715 \\btest|getest|sneltest|pcr\n",
      "20200716 \\btest|getest|sneltest|pcr\n",
      "20200717 \\btest|getest|sneltest|pcr\n",
      "20200718 \\btest|getest|sneltest|pcr\n",
      "20200719 \\btest|getest|sneltest|pcr\n",
      "20200720 \\btest|getest|sneltest|pcr\n",
      "20200721 \\btest|getest|sneltest|pcr\n",
      "20200722 \\btest|getest|sneltest|pcr\n",
      "20200723 \\btest|getest|sneltest|pcr\n",
      "20200724 \\btest|getest|sneltest|pcr\n",
      "20200725 \\btest|getest|sneltest|pcr\n",
      "20200726 \\btest|getest|sneltest|pcr\n",
      "20200727 \\btest|getest|sneltest|pcr\n",
      "20200728 \\btest|getest|sneltest|pcr\n",
      "20200729 \\btest|getest|sneltest|pcr\n",
      "20200730 \\btest|getest|sneltest|pcr\n",
      "20200731 \\btest|getest|sneltest|pcr\n",
      "20200801 \\btest|getest|sneltest|pcr\n",
      "20200802 \\btest|getest|sneltest|pcr\n",
      "20200803 \\btest|getest|sneltest|pcr\n",
      "20200804 \\btest|getest|sneltest|pcr\n",
      "20200805 \\btest|getest|sneltest|pcr\n",
      "20200806 \\btest|getest|sneltest|pcr\n",
      "20200807 \\btest|getest|sneltest|pcr\n",
      "20200808 \\btest|getest|sneltest|pcr\n",
      "20200809 \\btest|getest|sneltest|pcr\n",
      "20200810 \\btest|getest|sneltest|pcr\n",
      "20200811 \\btest|getest|sneltest|pcr\n",
      "20200812 \\btest|getest|sneltest|pcr\n",
      "20200813 \\btest|getest|sneltest|pcr\n",
      "20200814 \\btest|getest|sneltest|pcr\n",
      "20200815 \\btest|getest|sneltest|pcr\n",
      "20200816 \\btest|getest|sneltest|pcr\n",
      "20200817 \\btest|getest|sneltest|pcr\n",
      "20200818 \\btest|getest|sneltest|pcr\n",
      "20200819 \\btest|getest|sneltest|pcr\n",
      "20200820 \\btest|getest|sneltest|pcr\n",
      "20200821 \\btest|getest|sneltest|pcr\n",
      "20200822 \\btest|getest|sneltest|pcr\n",
      "20200823 \\btest|getest|sneltest|pcr\n",
      "20200824 \\btest|getest|sneltest|pcr\n",
      "20200825 \\btest|getest|sneltest|pcr\n",
      "20200826 \\btest|getest|sneltest|pcr\n",
      "20200827 \\btest|getest|sneltest|pcr\n",
      "20200828 \\btest|getest|sneltest|pcr\n",
      "20200829 \\btest|getest|sneltest|pcr\n",
      "20200830 \\btest|getest|sneltest|pcr\n",
      "20200831 \\btest|getest|sneltest|pcr\n",
      "20200901 \\btest|getest|sneltest|pcr\n",
      "20200902 \\btest|getest|sneltest|pcr\n",
      "20200903 \\btest|getest|sneltest|pcr\n",
      "20200904 \\btest|getest|sneltest|pcr\n",
      "20200905 \\btest|getest|sneltest|pcr\n",
      "20200906 \\btest|getest|sneltest|pcr\n",
      "20200907 \\btest|getest|sneltest|pcr\n",
      "20200908 \\btest|getest|sneltest|pcr\n",
      "20200909 \\btest|getest|sneltest|pcr\n",
      "20200910 \\btest|getest|sneltest|pcr\n",
      "20200911 \\btest|getest|sneltest|pcr\n",
      "20200912 \\btest|getest|sneltest|pcr\n",
      "20200913 \\btest|getest|sneltest|pcr\n",
      "20200914 \\btest|getest|sneltest|pcr\n",
      "20200915 \\btest|getest|sneltest|pcr\n",
      "20200916 \\btest|getest|sneltest|pcr\n",
      "20200917 \\btest|getest|sneltest|pcr\n",
      "20200918 \\btest|getest|sneltest|pcr\n",
      "20200919 \\btest|getest|sneltest|pcr\n",
      "20200920 \\btest|getest|sneltest|pcr\n",
      "20200921 \\btest|getest|sneltest|pcr\n",
      "20200922 \\btest|getest|sneltest|pcr\n",
      "20200923 \\btest|getest|sneltest|pcr\n",
      "20200924 \\btest|getest|sneltest|pcr\n",
      "20200925 \\btest|getest|sneltest|pcr\n",
      "20200926 \\btest|getest|sneltest|pcr\n",
      "20200927 \\btest|getest|sneltest|pcr\n",
      "20200928 \\btest|getest|sneltest|pcr\n",
      "20200929 \\btest|getest|sneltest|pcr\n",
      "20200930 \\btest|getest|sneltest|pcr\n",
      "20201001 \\btest|getest|sneltest|pcr\n",
      "20201002 \\btest|getest|sneltest|pcr\n",
      "20201003 \\btest|getest|sneltest|pcr\n",
      "20201004 \\btest|getest|sneltest|pcr\n",
      "20201005 \\btest|getest|sneltest|pcr\n",
      "20201006 \\btest|getest|sneltest|pcr\n",
      "20201007 \\btest|getest|sneltest|pcr\n",
      "20201008 \\btest|getest|sneltest|pcr\n",
      "20201009 \\btest|getest|sneltest|pcr\n",
      "20201010 \\btest|getest|sneltest|pcr\n",
      "20201011 \\btest|getest|sneltest|pcr\n",
      "20201012 \\btest|getest|sneltest|pcr\n",
      "20201013 \\btest|getest|sneltest|pcr\n",
      "20201014 \\btest|getest|sneltest|pcr\n",
      "20201015 \\btest|getest|sneltest|pcr\n",
      "20201016 \\btest|getest|sneltest|pcr\n",
      "20201017 \\btest|getest|sneltest|pcr\n",
      "20201018 \\btest|getest|sneltest|pcr\n",
      "20201019 \\btest|getest|sneltest|pcr\n",
      "20201020 \\btest|getest|sneltest|pcr\n",
      "20201021 \\btest|getest|sneltest|pcr\n",
      "20201022 \\btest|getest|sneltest|pcr\n",
      "20201023 \\btest|getest|sneltest|pcr\n",
      "20201024 \\btest|getest|sneltest|pcr\n",
      "20201025 \\btest|getest|sneltest|pcr\n",
      "20201026 \\btest|getest|sneltest|pcr\n",
      "20201027 \\btest|getest|sneltest|pcr\n",
      "20201028 \\btest|getest|sneltest|pcr\n",
      "20201029 \\btest|getest|sneltest|pcr\n",
      "20201030 \\btest|getest|sneltest|pcr\n",
      "20201031 \\btest|getest|sneltest|pcr\n",
      "20201101 \\btest|getest|sneltest|pcr\n",
      "20201102 \\btest|getest|sneltest|pcr\n",
      "20201103 \\btest|getest|sneltest|pcr\n",
      "20201104 \\btest|getest|sneltest|pcr\n",
      "20201105 \\btest|getest|sneltest|pcr\n",
      "20201106 \\btest|getest|sneltest|pcr\n",
      "20201107 \\btest|getest|sneltest|pcr\n",
      "20201108 \\btest|getest|sneltest|pcr\n",
      "20201109 \\btest|getest|sneltest|pcr\n",
      "20201110 \\btest|getest|sneltest|pcr\n",
      "20201111 \\btest|getest|sneltest|pcr\n",
      "20201112 \\btest|getest|sneltest|pcr\n",
      "20201113 \\btest|getest|sneltest|pcr\n",
      "20201114 \\btest|getest|sneltest|pcr\n",
      "20201115 \\btest|getest|sneltest|pcr\n",
      "20201116 \\btest|getest|sneltest|pcr\n",
      "20201117 \\btest|getest|sneltest|pcr\n",
      "20201118 \\btest|getest|sneltest|pcr\n",
      "20201119 \\btest|getest|sneltest|pcr\n",
      "20201120 \\btest|getest|sneltest|pcr\n",
      "20201121 \\btest|getest|sneltest|pcr\n",
      "20201122 \\btest|getest|sneltest|pcr\n",
      "20201123 \\btest|getest|sneltest|pcr\n",
      "20201124 \\btest|getest|sneltest|pcr\n",
      "20201125 \\btest|getest|sneltest|pcr\n",
      "20201126 \\btest|getest|sneltest|pcr\n",
      "20201127 \\btest|getest|sneltest|pcr\n",
      "20201128 \\btest|getest|sneltest|pcr\n",
      "20201129 \\btest|getest|sneltest|pcr\n",
      "20201130 \\btest|getest|sneltest|pcr\n",
      "20201201 \\btest|getest|sneltest|pcr\n",
      "20201202 \\btest|getest|sneltest|pcr\n",
      "20201203 \\btest|getest|sneltest|pcr\n",
      "20201204 \\btest|getest|sneltest|pcr\n",
      "20201205 \\btest|getest|sneltest|pcr\n",
      "20201206 \\btest|getest|sneltest|pcr\n",
      "20201207 \\btest|getest|sneltest|pcr\n",
      "20201208 \\btest|getest|sneltest|pcr\n",
      "20201209 \\btest|getest|sneltest|pcr\n",
      "20201210 \\btest|getest|sneltest|pcr\n",
      "20201211 \\btest|getest|sneltest|pcr\n",
      "20201212 \\btest|getest|sneltest|pcr\n",
      "20201213 \\btest|getest|sneltest|pcr\n",
      "20201214 \\btest|getest|sneltest|pcr\n",
      "20201215 \\btest|getest|sneltest|pcr\n",
      "20201216 \\btest|getest|sneltest|pcr\n",
      "20201217 \\btest|getest|sneltest|pcr\n",
      "20201218 \\btest|getest|sneltest|pcr\n",
      "20201219 \\btest|getest|sneltest|pcr\n",
      "20201220 \\btest|getest|sneltest|pcr\n",
      "20201221 \\btest|getest|sneltest|pcr\n",
      "20201222 \\btest|getest|sneltest|pcr\n",
      "20201223 \\btest|getest|sneltest|pcr\n",
      "20201224 \\btest|getest|sneltest|pcr\n",
      "20201225 \\btest|getest|sneltest|pcr\n",
      "20201226 \\btest|getest|sneltest|pcr\n",
      "20201227 \\btest|getest|sneltest|pcr\n",
      "20201228 \\btest|getest|sneltest|pcr\n",
      "20201229 \\btest|getest|sneltest|pcr\n",
      "20201230 \\btest|getest|sneltest|pcr\n",
      "20201231 \\btest|getest|sneltest|pcr\n"
     ]
    }
   ],
   "source": [
    "def deleteLastElement(myDict):\n",
    "    if myDict: del(myDict[list(myDict.keys())[-1]])\n",
    "\n",
    "def processData(dataContainer,queryName):\n",
    "    if len(dataContainer) > 0: deleteLastElement(dataContainer)\n",
    "    dataContainer = searchText(queryName,dataContainer)\n",
    "    saveCounts(dataContainer,queryName+CSVSUFFIX)\n",
    "    return(dataContainer)\n",
    "\n",
    "if False:\n",
    "    processData(lockdown,LOCKDOWN)\n",
    "    processData(distance,DISTANCE)\n",
    "    processData(topic,TOPIC)\n",
    "    processData(covid,\"covid\")\n",
    "    processData(mondkapje,\"mondkapje\")\n",
    "    processData(corona,\"corona\")\n",
    "    processData(rivm,\"rivm\")\n",
    "    \n",
    "if True:\n",
    "#    vaccin = processData({},VACCIN)\n",
    "    test = processData({},\"test\")\n",
    "#    avondklok = processData({},\"avondklok\")\n",
    "#    swear = processData({},\"swear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'202002': 37932,\n",
       " '202003': 276644,\n",
       " '202004': 207807,\n",
       " '202005': 142451,\n",
       " '202006': 97752,\n",
       " '202007': 134769,\n",
       " '202008': 189211,\n",
       " '202009': 268686,\n",
       " '202010': 306671,\n",
       " '202011': 183086,\n",
       " '202012': 251795,\n",
       " 'total': 2096804}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthCounts = {}\n",
    "for date in test:\n",
    "    month = str(date)[0:6]\n",
    "    if not month in monthCounts: monthCounts[month] = 0\n",
    "    monthCounts[month] += test[date]\n",
    "monthCounts[\"total\"] = sum(monthCounts.values())\n",
    "monthCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from warnings import warn\n",
    "\n",
    "WEEKLENGTH = 7\n",
    "\n",
    "def summarize(myDict,index,count):\n",
    "    counter = 0\n",
    "    mySum = 0\n",
    "    myKeys = list(myDict.keys())\n",
    "    for i in range(0,count):\n",
    "        if index-i >= 0 and not math.isnan(myDict[myKeys[index-i]]):\n",
    "            counter += 1\n",
    "            mySum += myDict[myKeys[index-i]]\n",
    "            if myKeys[index-i] > myKeys[index]:\n",
    "                warn(\"keys are not sorted!\")\n",
    "    if counter == 0: return(math.nan)\n",
    "    else: return(mySum/counter)\n",
    "\n",
    "rivm7 = {list(rivm.keys())[i]:summarize(rivm,i,WEEKLENGTH) for i in range(0,len(rivm))}\n",
    "corona7 = {list(corona.keys())[i]:summarize(corona,i,WEEKLENGTH) for i in range(0,len(corona))}\n",
    "covid7 = {list(covid.keys())[i]:summarize(covid,i,WEEKLENGTH) for i in range(0,len(covid))}\n",
    "mondkapje7 = {list(mondkapje.keys())[i]:summarize(mondkapje,i,WEEKLENGTH) for i in range(0,len(mondkapje))}\n",
    "topic7 = {list(topic.keys())[i]:summarize(topic,i,WEEKLENGTH) for i in range(0,len(topic))}\n",
    "distance7 = {list(distance.keys())[i]:summarize(distance,i,WEEKLENGTH) for i in range(0,len(distance))}\n",
    "lockdown7 = {list(lockdown.keys())[i]:summarize(lockdown,i,WEEKLENGTH) for i in range(0,len(lockdown))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib\n",
    "#%matplotlib inline\n",
    "\n",
    "DATEFORMATPLOT = \"%Y%m%d\"\n",
    "PLOTFILEOUT = \"tweet-frequencies.png\"\n",
    "\n",
    "def getWeekendDates(dateStrings):\n",
    "    weekendDates = []\n",
    "    for ds in dateStrings:\n",
    "        d = datetime.strptime(str(ds),DATEFORMATPLOT)\n",
    "        if d == 0 or d == 6: weekendDates.append(d)\n",
    "            \n",
    "def stringArrayToDates(stringList,dateFormat=DATEFORMATPLOT):\n",
    "    return([datetime.strptime(str(date),dateFormat) for date in stringList])\n",
    "\n",
    "def prettyPrintNumber(number):\n",
    "    digits = str(number)\n",
    "    prettyNumber = \"\"\n",
    "    for i in range(-1,-len(digits)-1,-1):\n",
    "        prettyNumber = digits[i]+prettyNumber\n",
    "        if i % 3 == 0 and i > -len(digits): prettyNumber = \",\"+prettyNumber\n",
    "    return(prettyNumber)\n",
    "\n",
    "def makeLabel(name,myDict):\n",
    "    if name == TOPIC: label = \"pandemic\"\n",
    "    elif name == DISTANCE: label = \"social distancing\"\n",
    "    elif name == \"rivm\": label = \"RIVM\"\n",
    "    elif name == \"mondkapje\": label = \"face masks\"\n",
    "    else: label = name\n",
    "    return(label+\" (\"+prettyPrintNumber(sum(myDict.values()))+\")\")\n",
    "\n",
    "weekendDates = getWeekendDates(rivm.keys())\n",
    "font = {\"size\":16}\n",
    "matplotlib.rc(\"font\",**font)\n",
    "plt.figure(figsize=(15,9))\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.plot_date(stringArrayToDates(topic.keys()),list(topic.values()),xdate=True,fmt=\"-\",label=makeLabel(TOPIC,topic))\n",
    "ax1.plot_date(stringArrayToDates(corona.keys()),list(corona.values()),xdate=True,fmt=\"-\",label=makeLabel(\"corona\",corona))\n",
    "ax1.plot_date(stringArrayToDates(covid.keys()),list(covid.values()),xdate=True,fmt=\"-\",label=makeLabel(\"covid\",covid))\n",
    "ax1.plot_date(stringArrayToDates(rivm.keys()),list(rivm.values()),xdate=True,fmt=\"-\",label=makeLabel(\"rivm\",rivm))\n",
    "ax1.plot_date(stringArrayToDates(lockdown.keys()),list(lockdown.values()),xdate=True,fmt=\"-\",label=makeLabel(LOCKDOWN,lockdown))\n",
    "ax1.plot_date(stringArrayToDates(distance.keys()),list(distance.values()),xdate=True,fmt=\"-\",label=makeLabel(DISTANCE,distance))\n",
    "ax1.plot_date(stringArrayToDates(mondkapje.keys()),list(mondkapje.values()),xdate=True,fmt=\"-\",label=makeLabel(\"mondkapje\",mondkapje))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "dummy = ax1.legend()\n",
    "plt.title(\"Daily frequencies of tweets with pandemic terms written in Dutch\")\n",
    "plt.xlabel(\"day/month\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.savefig(PLOTFILEOUT)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot normalized values\n",
    "\n",
    "This code needs the contents of the file date-counts.csv to be up-to-date. The data for the file can be computed with shell code executed in a terminal in the directory data/text (adjust month in command):\n",
    "```for FILE in 202101??-00*; do DATE=`echo $FILE|cut -c1-8`; COUNT=`gunzip -c ${DATE}*|grep -v '^[0-9]'|wc -l`; echo $DATE,$COUNT; done >> ../date-counts.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def normalize(dateCounts,countsIn):\n",
    "    countsOut = {}\n",
    "    for key in countsIn:\n",
    "        if int(key) in dateCounts.index: \n",
    "            countsOut[key] = countsIn[key]/dateCounts.loc[int(key)][\"count\"]\n",
    "    return(countsOut)\n",
    "\n",
    "dateCounts = pd.read_csv(DATADIR+\"../date-counts.csv\",index_col=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivmNorm = normalize(dateCounts,rivm)\n",
    "coronaNorm = normalize(dateCounts,corona)\n",
    "covidNorm = normalize(dateCounts,covid)\n",
    "mondkapjeNorm = normalize(dateCounts,mondkapje)\n",
    "topicNorm = normalize(dateCounts,topic)\n",
    "distanceNorm = normalize(dateCounts,distance)\n",
    "lockdownNorm = normalize(dateCounts,lockdown)\n",
    "\n",
    "rivmNorm7 = {list(rivmNorm.keys())[i]:summarize(rivmNorm,i,WEEKLENGTH) for i in range(0,len(rivmNorm))}\n",
    "coronaNorm7 = {list(coronaNorm.keys())[i]:summarize(coronaNorm,i,WEEKLENGTH) for i in range(0,len(coronaNorm))}\n",
    "covidNorm7 = {list(covidNorm.keys())[i]:summarize(covidNorm,i,WEEKLENGTH) for i in range(0,len(covidNorm))}\n",
    "mondkapjeNorm7 = {list(mondkapjeNorm.keys())[i]:summarize(mondkapjeNorm,i,WEEKLENGTH) for i in range(0,len(mondkapjeNorm))}\n",
    "topicNorm7 = {list(topicNorm.keys())[i]:summarize(topicNorm,i,WEEKLENGTH) for i in range(0,len(topicNorm))}\n",
    "distanceNorm7 = {list(distanceNorm.keys())[i]:summarize(distanceNorm,i,WEEKLENGTH) for i in range(0,len(distanceNorm))}\n",
    "lockdownNorm7 = {list(lockdownNorm.keys())[i]:summarize(lockdownNorm,i,WEEKLENGTH) for i in range(0,len(lockdownNorm))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "ax2 = plt.subplot(111)\n",
    "ax2.plot_date(stringArrayToDates(topicNorm7.keys()),list(topicNorm7.values()),xdate=True,fmt=\"-\",label=makeLabel(\"topic\",topic))\n",
    "ax2.plot_date(stringArrayToDates(coronaNorm7.keys()),list(coronaNorm7.values()),xdate=True,fmt=\"-\",label=makeLabel(\"corona\",corona))\n",
    "ax2.plot_date(stringArrayToDates(covidNorm7.keys()),list(covidNorm7.values()),xdate=True,fmt=\"-\",label=makeLabel(\"covid\",covid))\n",
    "ax2.plot_date(stringArrayToDates(mondkapjeNorm7.keys()),list(mondkapjeNorm7.values()),xdate=True,fmt=\"-\",label=makeLabel(\"mondkapje\",mondkapje))\n",
    "ax2.plot_date(stringArrayToDates(rivmNorm7.keys()),list(rivmNorm7.values()),xdate=True,fmt=\"-\",label=makeLabel(\"rivm\",rivm))\n",
    "ax2.plot_date(stringArrayToDates(distanceNorm7.keys()),list(distanceNorm7.values()),xdate=True,fmt=\"-\",label=makeLabel(\"distance\",distance))\n",
    "ax2.plot_date(stringArrayToDates(lockdownNorm7.keys()),list(lockdownNorm7.values()),xdate=True,fmt=\"-\",label=makeLabel(LOCKDOWN,lockdown))\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%-d/%-m\"))\n",
    "plt.title(\"Daily fractions of tweets with pandemic terms written in Dutch (moving average over 7 days)\")\n",
    "#plt.xticks([datetime.strptime(d,DATEFORMATPLOT) for d in \"20200301 20200401 20200501 20200601 20200701 20200801 20200901 20201001 20201101\".split()])\n",
    "dummy = ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "DATADIR = \"../data/all/\"\n",
    "ID = \"id_str\"\n",
    "LANG = \"lang\"\n",
    "USER = \"user\"\n",
    "SCREENNAME = \"screen_name\"\n",
    "RIVM = \"rivm\"\n",
    "DUTCH = \"nl\"\n",
    "TARGETDATES = [\"20200412\",\"20200413\",\"20200414\",\"20200415\",\"20200416\",\"20200417\",\"20200418\"]\n",
    "QUERY = \"mondkapje\"\n",
    "\n",
    "def removeNewlines(text):\n",
    "    return(re.sub(r\"\\n\",\" \",text))\n",
    "\n",
    "fileNames = os.listdir(DATADIR)\n",
    "texts = {}\n",
    "dates = {}\n",
    "for inFileName in fileNames:\n",
    "    inFileDate = inFileName[0:8]\n",
    "    if inFileDate in TARGETDATES:\n",
    "        inFile = gzip.open(DATADIR+inFileName,mode=\"rt\")\n",
    "        for line in inFile:\n",
    "            jsonData = json.loads(line)\n",
    "            tweetText = removeNewlines(getTweetText(jsonData))\n",
    "            tweetLang = jsonData[LANG]\n",
    "            tweetId = jsonData[ID]\n",
    "            tweetUser = jsonData[USER][SCREENNAME]\n",
    "            if tweetLang == DUTCH and \\\n",
    "               re.search(QUERY,tweetText,flags=re.IGNORECASE) and \\\n",
    "               re.search(RIVM,tweetText,flags=re.IGNORECASE):\n",
    "                texts[tweetId] = {\"user\":tweetUser,\"text\":tweetText}\n",
    "                dates[tweetId] = int(inFileDate)\n",
    "        inFile.close()\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(texts,orient=\"index\").to_csv(\"mondkapje-tweets.csv\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONFILE = DATADIR+\"../\"+\"mondkapje-tweets.csv.human-labels.txt\"\n",
    "\n",
    "def readAnnotations(annotationFile):\n",
    "    inFile = open(annotationFile,\"r\")\n",
    "    annotations = {}\n",
    "    minutes = {}\n",
    "    for line in inFile:\n",
    "        (userName,date,tweetId,nbr,label) = line.strip().split()\n",
    "        if not userName in annotations: \n",
    "            annotations[userName] = {}\n",
    "            minutes[userName] = {}\n",
    "        annotations[userName][tweetId] = label\n",
    "        minutes[userName][date[0:12]] = True\n",
    "    inFile.close()\n",
    "    for userName in annotations:\n",
    "        print(\"annotation time of user {0}: {1:d} messages in {2:d} minutes ({3:0.1f} tweets per minute)\".\\\n",
    "              format(userName,len(annotations[userName]),len(minutes[userName]),round(len(annotations[userName])/len(minutes[userName]),1)))\n",
    "    return(annotations)\n",
    "\n",
    "annotations = readAnnotations(ANNOTATIONFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotationFile in \"202007-distance-twitter.csv.human-labels.txt 202007-distance-nunl.csv.human-labels.txt \\\n",
    "                       202007-distance-reddit.csv.human-labels.txt\".split():\n",
    "    dummy = readAnnotations(\"../data/\"+annotationFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = readAnnotations(\"../data/\"+\"distance-tweets.csv.human-labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRRELEVANT = \"IRRELEVANT\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "POSITIVE = \"POSITIVE\"\n",
    "\n",
    "labelsPerDate = {}\n",
    "totals = {}\n",
    "for tweetId in dates:\n",
    "    if tweetId in annotations and annotations[tweetId] != IRRELEVANT:\n",
    "        date = int(dates[tweetId])\n",
    "        label = annotations[tweetId]\n",
    "        if not date in labelsPerDate: labelsPerDate[date] = {}\n",
    "        labelsPerDate[date][label] = labelsPerDate[date][label]+1 if label in labelsPerDate[date] else 1\n",
    "        totals[label] = totals[label]+1 if label in totals else 1\n",
    "labelsPerDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = {\"NEGATIVE\":\"rejects\",\"POSITIVE\":\"supports\",\"NEUTRAL\":\"neutral\"}\n",
    "percentages = {key:round(100*totals[key]/sum(totals.values())) for key in totals}\n",
    "font = {\"size\":16}\n",
    "matplotlib.rc(\"font\",**font)\n",
    "\n",
    "for date in labelsPerDate:\n",
    "    for label in [NEGATIVE,NEUTRAL,POSITIVE]:\n",
    "        if not label in labelsPerDate[date]:\n",
    "            labelsPerDate[date][label] = 0\n",
    "\n",
    "negative = [labelsPerDate[date][NEGATIVE] for date in labelsPerDate.keys()]\n",
    "neutral = [labelsPerDate[date][NEUTRAL] for date in labelsPerDate.keys()]\n",
    "positive = [labelsPerDate[date][POSITIVE] for date in labelsPerDate.keys()]\n",
    "negplusneu = [negative[i]+neutral[i] for i in range(0,len(neutral))]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(list(labelsPerDate.keys()),positive,label=labels[POSITIVE]+\" (\"+str(percentages[POSITIVE])+\"%)\",bottom=negplusneu)\n",
    "plt.bar(list(labelsPerDate.keys()),neutral,label=labels[NEUTRAL]+\" (\"+str(percentages[NEUTRAL])+\"%)\",bottom=negative)\n",
    "plt.bar(list(labelsPerDate.keys()),negative,label=labels[NEGATIVE]+\" (\"+str(percentages[NEGATIVE])+\"%)\",color=\"r\")\n",
    "plt.title(\"Twitter stance on RIVM advising against facemask use by general public\")\n",
    "plt.xticks(list(labelsPerDate.keys()),[\"Fri 17/4\",\"Wed 15/4\",\"Sun 12/4\",\"Thu 16/4\",\"Mon 13/4\",\"Tue 14/4\"])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## twiqs.nl tweets per month (alltime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFILE = \"../data/months.txt\"\n",
    "DATEFORMAT = \"%Y%m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATAFILE,sep=\" \",header=None,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\"size\":14}\n",
    "matplotlib.rc(\"font\",**font)\n",
    "plt.figure(figsize=(12,8))\n",
    "ax2 = plt.subplot(111)\n",
    "ax2.set_ylim([0,90000000])\n",
    "ax2.plot_date([datetime.strptime(str(month),DATEFORMAT) for month in df.index if month > 201100],\\\n",
    "               [df.loc[month][1] for month in df.index if month > 201100],fmt=\"-\")\n",
    "plt.title(\"number of Dutch tweets collected by twiqs.nl per month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
