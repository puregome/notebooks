{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with the antivac data of Kunneman et al 2020\n",
    "\n",
    "F. Kunneman, M. Lambooij, A. Wong, A. van den Bosch, L. Mollema. Monitoring stance towards vaccination in Twitter messages. In: BMC Medical Informatics and Decision Making. 20, 1, p. 1-14, 2020, doi 10.1186/s12911-020-1046-y. Data: http://cls.ru.nl/~fkunneman/data_stance_vaccination.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/erikt/projects/puregome/data/data_stance_vaccination/\"\n",
    "DATAFILE = \"tweetids_labels.txt\"\n",
    "TWEETSFILE = \"getTweetsId.py.out\"\n",
    "POLARITY = \"Polarity\"\n",
    "SENTIMENT = \"Sentiment\"\n",
    "IDSTR = \"id_str\"\n",
    "TEXT = \"text\"\n",
    "TOKENIZEDTEXT = \"tokenizedtext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAnnotations(inFileName):\n",
    "    return(pd.read_csv(inFileName,sep=\"\\t\",index_col=\"Tweet ID\"))\n",
    "           \n",
    "dfAnnotations = readAnnotations(DATADIR+DATAFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"text\"\n",
    "FULLTEXT = \"full_text\"\n",
    "EXTENDEDTWEET = \"extended_tweet\"\n",
    "RETWEETEDSTATUS = \"retweeted_status\"\n",
    "\n",
    "def getTweetText(jsonData):\n",
    "    text = \"\"\n",
    "    if TEXT in jsonData: \n",
    "        text = jsonData[TEXT]\n",
    "    if EXTENDEDTWEET in jsonData and \\\n",
    "       FULLTEXT in jsonData[EXTENDEDTWEET]:\n",
    "        text = jsonData[EXTENDEDTWEET][FULLTEXT]\n",
    "    if RETWEETEDSTATUS in jsonData and \\\n",
    "       EXTENDEDTWEET in jsonData[RETWEETEDSTATUS] and \\\n",
    "       FULLTEXT in jsonData[RETWEETEDSTATUS][EXTENDEDTWEET]:\n",
    "        text = jsonData[RETWEETEDSTATUS][EXTENDEDTWEET][FULLTEXT]\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTweetTexts(inFileName):\n",
    "    tweetTexts = {}\n",
    "    inFile = open(inFileName,\"r\")\n",
    "    for line in inFile:\n",
    "        jsonData = json.loads(line.strip())\n",
    "        idStr = jsonData[IDSTR]\n",
    "        text = getTweetText(jsonData)\n",
    "        tweetTexts[idStr] = text\n",
    "    inFile.close()\n",
    "    return(tweetTexts)\n",
    "\n",
    "dictTweetTexts = readTweetTexts(DATADIR+TWEETSFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFasttextData(dfAnnotations,dictTweetTexts):\n",
    "    fasttextData = []\n",
    "    for idStr in dictTweetTexts:\n",
    "        polarity = re.sub(\" \",\"_\",dfAnnotations.loc[int(idStr)][POLARITY])\n",
    "        tokenizedText = \" \".join(TweetTokenizer().tokenize(dictTweetTexts[idStr])).lower()\n",
    "        fasttextData.append({IDSTR:idStr,POLARITY:polarity,TOKENIZEDTEXT:tokenizedText})\n",
    "    return(fasttextData)\n",
    "        \n",
    "fasttextData = makeFasttextData(dfAnnotations,dictTweetTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINEDDIR = \"/home/erikt/projects/newsgac/fasttext-runs/\"\n",
    "WIKIFILENAME = \"wiki.nl.vec\"\n",
    "DIM = 300\n",
    "EPOCH = 100\n",
    "LR = 0.1\n",
    "N = 10\n",
    "LARGEINT = 9999999999\n",
    "LABELPREFIX = \"__label__\"\n",
    "TRAIN = \"TRAIN\"+str(int(random.random()*LARGEINT))\n",
    "TEST = \"TEST\"+str(int(random.random()*LARGEINT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFasttext(fasttextData,dim=DIM,epoch=EPOCH,lr=LR,n=N):\n",
    "    predictionCounts = []\n",
    "    predictionLabels = []\n",
    "    for fold in range(0,n):\n",
    "        clear_output(wait=True)\n",
    "        print(\"starting fold\",fold)\n",
    "        testStart = round(fold*len(fasttextData)/n)\n",
    "        testEnd = round((fold+1)*len(fasttextData)/n)\n",
    "        trainFile = open(TRAIN,\"w\")\n",
    "        testFile = open(TEST,\"w\")\n",
    "        testData = []\n",
    "        for i in range(0,len(fasttextData)):\n",
    "            data = LABELPREFIX+fasttextData[i][POLARITY]+\" \"+fasttextData[i][TOKENIZEDTEXT]\n",
    "            if i < testStart or i >= testEnd: \n",
    "                print(data,file=trainFile)\n",
    "            else: \n",
    "                print(data,file=testFile)\n",
    "                testData.append(data)\n",
    "        testFile.close()\n",
    "        trainFile.close()\n",
    "        model = fasttext.train_supervised(TRAIN,dim=dim,epoch=epoch,lr=lr) #,pretrainedVectors=PRETRAINEDDIR+WIKIFILENAME)\n",
    "        predictionCounts.append([*model.test(TEST)])\n",
    "        predictionLabels.extend(model.predict(testData)[0])\n",
    "        os.unlink(TRAIN)\n",
    "        os.unlink(TEST)\n",
    "    clear_output(wait=True)\n",
    "    print(\"finished\")\n",
    "    return(predictionCounts,predictionLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "predictionCounts,predictionLabels = runFasttext(fasttextData,dim=300,epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases: 6361; precision: 0.372; recall: 0.372\n"
     ]
    }
   ],
   "source": [
    "def showOverallPrecision(predictionCounts):\n",
    "    caseTotal = 0\n",
    "    pTotal = 0\n",
    "    rTotal = 0\n",
    "    for i in range(0,len(predictionCounts)):\n",
    "        caseTotal += predictionCounts[i][0]\n",
    "        pTotal += predictionCounts[i][0]*predictionCounts[i][1]\n",
    "        rTotal += predictionCounts[i][0]*predictionCounts[i][2]\n",
    "    print(\"cases: {0}; precision: {1}; recall: {2}\".format(caseTotal,round(pTotal/caseTotal,3),round(rTotal/caseTotal,3)))\n",
    "    \n",
    "showOverallPrecision(predictionCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 2364,\n",
       " 'Negative': 921,\n",
       " 'Irrelevant': 716,\n",
       " 'Neutral': 1061,\n",
       " 'Not_clear': 706}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countGoldLabels(fasttextData):\n",
    "    labelCountsGold = {}\n",
    "    for i in range(0,len(fasttextData)):\n",
    "        label = fasttextData[i][POLARITY]\n",
    "        if label in labelCountsGold: labelCountsGold[label] += 1\n",
    "        else: labelCountsGold[label] = 1\n",
    "    return(labelCountsGold)\n",
    "\n",
    "labelCountsGold = countGoldLabels(fasttextData)\n",
    "labelCountsGold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "def getBaselineAccuracy(labelCountsGold):\n",
    "    return(round(max(labelCountsGold.values())/sum(labelCountsGold.values()),3))\n",
    "\n",
    "print(\"baseline accuracy:\",getBaselineAccuracy(labelCountsGold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__label__Neutral': 1068,\n",
       " '__label__Negative': 946,\n",
       " '__label__Not_clear': 650,\n",
       " '__label__Irrelevant': 716,\n",
       " '__label__Positive': 2981}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countPredictedLabels(predictionLabels):\n",
    "    labelCountsPredicted = {}\n",
    "    for i in range(0,len(predictionLabels)):\n",
    "        label = predictionLabels[i][0]\n",
    "        if label in labelCountsPredicted: labelCountsPredicted[label] += 1\n",
    "        else: labelCountsPredicted[label] = 1\n",
    "    return(labelCountsPredicted)\n",
    "\n",
    "labelCountsPredicted = countPredictedLabels(predictionLabels)\n",
    "labelCountsPredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>__label__Irrelevant</th>\n",
       "      <th>__label__Negative</th>\n",
       "      <th>__label__Neutral</th>\n",
       "      <th>__label__Not_clear</th>\n",
       "      <th>__label__Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>192</td>\n",
       "      <td>94</td>\n",
       "      <td>111</td>\n",
       "      <td>84</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Negative</td>\n",
       "      <td>72</td>\n",
       "      <td>224</td>\n",
       "      <td>144</td>\n",
       "      <td>88</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>100</td>\n",
       "      <td>125</td>\n",
       "      <td>333</td>\n",
       "      <td>135</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Not_clear</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>157</td>\n",
       "      <td>100</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Positive</td>\n",
       "      <td>160</td>\n",
       "      <td>288</td>\n",
       "      <td>303</td>\n",
       "      <td>196</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       __label__Irrelevant  __label__Negative  __label__Neutral  \\\n",
       "row_0                                                                  \n",
       "Irrelevant                  192                 94               111   \n",
       "Negative                     72                224               144   \n",
       "Neutral                     100                125               333   \n",
       "Not_clear                    80                 85               157   \n",
       "Positive                    160                288               303   \n",
       "\n",
       "col_0       __label__Not_clear  __label__Positive  \n",
       "row_0                                              \n",
       "Irrelevant                  84                235  \n",
       "Negative                    88                393  \n",
       "Neutral                    135                368  \n",
       "Not_clear                  100                284  \n",
       "Positive                   196               1417  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeConfusionMatrix(fasttextData,predictionLabels):\n",
    "    goldLabels = pd.Series([fasttextData[i][POLARITY] for i in range(0,len(fasttextData))])\n",
    "    predictedLabels = pd.Series([predictionLabels[i][0] for i in range(0,len(predictionLabels))])\n",
    "    return(pd.crosstab(goldLabels,predictedLabels))\n",
    "\n",
    "makeConfusionMatrix(fasttextData,predictionLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total absolute deviation 666\n"
     ]
    }
   ],
   "source": [
    "print(\"total absolute deviation\",sum([abs(labelCountsPredicted[LABELPREFIX+l]-labelCountsGold[l]) for l in labelCountsGold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative deviation per label: {'Positive': 0.141, 'Negative': 0.114, 'Irrelevant': 0.156, 'Neutral': 0.012, 'Not_clear': 0.146}\n"
     ]
    }
   ],
   "source": [
    "print(\"relative deviation per label:\",\\\n",
    "      {l:round(abs(labelCountsPredicted[LABELPREFIX+l]-labelCountsGold[l])/labelCountsGold[l],3) for l in labelCountsGold})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine stance data sets with different topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = \"mondkapje\"\n",
    "FILETWEETS = TOPIC+\"-tweets.csv\"\n",
    "FILEANNOTATIONS = \"human-labels-\"+TOPIC+\"-tweets.txt\"\n",
    "LABEL = \"label\"\n",
    "TEXT = \"text\"\n",
    "USER = \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAnnotations(inFileName):\n",
    "    return(pd.read_csv(inFileName,header=None,sep=\" \"))\n",
    "\n",
    "dfAnnotations = readAnnotations(FILEANNOTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTweets(inFileName):\n",
    "    return(pd.read_csv(inFileName,header=None,index_col=0))\n",
    "\n",
    "dfTweets = readTweets(FILETWEETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLabel(label):\n",
    "    label = re.sub(\"NEUTRAL\",\"Neutral\",label)\n",
    "    label = re.sub(\"POSITIVE\",\"Positive\",label)\n",
    "    label = re.sub(\"NEGATIVE\",\"Negative\",label)\n",
    "    label = re.sub(\"IRRELEVANT\",\"Irrelevant\",label)\n",
    "    return(label)\n",
    "\n",
    "def makeFasttextData(dfAnnotations,dfTweets):\n",
    "    fasttextData = []\n",
    "    seen = {}\n",
    "    for i in range(0,len(dfAnnotations)):\n",
    "        tweetId = dfAnnotations.iloc[i][2]\n",
    "        if tweetId in list(dfTweets.index):\n",
    "            tweetLabel = convertLabel(dfAnnotations.iloc[i][4])\n",
    "            tweetUser = dfTweets.loc[tweetId][1]\n",
    "            tokenizedText = \" \".join(TweetTokenizer().tokenize(dfTweets.loc[tweetId][2])).lower()\n",
    "            if not tokenizedText in seen:\n",
    "                seen[tokenizedText] = True\n",
    "                fasttextData.append({IDSTR:tweetId,POLARITY:tweetLabel,TOKENIZEDTEXT:tokenizedText})\n",
    "    return(fasttextData)\n",
    "\n",
    "fasttextDataTopic = makeFasttextData(dfAnnotations,dfTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttextDataCombined = fasttextData+fasttextDataTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5768, 593, 6361)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasttextData),len(fasttextDataTopic),len(fasttextDataCombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "predictionCounts,predictionLabels = runFasttext(fasttextDataCombined,dim=300,epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases: 6361; precision: 0.369; recall: 0.369\n"
     ]
    }
   ],
   "source": [
    "showOverallPrecision(predictionCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 2364,\n",
       " 'Negative': 921,\n",
       " 'Irrelevant': 716,\n",
       " 'Neutral': 1061,\n",
       " 'Not_clear': 706}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelCountsGold = countGoldLabels(fasttextData)\n",
    "labelCountsGold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline accuracy:\",getBaselineAccuracy(labelCountsGold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__label__Neutral': 1071,\n",
       " '__label__Negative': 938,\n",
       " '__label__Not_clear': 663,\n",
       " '__label__Irrelevant': 707,\n",
       " '__label__Positive': 2982}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelCountsPredicted = countPredictedLabels(predictionLabels)\n",
    "labelCountsPredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>__label__Irrelevant</th>\n",
       "      <th>__label__Negative</th>\n",
       "      <th>__label__Neutral</th>\n",
       "      <th>__label__Not_clear</th>\n",
       "      <th>__label__Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Negative</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Neutral</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       __label__Irrelevant  __label__Negative  __label__Neutral  \\\n",
       "row_0                                                                  \n",
       "Irrelevant                   38                 44                21   \n",
       "Negative                     19                 54                21   \n",
       "Neutral                       8                 15                 6   \n",
       "Positive                      4                  4                 1   \n",
       "\n",
       "col_0       __label__Not_clear  __label__Positive  \n",
       "row_0                                              \n",
       "Irrelevant                  35                 98  \n",
       "Negative                    32                146  \n",
       "Neutral                      6                 18  \n",
       "Positive                     6                 17  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeConfusionMatrix(fasttextDataCombined[5768:],predictionLabels[5768:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6361"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasttextDataCombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6361"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictionLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
