{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic keywords\n",
    "\n",
    "Check which words are typical for topic tweets in different time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "sys.path.append(\"/home/erikt/projects/newsgac/fasttext-runs\")\n",
    "import tscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/erikt/projects/puregome/data/text/\"\n",
    "ID = \"id_str\"\n",
    "REPLYID = \"in_reply_to_status_id_str\"\n",
    "TEXT = \"text\"\n",
    "TOKEN = \"token\"\n",
    "USER = \"user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count tweets with topic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTweets(datePattern,query):\n",
    "    count = 0\n",
    "    fileList = sorted(os.listdir(DATADIR))\n",
    "    for inFileName in fileList:\n",
    "        if re.search(datePattern,inFileName):\n",
    "            squeal(inFileName)\n",
    "            df = pd.read_csv(DATADIR+inFileName,compression=\"gzip\",index_col=ID)\n",
    "            for i in range(0,len(df)):\n",
    "                text = df.iloc[i][TEXT]\n",
    "                if re.search(query,text): count += 1\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTweetsReplies(datePattern,query):\n",
    "    count = 0\n",
    "    selectedIds = {}\n",
    "    fileList = sorted(os.listdir(DATADIR))\n",
    "    for inFileName in fileList:\n",
    "        if re.search(datePattern,inFileName):\n",
    "            squeal(inFileName)\n",
    "            df = pd.read_csv(DATADIR+inFileName,compression=\"gzip\",index_col=ID)\n",
    "            for i in range(0,len(df)):\n",
    "                text = df.iloc[i][TEXT]\n",
    "                replyParent = df.iloc[i][REPLYID]\n",
    "                if re.search(query,text) or replyParent in selectedIds: \n",
    "                    count += 1\n",
    "                    idstr = df.index[i]\n",
    "                    selectedIds[idstr] = True\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATTERN = \"20200522\"\n",
    "\n",
    "for query in \"corona corona|covid corona|covid|flattenthecurve corona|covid|blijfthuis corona|covid|rivm\\\n",
    "              corona|covid|mondkapje corona|covid|huisarts corona|covid|houvol corona|covid|zorg\".split():\n",
    "    count = countTweets(FILEPATTERN,query)\n",
    "    print(count,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATTERN = \"20200522\"\n",
    "\n",
    "for query in \"corona corona|covid corona|covid|flattenthecurve corona|covid|blijfthuis corona|covid|rivm\\\n",
    "              corona|covid|mondkapje corona|covid|huisarts corona|covid|houvol corona|covid|zorg\".split():\n",
    "    count = countTweetsReplies(FILEPATTERN,query)\n",
    "    print(count,query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the query \"zorg\" produces many false positives. There are irrelevant types (\"bezorgd\" and \"bezorgen\"), irrelevant syntactical forms (\"ik zorg dat\" and \"Zorg dat je\") and even the correct sense is not always related to the pandemic topic (\"zorg voor ouderen/gehandicapten\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find other relevant words in topic tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "AT = r\"@\"\n",
    "HASH = r\"#\"\n",
    "\n",
    "def getTokensOfMatchedTweets(filePattern,query):\n",
    "    fileList = sorted(os.listdir(DATADIR))\n",
    "    matchTokens = {}\n",
    "    nonMatchTokens = {}\n",
    "    for inFileName in fileList:\n",
    "        if re.search(filePattern,inFileName):\n",
    "            squeal(inFileName)\n",
    "            df = pd.read_csv(DATADIR+inFileName,compression=\"gzip\",index_col=ID)\n",
    "            for i in range(0,len(df)):\n",
    "                text = re.sub(\"\\\\\\\\n\",\" \",df.iloc[i][TEXT])\n",
    "                if re.search(query,text):\n",
    "                    for token in TweetTokenizer().tokenize(text.lower()): \n",
    "                        if not token in matchTokens: matchTokens[token] = 0\n",
    "                        matchTokens[token] += 1\n",
    "                else:\n",
    "                    for token in TweetTokenizer().tokenize(text.lower()): \n",
    "                        if not token in nonMatchTokens: nonMatchTokens[token] = 0\n",
    "                        nonMatchTokens[token] += 1\n",
    "    return(matchTokens,nonMatchTokens)\n",
    "\n",
    "\n",
    "def readData(fileName):\n",
    "    return(pd.read_csv(fileName,index_col=TOKEN).to_dict())\n",
    "\n",
    "def writeData(data,fileName):\n",
    "    pd.DataFrame(data).to_csv(fileName,index_label=TOKEN)\n",
    "    \n",
    "def findKeysStartingWithChar(data,char):\n",
    "    keysStartingWithChar = []\n",
    "    for key in data:\n",
    "        try:\n",
    "            if re.search(r\"^\"+char+r\"\\w\",key):\n",
    "                shortKey = key[1:]\n",
    "                if shortKey in data: keysStartingWithChar.append(shortKey)\n",
    "        except: pass\n",
    "    return(keysStartingWithChar)\n",
    "\n",
    "def combineKeysStartingWithChar(data,char,keysStartingWithChar):\n",
    "    for key in keysStartingWithChar:\n",
    "        data[key] += data[char+key]\n",
    "        del(data[char+key])\n",
    "    return(data)\n",
    "\n",
    "def combineInitialHashAt(data):\n",
    "    keysStartingWithHash = findKeysStartingWithChar(data,HASH)\n",
    "    data = combineKeysStartingWithChar(data,HASH,keysStartingWithHash)\n",
    "    keysStartingWithAt = findKeysStartingWithChar(data,AT)\n",
    "    data = combineKeysStartingWithChar(data,AT,keysStartingWithAt)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFEXAMPLES = 20\n",
    "\n",
    "def dictTopN(dictionary,n=NBROFEXAMPLES):\n",
    "    return([(x[1],x[0]) for x in dictionary.items()][0:n])\n",
    "\n",
    "def dictBottomN(dictionary,n=NBROFEXAMPLES):\n",
    "    return([(x[1],x[0]) for x in dictionary.items()][-n:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBROFTOKENS = \"totalFreq\"\n",
    "NBROFTYPES = \"nbrOfWords\"\n",
    "WORDFREQS = \"wordFreqs\"\n",
    "\n",
    "def makeTscoreData(tokenList):\n",
    "    data = { NBROFTOKENS:0, NBROFTYPES:0, WORDFREQS:{} }\n",
    "    for token in tokenList:\n",
    "        if not math.isnan(tokenList[token]):\n",
    "            data[WORDFREQS][token] = tokenList[token]\n",
    "            data[NBROFTYPES] += 1\n",
    "            data[NBROFTOKENS] += tokenList[token]\n",
    "    return(data)\n",
    "\n",
    "def sortTscores(tscores):\n",
    "    return({token:tscores[token] for token in sorted(tscores.keys(),key=lambda t:tscores[t],reverse=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201031-23.out.gz\n"
     ]
    }
   ],
   "source": [
    "FILEPATTERN = \"2020102[56789]|2020103\" \n",
    "QUERY= r\"1[.,]5[ -]*m|afstand.*hou|hou.*afstand|anderhalve[ -]*meter\"\n",
    "QUERY = \"corona|covid\"\n",
    "QUERY = \"reis|reizen\"\n",
    "QUERY = \"hand.*was|was.*hand\"\n",
    "\n",
    "queryTokens = {}\n",
    "nonQueryTokens = {}\n",
    "tscoresDataQuery = {}\n",
    "tscoresDataNonQuery = {}\n",
    "queryTokens[FILEPATTERN],nonQueryTokens[FILEPATTERN] = getTokensOfMatchedTweets(FILEPATTERN,QUERY)\n",
    "tscoresDataQuery[FILEPATTERN] = makeTscoreData(queryTokens[FILEPATTERN])\n",
    "tscoresDataNonQuery[FILEPATTERN] = makeTscoreData(nonQueryTokens[FILEPATTERN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.2 was\n",
      "41.8 handen\n",
      "31.2 hand\n",
      "31.2 wassen\n",
      "27.2 zoon\n",
      "24.0 verkocht\n",
      "20.7 school\n",
      "19.9 .\n",
      "19.1 behandeling\n",
      "19.0 afstand\n",
      "18.3 mishandeling\n",
      "17.5 werden\n",
      "17.5 boekhandel\n",
      "17.2 loopt\n",
      "17.1 nederlanden\n",
      "17.1 baken\n",
      "17.1 nergens\n",
      "17.1 waarschuwen\n",
      "17.1 gezakt\n",
      "17.0 mochten\n",
      "16.9 verlichting\n",
      "16.9 @kajsaollongren\n",
      "16.8 verkoopt\n",
      "16.6 aldus\n",
      "16.5 publiek\n",
      "16.5 namens\n",
      "16.3 kapot\n",
      "16.3 @martinbosma_pvv\n",
      "16.2 toen\n",
      "16.2 getuige\n",
      "16.1 boeken\n",
      "16.0 https://t.co/zuqtdznsnx\n",
      "16.0 filmt\n",
      "16.0 diep\n",
      "15.9 schokkende\n",
      "15.9 1ste\n",
      "15.8 op\n",
      "15.7 middelbare\n",
      "15.7 werd\n",
      "15.7 let\n",
      "15.6 meid\n",
      "15.6 ongelooflijk\n",
      "15.4 der\n",
      "15.1 beelden\n",
      "15.1 mijn\n",
      "15.0 aan\n",
      "15.0 lief\n",
      "14.8 lastig\n",
      "14.7 ooit\n",
      "14.6 vandaag\n",
      "14.4 zwarte\n",
      "14.4 handig\n",
      "14.4 ver\n",
      "14.2 protocol\n",
      "14.1 langer\n",
      "14.1 fulmineert\n",
      "14.0 boven\n",
      "14.0 ethisch\n",
      "14.0 geactiveerd\n",
      "13.9 overleggen\n",
      "13.8 . ...\n",
      "13.7 jonge\n",
      "13.6 houden\n",
      "13.5 hij\n",
      "13.4 had\n",
      "13.4 schande\n",
      "13.2 valt\n",
      "12.9 vrijheid\n",
      "12.8 kiezen\n",
      "12.7 geweld\n",
      "12.6 er\n",
      "12.5 die\n",
      "12.4 verschillende\n",
      "12.1 onhandig\n",
      "12.1 1,5\n",
      "12.1 wie\n",
      "11.9 europa\n",
      "11.8 moest\n",
      "11.6 handhaven\n",
      "11.6 schandalig\n",
      "11.5 ziekenhuizen\n",
      "11.3 maatregelen\n",
      "11.1 onschuld\n",
      "11.1 mondmasker\n",
      "11.1 geweest\n",
      "10.9 handhaving\n",
      "10.9 krijgt\n",
      "10.8 #akwasi\n",
      "10.6 al\n",
      "10.6 wast\n",
      "10.4 de\n",
      "10.4 🇳\n",
      "10.3 🇱\n",
      "10.3 kon\n",
      "10.2 behandeld\n",
      "10.2 regels\n",
      "10.1 https://t.co/sjmv1fllei\n",
      "10.1 anti-lhbti\n",
      "10.1 lhbti\n",
      "10.1 homofoob\n"
     ]
    }
   ],
   "source": [
    "for x in dictTopN(sortTscores(tscore.computeTscore(tscoresDataQuery[FILEPATTERN],tscoresDataNonQuery[FILEPATTERN])),n=100): \n",
    "    print(round(x[0],1),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-86.9 islam\n",
      "-87.2 0.0\n",
      "-88.0 fijne\n",
      "-90.7 goedemorgen\n",
      "-91.9 gogh\n",
      "-96.8 moslims\n",
      "-97.7 !\n",
      "-99.8 😂\n",
      "-102.6 luchtdruk\n",
      "-103.0 km\n",
      "-104.3 erdogan\n",
      "-104.6 celine\n",
      "-106.9 profeet\n",
      "-107.3 vermist\n",
      "-108.2 😘\n",
      "-112.7 hpa\n",
      "-118.3 mm\n",
      "-131.0 ¡\n",
      "-133.7 °\n",
      "-142.4 ik\n"
     ]
    }
   ],
   "source": [
    "for x in dictBottomN(sortTscores(tscore.computeTscore(tscoresDataQuery[FILEPATTERN],tscoresDataNonQuery[FILEPATTERN])),n=20): \n",
    "    print(round(x[0],1),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME202002 = \"query-tokens-202002-202003.csv\"\n",
    "FILENAME202004 = \"query-tokens-202004-202005.csv\"\n",
    "NON = \"non-\"\n",
    "WEEKS = {\"2020020[2-8]\":\"20200202\",\"20200209|2020021[0-5]\":\"20200209\",\"2020021[6-9]|2020022[0-2]\":\"20200216\",\"2020022[3-9]\":\"20200223\",\\\n",
    "         \"2020030[1-7]\":\"20200301\",\"2020030[89]|2020031[0-4]\":\"20200308\",\"2020031[5-9]|2020032[01]\":\"20200315\",\"2020032[2-8]\":\"20200322\",\\\n",
    "                                   \"20200329|20200330|2020040[1-4]\":\"20200329\",\\\n",
    "         \"2020040[5-9]|2020041[01]\":\"20200405\",\"2020041[2-8]\":\"20200412\",\"20200419|2020042[0-5]\":\"20200419\",\"2020042[6-9]|2020043|2020050[1-2]\":\"20200426\",\\\n",
    "         \"2020050[3-9]\":\"20200503\",\"2020051[0-6]\":\"20200510\",\"2020051[7-9]|2020052[0-3]\":\"20200517\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryTokens202002 = readData(FILENAME202004)\n",
    "nonQueryTokens202002 = readData(NON+FILENAME202004)\n",
    "tscoresDataQuery = {}\n",
    "tscoresDataNonQuery = {}\n",
    "tscores = {}\n",
    "for query in queryTokens202002:\n",
    "    tscoresDataQuery[query] = makeTscoreData(combineInitialHashAt(queryTokens202002[query]))\n",
    "    tscoresDataNonQuery[query] = makeTscoreData(combineInitialHashAt(nonQueryTokens202002[query]))\n",
    "    print(query)\n",
    "    tscores[query] = sortTscores(tscore.computeTscore(tscoresDataQuery[query],tscoresDataNonQuery[query]))\n",
    "    for x in dictTopN(tscores[query]): print(round(x[0],1),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writeData(tscores,\"tscores-202004-202005.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscores202002 = readData(\"tscores-202002-202003.csv\")\n",
    "tscores202004 = readData(\"tscores-202004-202005.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = \"maatregelen mondkapje anderhalve besmet rivm \".split()\n",
    "\n",
    "data = {}\n",
    "for topic in TOPICS:\n",
    "    for date in tscores202002.keys():\n",
    "        if not topic in data: data[topic] = {}\n",
    "        data[topic][date] = tscores202002[date][topic]\n",
    "    for date in tscores202004.keys():\n",
    "        data[topic][date] = tscores202004[date][topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "DATEFORMAT = \"%Y%m%d\"\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,4))\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%d %b\"))\n",
    "for topic in TOPICS:\n",
    "    plt.plot_date([datetime.strptime(WEEKS[date],DATEFORMAT) for date in data[topic]],list(data[topic].values()),label=topic,fmt=\"-\")\n",
    "ax.set(xlabel=\"date (weeks)\",ylabel=\"t-scores\")\n",
    "plt.title(\"t-scores for relevant words, comparing selected topic tweets with unselected tweets\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We expected only positive scores for topic words but the graph shows that *anderhalve* had negative scores  in two weeks. This means that most of the tweets containing this word are outside our topic tweets. We checked a sample of these missing tweets and most of them turned out to be on-topic, but they lacked the words *corona* and *covid*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"anderhalve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in tscores202002: \n",
    "    print(\"#####\",date)\n",
    "    for x in dictTopN(sortTscores(tscores202002[date]),n=50): print(round(x[0],1),x[1])\n",
    "for date in tscores202004:\n",
    "    print(\"#####\",date)\n",
    "    for x in dictTopN(sortTscores(tscores202004[date]),n=50): print(round(x[0],1),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryTokens202004 = readData(FILENAME202004)\n",
    "nonQueryTokens202004 = readData(NON+FILENAME202004)\n",
    "for query in queryTokens202004:\n",
    "    tscoresDataQuery[query] = makeTscoreData(combineInitialHashAt(queryTokens202004[query]))\n",
    "    tscoresDataNonQuery[query] = makeTscoreData(combineInitialHashAt(nonQueryTokens202004[query]))\n",
    "    print(query)\n",
    "    for x in dictTopN(sortTscores(tscore.computeTscore(tscoresDataQuery[query],tscoresDataNonQuery[query]))): print(round(x[0],1),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writeData(queryTokens,\"query-tokens-202004-202005.csv\")\n",
    "#writeData(nonQueryTokens,\"non-query-tokens-202004-202005.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2020051[7-9]|2020052[0-3]\"\n",
    "for x in dictTopN(sortTscores(tscore.computeTscore(tscoresDataQuery[query],tscoresDataNonQuery[query])),n=40): print(round(x[0],1),x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATTERN = \"20200601\" \n",
    "QUERY= r\"1.5m|1,5m|afstand.*hou|hou.*afstand|anderhalve\"\n",
    "\n",
    "queryTokens = {}\n",
    "nonQueryTokens = {}\n",
    "tscoresDataQuery = {}\n",
    "tscoresDataNonQuery = {}\n",
    "queryTokens[FILEPATTERN],nonQueryTokens[FILEPATTERN] = getTokensOfMatchedTweets(FILEPATTERN,QUERY)\n",
    "tscoresDataQuery[FILEPATTERN] = makeTscoreData(queryTokens[FILEPATTERN])\n",
    "tscoresDataNonQuery[FILEPATTERN] = makeTscoreData(nonQueryTokens[FILEPATTERN])\n",
    "for x in dictTopN(sortTscores(tscore.computeTscore(tscoresDataQuery[FILEPATTERN],tscoresDataNonQuery[FILEPATTERN])),n=40): \n",
    "    print(round(x[0],1),x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the query \"zorg\" produces many false positives. There are irrelevant types (\"bezorgd\" and \"bezorgen\"), irrelevant syntactical forms (\"ik zorg dat\" and \"Zorg dat je\") and even the correct sense is not always related to the pandemic topic (\"zorg voor ouderen/gehandicapten\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate coverage of crawler by looking back for messages with replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEPATTERN = \"20200522\"\n",
    "\n",
    "fileList = sorted(os.listdir(DATADIR))\n",
    "seenIds = {}\n",
    "for inFileName in fileList:\n",
    "    if re.search(DATEPATTERN,inFileName):\n",
    "        df = pd.read_csv(DATADIR+inFileName,compression=\"gzip\",dtype=str)\n",
    "        known = 0\n",
    "        unknown = 0\n",
    "        for i in range(0,len(df)):\n",
    "            idstr = df.iloc[i][ID]\n",
    "            seenIds[idstr] = True\n",
    "            replyParent = df.iloc[i][REPLYID]\n",
    "            if str(replyParent) != \"nan\":\n",
    "                if replyParent in seenIds: known += 1\n",
    "                else: unknown += 1\n",
    "        print(\"{0} {1:.3f}\".format(inFileName,round(known/(known+unknown),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
