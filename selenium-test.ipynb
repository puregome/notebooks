{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NU.nl comment harvester\n",
    "\n",
    "You need the Python library selenium (pip install selenium) and the geckodriver: https://github.com/mozilla/geckodriver/releases\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. point your web browser to a nu.nl news article\n",
    "2. ~~open the comment section by clicking on \"number reacties\" below the article~~\n",
    "3. ~~right click on a comment, choose \"This frame\" and then \"Show only this frame\" (tested in Firefox browser)~~\n",
    "4. ~~a new web page opens: get the address of this webpage~~\n",
    "5. ~~add the web page address in first code block below in a new line WEBPAGE=\"...\" below the other ones~~\n",
    "6. copy the url into the variable `current_url` in the first code block\n",
    "7. run the first code block\n",
    "8. a new window open with the comments\n",
    "9. open all comments by searching for \"meer reacties\" and clicking on the buttons\n",
    "10. run the second code block and wait (this takes a lot of time)\n",
    "11. the comments are stored in a file `[category]-[article_id].csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect list of relevant URLs:\n",
    "\n",
    "1. go to https://www.nu.nl/tag/Coronavirus\n",
    "2. manually click \"Laad meer artikelen\" until the desired time period is shown\n",
    "3. copy-paste from browser window to LibreOffice Writer\n",
    "4. save as Flat ODT xml file (.fodt)\n",
    "5. `grep -Eo \"https://www.nu.nl/[A-Za-z\\-]+/[0-9]+/\" [copied file].fodt|sort|uniq > [url file].txt`\n",
    "\n",
    "wrt 3 and 4: this can also be done with Microsoft Word, open the `docx` file in a file extraction program (e.g., WinZip) and locate the relevant `.xml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import re\n",
    "\n",
    "def id_from_article_url(article_url):\n",
    "    res = re.search(r\"([0-9]+)/$\", article_url)\n",
    "    return res.group(1)\n",
    "\n",
    "def category_from_article_url(article_url):\n",
    "    res = re.search(r\"^https://www.nu.nl/([^\\/]+)/\", article_url)\n",
    "    return res.group(1)\n",
    "\n",
    "def talk_url_from_id(article_id):\n",
    "    return \"https://talk.nu.nl/embed/stream?asset_url=https%3A%2F%2Fwww.nu.nl%2Fartikel%2F\"+str(article_id)+\"%2Fredirect.html&initialWidth=601&childId=coral_talk_wrapper\"\n",
    "\n",
    "DRIVER = \"/usr/local/bin/geckodriver\"\n",
    "\n",
    "URLFILE = \"urls_may_week1_uniq.txt\"\n",
    "urls_from_file = open(URLFILE, encoding=\"utf8\")\n",
    "urls_all = urls_from_file.read().splitlines()\n",
    "current_id = 12\n",
    "\n",
    "current_url = urls_all[current_id]\n",
    "# or add manually here\n",
    "# current_url = \"https://www.nu.nl/[...]\"\n",
    "\n",
    "print(current_url, \"id:\", id_from_article_url(current_url), \"category:\", category_from_article_url(current_url))\n",
    "\n",
    "article_id = id_from_article_url(current_url)\n",
    "article_cat = category_from_article_url(current_url)\n",
    "      \n",
    "WEBPAGE = talk_url_from_id(article_id)\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=DRIVER)\n",
    "driver.get(WEBPAGE)\n",
    "driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "COMMENT = r\"^Comment__commentContainer\"\n",
    "AUTHORNAME = r\"^AuthorName__name\"\n",
    "TIMESTAMP = r\"^CommentTimestamp__timestamp\"\n",
    "TEXT = r\"^Comment__content\"\n",
    "CLASS = \"class\"\n",
    "TITLE = \"title\"\n",
    "XPATHID = \"../../..\"\n",
    "XPATHPARENTID = \"../../../../..\"\n",
    "OUTPUTFILE = f\"{article_cat}-{article_id}.csv\"\n",
    "\n",
    "data = []\n",
    "for e in driver.find_elements_by_xpath(\"//div\"):\n",
    "    eClass = e.get_attribute(CLASS)\n",
    "    if re.search(COMMENT,eClass):\n",
    "        eId = e.find_elements_by_xpath(XPATHID)[0].id\n",
    "        parent = e.find_elements_by_xpath(XPATHPARENTID)[0].id\n",
    "        authorName = \"\"\n",
    "        timeStamp = \"\"\n",
    "        text = \"\"\n",
    "        for f in e.find_elements_by_xpath(\".//*\"):\n",
    "            fClass = f.get_attribute(CLASS)\n",
    "            if fClass != eClass:\n",
    "                if re.search(AUTHORNAME,fClass): \n",
    "                    authorName = f.text\n",
    "                elif re.search(TIMESTAMP,fClass): \n",
    "                    timeStamp = f.get_attribute(TITLE)\n",
    "                elif re.search(TEXT,fClass): \n",
    "                    text = re.sub(\"\\n\",\" \",f.text)\n",
    "                    break\n",
    "        data.append({\"id\":eId,\"name\":authorName,\"date\":timeStamp,\"text\":text,\"parent\":parent})\n",
    "        clear_output(wait=True)\n",
    "        print(\"processed:\",len(data))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(OUTPUTFILE,index=False)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
